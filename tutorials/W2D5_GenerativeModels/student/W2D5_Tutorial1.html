
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 1: Variational Autoencoders (VAEs) — Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.jpeg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W2D5_Tutorial2.html" rel="next" title="Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs"/>
<link href="../chapter_title.html" rel="prev" title="Generative Models"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.jpeg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/TheBasics.html">
   Deep Learning: The Basics Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing More With Fewer Parameters
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial2.html">
     (Bonus) Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Generative Models (W2D5)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DoingMoreWithFewerParameters.html">
   Deep Learning: Doing more with fewer parameters Wrap-up (Coming soon!)
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Advanced Topics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ContinualLearning/chapter_title.html">
   Continual Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Introduction to Continual Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/AdvancedTopics.html">
   Deep Learning: Advanced Topics Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/image_alignment.html">
       Image Alignment
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial1.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W2D5_GenerativeModels/student/W2D5_Tutorial1.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Variational Autoencoders (VAEs)
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-generative-models">
   Section 1: Generative models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-generative-modeling">
     Video 1: Generative Modeling
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-generating-images-from-biggan">
     Section 1.1: Generating Images from BigGAN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-1-generated-images">
       Think! 1.1: Generated images
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-2-interpolating-images-with-biggan">
     Section 1.2: Interpolating Images with BigGAN
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-2-interpolating-samples-from-the-same-category">
       Think! 1.2: Interpolating samples from the same category
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-latent-variable-models">
   Section 2: Latent Variable Models
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-latent-variable-models">
     Video 2: Latent Variable Models
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-ppca">
     Coding Exercise 2: pPCA
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-autoencoders">
   Section 3: Autoencoders
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-autoenconders">
     Video 3: Autoenconders
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#select-a-dataset">
       Select a dataset
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-conceptual-introduction-to-autoencoders">
     Section 3.1: Conceptual introduction to AutoEncoders
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-1-linear-autoencoder-architecture">
       Coding Exercise 3.1: Linear AutoEncoder Architecture
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparison-to-pca">
       Comparison to PCA
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-1-pca-vs-linear-autoenconder">
       Think! 3.1: PCA vs. Linear autoenconder
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-building-a-nonlinear-convolutional-autoencoder">
     Section 3.2: Building a nonlinear convolutional autoencoder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module">
       Coding Exercise 3.2: Fill in code for the
       <code class="docutils literal notranslate">
<span class="pre">
         ConvAutoEncoder
        </span>
</code>
       module
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-variational-auto-encoders-vaes">
   Section 4: Variational Auto-Encoders (VAEs)
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-variational-autoencoders">
     Video 4: Variational Autoencoders
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-components-of-a-vae">
     Section 4.1: Components of a VAE
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-generating-novel-images-from-the-decoder">
     Section 4.2: Generating novel images from the decoder
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-2-generating-images">
       Coding Exercise 4.2: Generating images
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-state-of-the-art-vaes-and-wrap-up">
   Section 5: State of the art VAEs and Wrap-up
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-state-of-the-art-vaes">
     Video 5: State-Of-The-Art VAEs
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W2D5_GenerativeModels/student/W2D5_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-1-variational-autoencoders-vaes">
<h1>Tutorial 1: Variational Autoencoders (VAEs)<a class="headerlink" href="#tutorial-1-variational-autoencoders-vaes" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 2, Day 5: Generative Models</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Saeed Salehi, Spiros Chavlis, Vikash Gilja</p>
<p><strong>Content reviewers:</strong> Diptodip Deb</p>
<p><strong>Content editor:</strong> Charles J Edelson</p>
<p><strong>Production editors:</strong> Saeed Salehi, Spiros Chavlis</p>
<p><em>Inspired from UPenn course</em>:
<strong>Instructor:</strong> Konrad Kording, <strong>Original Content creators:</strong> Richard Lange, Arash Ash</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In the first tutorial of the <em>Generative Models</em> day, we are going to</p>
<ul class="simple">
<li><p>Think about unsupervised learning / Generative Models and get a bird’s eye view of why it is useful</p></li>
<li><p>Build intuition about latent variables</p></li>
<li><p>See the connection between AutoEncoders and PCA</p></li>
<li><p>Start thinking about neural networks as generative models by contrasting AutoEncoders and Variational AutoEncoders</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<p>These are the slides for the videos in this tutorial</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/rd7ng/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<p>Install <em>Huggingface BigGAN</em> library</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip install --upgrade torchvision --quiet

<span class="c1"># @markdown Install *Huggingface BigGAN* library</span>
<span class="o">!</span>pip install pytorch-pretrained-biggan --quiet
<span class="o">!</span>pip install Pillow libsixel-python --quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class="-Color -Color-Yellow">WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.</span>
<span class="-Color -Color-Yellow">You should consider upgrading via the '/opt/hostedtoolcache/Python/3.7.11/x64/bin/python -m pip install --upgrade pip' command.</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class="-Color -Color-Yellow">WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.</span>
<span class="-Color -Color-Yellow">You should consider upgrading via the '/opt/hostedtoolcache/Python/3.7.11/x64/bin/python -m pip install --upgrade pip' command.</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class="-Color -Color-Yellow">WARNING: You are using pip version 21.2.2; however, version 21.2.3 is available.</span>
<span class="-Color -Color-Yellow">You should consider upgrading via the '/opt/hostedtoolcache/Python/3.7.11/x64/bin/python -m pip install --upgrade pip' command.</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">nltk</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision</span> <span class="k">as</span> <span class="nn">tv</span>
<span class="kn">import</span> <span class="nn">matplotlib.pylab</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">trange</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>

<span class="kn">from</span> <span class="nn">pytorch_pretrained_biggan</span> <span class="kn">import</span> <span class="n">BigGAN</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_biggan</span> <span class="kn">import</span> <span class="n">one_hot_from_names</span>
<span class="kn">from</span> <span class="nn">pytorch_pretrained_biggan</span> <span class="kn">import</span> <span class="n">truncated_noise_sample</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">'wordnet'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[nltk_data] Downloading package wordnet to /home/runner/nltk_data...
[nltk_data]   Unzipping corpora/wordnet.zip.
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interact</span><span class="p">,</span> <span class="n">IntSlider</span><span class="p">,</span> <span class="n">FloatSlider</span><span class="p">,</span> <span class="n">interact_manual</span><span class="p">,</span> <span class="n">fixed</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">FloatLogSlider</span><span class="p">,</span> <span class="n">HBox</span><span class="p">,</span> <span class="n">Layout</span><span class="p">,</span> <span class="n">VBox</span><span class="p">,</span> <span class="n">interactive</span><span class="p">,</span> <span class="n">Label</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">interactive_output</span><span class="p">,</span> <span class="n">Dropdown</span>

<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>

<span class="c1">#@title Helper functions</span>

<span class="k">def</span> <span class="nf">image_moments</span><span class="p">(</span><span class="n">image_batches</span><span class="p">,</span> <span class="n">n_batches</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Compute mean an covariance of all pixels from batches of images</span>
<span class="sd">  """</span>
  <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((),</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">n</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">im</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">image_batches</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">n_batches</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">desc</span><span class="o">=</span><span class="s1">'Computing pixel mean and covariance...'</span><span class="p">):</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">m1</span> <span class="o">=</span> <span class="n">m1</span> <span class="o">+</span> <span class="n">im</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">m2</span> <span class="o">=</span> <span class="n">m2</span> <span class="o">+</span> <span class="p">(</span><span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">im</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">+=</span> <span class="n">b</span>
  <span class="n">m1</span><span class="p">,</span> <span class="n">m2</span> <span class="o">=</span> <span class="n">m1</span><span class="o">/</span><span class="n">n</span><span class="p">,</span> <span class="n">m2</span><span class="o">/</span><span class="n">n</span>
  <span class="n">cov</span> <span class="o">=</span> <span class="n">m2</span> <span class="o">-</span> <span class="n">m1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">m1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">m1</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">cov</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">interpolate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">A</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">'A and B must have the same shape to interpolate.'</span><span class="p">)</span>
  <span class="n">alphas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="mi">1</span><span class="o">-</span><span class="n">a</span><span class="p">)</span><span class="o">*</span><span class="n">A</span> <span class="o">+</span> <span class="n">a</span><span class="o">*</span><span class="n">B</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">alphas</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">kl_q_p</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">phi</span><span class="p">):</span>
  <span class="sd">"""Given [b,n,k] samples of z drawn from q, compute estimate of KL(q||p).</span>
<span class="sd">  phi must be size [b,k+1]</span>

<span class="sd">  This uses mu_p = 0 and sigma_p = 1, which simplifies the log(p(zs)) term to</span>
<span class="sd">  just -1/2*(zs**2)</span>
<span class="sd">  """</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">mu_q</span><span class="p">,</span> <span class="n">log_sig_q</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="n">log_p</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">zs</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
  <span class="n">log_q</span> <span class="o">=</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="p">(</span><span class="n">zs</span> <span class="o">-</span> <span class="n">mu_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">log_sig_q</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">log_sig_q</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="c1"># Size of log_q and log_p is [b,n,k]. Sum along [k] but mean along [b,n]</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">log_q</span> <span class="o">-</span> <span class="n">log_p</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">log_p_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_xs</span><span class="p">,</span> <span class="n">sig_x</span><span class="p">):</span>
  <span class="sd">"""Given [batch, ...] input x and [batch, n, ...] reconstructions, compute</span>
<span class="sd">  pixel-wise log Gaussian probability</span>

<span class="sd">  Sum over pixel dimensions, but mean over batch and samples.</span>
<span class="sd">  """</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">n</span> <span class="o">=</span> <span class="n">mu_xs</span><span class="o">.</span><span class="n">size</span><span class="p">()[:</span><span class="mi">2</span><span class="p">]</span>
  <span class="c1"># Flatten out pixels and add a singleton dimension [1] so that x will be</span>
  <span class="c1"># implicitly expanded when combined with mu_xs</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">squared_error</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">mu_xs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">sig_x</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

  <span class="c1"># Size of squared_error is [b,n,p]. log prob is by definition sum over [p].</span>
  <span class="c1"># Expected value requires mean over [n]. Handling different size batches</span>
  <span class="c1"># requires mean over [b].</span>
  <span class="k">return</span> <span class="o">-</span><span class="p">(</span><span class="n">squared_error</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">sig_x</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Compute encoder and decoder matrices for PCA dimensionality reduction</span>
<span class="sd">  """</span>
  <span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">u</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">v</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">svd_lowrank</span><span class="p">(</span><span class="n">cov</span><span class="p">,</span> <span class="n">q</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
  <span class="n">W_encode</span> <span class="o">=</span> <span class="n">v</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
  <span class="n">W_decode</span> <span class="o">=</span> <span class="n">u</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">pca_encode</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c1"># Encoder: subtract mean image and project onto top K eigenvectors of</span>
    <span class="c1"># the data covariance</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="n">mu</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span> <span class="o">-</span> <span class="n">mu</span><span class="p">)</span> <span class="o">@</span> <span class="n">W_encode</span>

  <span class="k">def</span> <span class="nf">pca_decode</span><span class="p">(</span><span class="n">h</span><span class="p">):</span>
    <span class="c1"># Decoder: un-project then add back in the mean</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">h</span> <span class="o">@</span> <span class="n">W_decode</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span>

  <span class="k">return</span> <span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span>


<span class="k">def</span> <span class="nf">cout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">layer</span><span class="p">):</span>
  <span class="sd">"""Unnecessarily complicated but complete way to</span>
<span class="sd">  calculate the output depth, height and width size for a Conv2D layer</span>

<span class="sd">  Args:</span>
<span class="sd">    x (tuple): input size (depth, height, width)</span>
<span class="sd">    layer (nn.Conv2d): the Conv2D layer</span>

<span class="sd">  returns:</span>
<span class="sd">    (int): output shape as given in [Ref]</span>

<span class="sd">  Ref:</span>
<span class="sd">    https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html</span>
<span class="sd">  """</span>
  <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">)</span>
  <span class="n">p</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">padding</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">padding</span><span class="p">,)</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">kernel_size</span><span class="p">,)</span>
  <span class="n">d</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">dilation</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">dilation</span><span class="p">,)</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">stride</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)</span> <span class="k">else</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">stride</span><span class="p">,)</span>
  <span class="n">in_depth</span><span class="p">,</span> <span class="n">in_height</span><span class="p">,</span> <span class="n">in_width</span> <span class="o">=</span> <span class="n">x</span>
  <span class="n">out_depth</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">out_channels</span>
  <span class="n">out_height</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">in_height</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">s</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">out_width</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">in_width</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="p">(</span><span class="n">k</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">d</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">s</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">out_depth</span><span class="p">,</span> <span class="n">out_height</span><span class="p">,</span> <span class="n">out_width</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_gen_samples_ppca</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="n">therm_data_sim</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'c'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'training data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm_data_sim</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">therm_data_sim</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s1">'.'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'m'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'"generated" data'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'equal'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Thermometer 1 ($^\circ$C)'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Thermometer 2 ($^\circ$C)'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_linear_ae</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">()])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Training batch'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'MSE Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_conv_ae</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">,</span> <span class="n">conv_losses</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">conv_losses</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'Lin AE'</span><span class="p">,</span> <span class="s1">'Conv AE'</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Training batch'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'MSE Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span>
            <span class="mi">2</span><span class="o">*</span><span class="nb">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">conv_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span>
                  <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">lin_losses</span><span class="p">)</span><span class="o">.</span><span class="n">median</span><span class="p">())])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_images</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">plt_title</span><span class="o">=</span><span class="s1">''</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">w</span><span class="o">*</span><span class="mi">2</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="n">plt_title</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">1.03</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="n">w</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_phi</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">zs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">zs</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'.'</span><span class="p">)</span>
    <span class="n">th</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">6.28318</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">th</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">th</span><span class="p">)</span>
    <span class="c1"># Draw 2-sigma contours</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
        <span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
        <span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">*</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">+</span> <span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'equal'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">'If rsample() is correct, then most but not all points should lie in the circles'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span> <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
  <span class="n">c</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="k">if</span> <span class="n">c</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="s1">'gray'</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">cm</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="c1"># Torch images have shape (channels, height, width) but matplotlib expects</span>
  <span class="c1"># (height, width, channels) or just (height,width) when grayscale</span>
  <span class="n">im_plt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">im_plt</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">cm</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'right'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">spines</span><span class="p">[</span><span class="s1">'top'</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-generative-models">
<h1>Section 1: Generative models<a class="headerlink" href="#section-1-generative-models" title="Permalink to this headline">¶</a></h1>
<p><strong>Please</strong> run the cell after the video to download BigGAN (a generative model) and a few standard image datasets while the video plays.</p>
<div class="section" id="video-1-generative-modeling">
<h2>Video 1: Generative Modeling<a class="headerlink" href="#video-1-generative-modeling" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8250c6cc6f14495d975727203635e54e"}
</script></div>
</div>
<p>Download BigGAN (a generative model) and a few standard image datasets while the above video plays</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Download BigGAN (a generative model) and a few standard image datasets while the above video plays</span>

<span class="n">biggan_model</span> <span class="o">=</span> <span class="n">BigGAN</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s1">'biggan-deep-256'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/234411737 [00:00&lt;?, ?B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  2%|▏         | 4580352/234411737 [00:00&lt;00:05, 45803454.48B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  4%|▍         | 9160704/234411737 [00:00&lt;00:11, 18987131.70B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  7%|▋         | 15586304/234411737 [00:00&lt;00:07, 30682149.43B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  9%|▊         | 19976192/234411737 [00:00&lt;00:08, 24743792.55B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 11%|█         | 25510912/234411737 [00:00&lt;00:06, 31405555.64B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 13%|█▎        | 30889984/234411737 [00:00&lt;00:05, 36714803.97B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 16%|█▌        | 36369408/234411737 [00:01&lt;00:04, 41288424.27B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 18%|█▊        | 42065920/234411737 [00:01&lt;00:04, 45010358.83B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 21%|██        | 48615424/234411737 [00:01&lt;00:03, 50604041.43B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 23%|██▎       | 54146048/234411737 [00:01&lt;00:03, 50898016.45B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 25%|██▌       | 59561984/234411737 [00:01&lt;00:03, 47090327.71B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 28%|██▊       | 66066432/234411737 [00:01&lt;00:03, 51900891.40B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 31%|███       | 71511040/234411737 [00:01&lt;00:03, 47699940.19B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 33%|███▎      | 76509184/234411737 [00:01&lt;00:04, 38168791.23B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 35%|███▌      | 82716672/234411737 [00:02&lt;00:03, 43656098.18B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 37%|███▋      | 87549952/234411737 [00:02&lt;00:03, 42118780.03B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 39%|███▉      | 92259328/234411737 [00:02&lt;00:03, 40904180.70B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 42%|████▏     | 98031616/234411737 [00:02&lt;00:03, 45130426.82B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 44%|████▍     | 104014848/234411737 [00:02&lt;00:02, 49013857.39B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 47%|████▋     | 110214144/234411737 [00:02&lt;00:02, 52568550.74B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 50%|████▉     | 116673536/234411737 [00:02&lt;00:02, 55950914.59B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 52%|█████▏    | 122423296/234411737 [00:02&lt;00:02, 52425426.28B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 55%|█████▍    | 127812608/234411737 [00:02&lt;00:02, 46827790.95B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 57%|█████▋    | 134094848/234411737 [00:03&lt;00:01, 50966035.69B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 60%|█████▉    | 140457984/234411737 [00:03&lt;00:01, 54382399.76B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 63%|██████▎   | 146628608/234411737 [00:03&lt;00:01, 56418832.45B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 65%|██████▌   | 152412160/234411737 [00:03&lt;00:01, 56233607.12B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 68%|██████▊   | 158691328/234411737 [00:03&lt;00:01, 58111193.93B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 70%|███████   | 165170176/234411737 [00:03&lt;00:01, 60049544.91B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 73%|███████▎  | 171784192/234411737 [00:03&lt;00:01, 61835336.83B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 76%|███████▌  | 178354176/234411737 [00:03&lt;00:00, 62976153.61B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 79%|███████▉  | 184990720/234411737 [00:03&lt;00:00, 63981493.49B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 82%|████████▏ | 191675392/234411737 [00:03&lt;00:00, 64833124.26B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 85%|████████▍ | 198353920/234411737 [00:04&lt;00:00, 65411660.90B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 87%|████████▋ | 204990464/234411737 [00:04&lt;00:00, 65695263.17B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 90%|█████████ | 211645440/234411737 [00:04&lt;00:00, 65949102.37B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 93%|█████████▎| 218247168/234411737 [00:04&lt;00:00, 57355794.48B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 96%|█████████▌| 224638976/234411737 [00:04&lt;00:00, 59133549.53B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> 98%|█████████▊| 230714368/234411737 [00:04&lt;00:00, 40763843.87B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 234411737/234411737 [00:04&lt;00:00, 47939343.60B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  0%|          | 0/715 [00:00&lt;?, ?B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|██████████| 715/715 [00:00&lt;00:00, 794838.95B/s]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-1-generating-images-from-biggan">
<h2>Section 1.1: Generating Images from BigGAN<a class="headerlink" href="#section-1-1-generating-images-from-biggan" title="Permalink to this headline">¶</a></h2>
<p>To demonstrate the power of generative models, we are giving you a sneak peak of a fully trained generative model called BigGAN. You’ll see it again (with more background under your belt) later today. For now, let’s just focus on BigGAN as a generative model. Specifically, BigGAN is a class conditional generative model for 128 x 128 images. The classes are based on categorical labels that describe the images and images are generated based upon a vector (z from the video lecture) and the probability that the image comes from a specific discrete category.</p>
<p>For now, don’t worry about the specifics of the model other than the fact that it generates images based on the vector and the category label.</p>
<p>To explore the space of generated images, we’ve provided you with a widget that allows you to select a category label and to alter the value of the vector. The vector is a 128-D, which may seem high dimensional, but is much lower dimensional than a 128 x 128 image! To simplify usability the widget limits the magnitude of the vector and constrains all entries to be equal (so you are only exploring a subset of the possible images that can be generated).</p>
<div class="section" id="think-1-1-generated-images">
<h3>Think! 1.1: Generated images<a class="headerlink" href="#think-1-1-generated-images" title="Permalink to this headline">¶</a></h3>
<p>As you alter the magnitude of the vector, what do you note about the relationship between the different generated images? What do you note about the relationship between the image and the category label as you increase the magnitude of the vector?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span> --no-display
<span class="c1"># @markdown BigGAN Image Generator (the updates may take a few seconds)</span>

<span class="c1"># category = 'German shepherd' # @param ['tench', 'magpie', 'jellyfish', 'German shepherd', 'bee', 'acoustic guitar', 'coffee mug', 'minibus', 'monitor']</span>
<span class="c1"># z_magnitude = -16 # @param {type:"slider", min:-50, max:50, step:1}</span>

<span class="k">def</span> <span class="nf">sample_from_biggan</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">z_magnitude</span><span class="p">):</span>
  <span class="n">unit_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">z_magnitude</span> <span class="o">*</span> <span class="n">unit_vector</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

  <span class="c1"># Move to GPU</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>
  <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>
  <span class="n">biggan_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">set_device</span><span class="p">())</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">biggan_model</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Back to CPU</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>

  <span class="c1"># The output layer of BigGAN has a tanh layer, resulting the range of [-1, 1] for the output image</span>
  <span class="c1"># Therefore, we normalize the images properly to [0, 1] range.</span>
  <span class="c1"># Clipping is only in case of numerical instability problems</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(((</span><span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

<span class="n">z_slider</span> <span class="o">=</span> <span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">25</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                     <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                     <span class="n">description</span><span class="o">=</span><span class="s1">'Z Magnitude'</span><span class="p">,</span>
                     <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'440px'</span><span class="p">))</span>

<span class="n">category_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">'tench'</span><span class="p">,</span> <span class="s1">'magpie'</span><span class="p">,</span> <span class="s1">'jellyfish'</span><span class="p">,</span> <span class="s1">'German shepherd'</span><span class="p">,</span> <span class="s1">'bee'</span><span class="p">,</span>
             <span class="s1">'acoustic guitar'</span><span class="p">,</span> <span class="s1">'coffee mug'</span><span class="p">,</span> <span class="s1">'minibus'</span><span class="p">,</span> <span class="s1">'monitor'</span><span class="p">],</span>
             <span class="n">value</span><span class="o">=</span><span class="s2">"German shepherd"</span><span class="p">,</span>
             <span class="n">description</span><span class="o">=</span><span class="s2">"Category: "</span><span class="p">)</span>

<span class="n">widgets_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">category_dropdown</span><span class="p">,</span> <span class="n">z_slider</span><span class="p">])</span>

<span class="n">widgets_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">sample_from_biggan</span><span class="p">,</span>
                                 <span class="p">{</span>
                                     <span class="s1">'z_magnitude'</span><span class="p">:</span> <span class="n">z_slider</span><span class="p">,</span>
                                  <span class="s1">'category'</span><span class="p">:</span> <span class="n">category_dropdown</span>
                                  <span class="p">}</span>
                                 <span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets_ui</span><span class="p">,</span> <span class="n">widgets_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "735edccd840740c6bac87698b1ed16e5"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6858a83eb59b4ea7b28a2f9f7f9ceda7"}
</script><img alt="../../../_images/W2D5_Tutorial1_32_2.png" src="../../../_images/W2D5_Tutorial1_32_2.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="section-1-2-interpolating-images-with-biggan">
<h2>Section 1.2: Interpolating Images with BigGAN<a class="headerlink" href="#section-1-2-interpolating-images-with-biggan" title="Permalink to this headline">¶</a></h2>
<p>This next widget allows you to interpolate between two generated images. It does this by linearly interpolating between the probability of each category you select and linearly interpolating between the latent vector values.</p>
<div class="section" id="think-1-2-interpolating-samples-from-the-same-category">
<h3>Think! 1.2: Interpolating samples from the same category<a class="headerlink" href="#think-1-2-interpolating-samples-from-the-same-category" title="Permalink to this headline">¶</a></h3>
<p>Try interpolating between samples from the same category, samples from similar categories, and samples from very different categories. Do you notice any trends? What does this suggest about the representations of images in the latent space?</p>
<p>BigGAN Interpolation Widget (the updates may take a few seconds)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown BigGAN Interpolation Widget (the updates may take a few seconds)</span>

<span class="k">def</span> <span class="nf">interpolate_biggan</span><span class="p">(</span><span class="n">category_A</span><span class="p">,</span> <span class="n">z_magnitude_A</span><span class="p">,</span> <span class="n">category_B</span><span class="p">,</span> <span class="n">z_magnitude_B</span><span class="p">):</span>
  <span class="n">num_interps</span> <span class="o">=</span> <span class="mi">16</span>

  <span class="c1"># category_A = 'jellyfish' #@param ['tench', 'magpie', 'jellyfish', 'German shepherd', 'bee', 'acoustic guitar', 'coffee mug', 'minibus', 'monitor']</span>
  <span class="c1"># z_magnitude_A = 0 #@param {type:"slider", min:-10, max:10, step:1}</span>

  <span class="c1"># category_B = 'German shepherd' #@param ['tench', 'magpie', 'jellyfish', 'German shepherd', 'bee', 'acoustic guitar', 'coffee mug', 'minibus', 'monitor']</span>
  <span class="c1"># z_magnitude_B = 0 #@param {type:"slider", min:-10, max:10, step:1}</span>


  <span class="k">def</span> <span class="nf">interpolate_and_shape</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">):</span>
    <span class="n">interps</span> <span class="o">=</span> <span class="n">interpolate</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">interps</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">*</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">interps</span><span class="o">.</span><span class="n">shape</span><span class="p">)))</span>
                  <span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_interps</span><span class="p">,</span> <span class="o">*</span><span class="n">interps</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">:]))</span>

  <span class="n">unit_vector</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">))</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">128</span><span class="p">)</span>
  <span class="n">z_A</span> <span class="o">=</span> <span class="n">z_magnitude_A</span> <span class="o">*</span> <span class="n">unit_vector</span>
  <span class="n">z_B</span> <span class="o">=</span> <span class="n">z_magnitude_B</span> <span class="o">*</span> <span class="n">unit_vector</span>
  <span class="n">y_A</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category_A</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">y_B</span> <span class="o">=</span> <span class="n">one_hot_from_names</span><span class="p">(</span><span class="n">category_B</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">interpolate_and_shape</span><span class="p">(</span><span class="n">z_A</span><span class="p">,</span> <span class="n">z_B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">interpolate_and_shape</span><span class="p">(</span><span class="n">y_A</span><span class="p">,</span> <span class="n">y_B</span><span class="p">,</span> <span class="n">num_interps</span><span class="p">)</span>

  <span class="c1"># Convert to tensor</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">z_interp</span><span class="p">)</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">z_interp</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">y_interp</span><span class="p">)</span>

  <span class="c1"># Move to GPU</span>
  <span class="n">z_interp</span> <span class="o">=</span> <span class="n">z_interp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">y_interp</span> <span class="o">=</span> <span class="n">y_interp</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">biggan_model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">biggan_model</span><span class="p">(</span><span class="n">z_interp</span><span class="p">,</span> <span class="n">y_interp</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="c1"># Back to CPU</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>

  <span class="c1"># The output layer of BigGAN has a tanh layer, resulting the range of [-1, 1] for the output image</span>
  <span class="c1"># Therefore, we normalize the images properly to [0, 1] range.</span>
  <span class="c1"># Clipping is only in case of numerical instability problems</span>

  <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clip</span><span class="p">(((</span><span class="n">output</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">),</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">output</span> <span class="o">=</span> <span class="n">output</span>

  <span class="c1"># Make grid and show generated samples</span>
  <span class="n">output_grid</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">output</span><span class="p">,</span>
                                  <span class="n">nrow</span><span class="o">=</span><span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span>
                                  <span class="n">padding</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">);</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">output_grid</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="n">z_A_slider</span> <span class="o">=</span> <span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'Z Magnitude A'</span><span class="p">,</span>
                        <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'440px'</span><span class="p">),</span> <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">})</span>

<span class="n">z_B_slider</span> <span class="o">=</span> <span class="n">IntSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">10</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                        <span class="n">continuous_update</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">'Z Magntude B'</span><span class="p">,</span>
                        <span class="n">layout</span><span class="o">=</span><span class="n">Layout</span><span class="p">(</span><span class="n">width</span><span class="o">=</span><span class="s1">'440px'</span><span class="p">),</span> <span class="n">style</span><span class="o">=</span><span class="p">{</span><span class="s1">'description_width'</span><span class="p">:</span> <span class="s1">'initial'</span><span class="p">})</span>

<span class="n">category_A_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">'tench'</span><span class="p">,</span> <span class="s1">'magpie'</span><span class="p">,</span> <span class="s1">'jellyfish'</span><span class="p">,</span> <span class="s1">'German shepherd'</span><span class="p">,</span> <span class="s1">'bee'</span><span class="p">,</span>
             <span class="s1">'acoustic guitar'</span><span class="p">,</span> <span class="s1">'coffee mug'</span><span class="p">,</span> <span class="s1">'minibus'</span><span class="p">,</span> <span class="s1">'monitor'</span><span class="p">],</span>
                      <span class="n">value</span><span class="o">=</span><span class="s2">"German shepherd"</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"Category A: "</span><span class="p">)</span>

<span class="n">category_B_dropdown</span> <span class="o">=</span> <span class="n">Dropdown</span><span class="p">(</span>
    <span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s1">'tench'</span><span class="p">,</span> <span class="s1">'magpie'</span><span class="p">,</span> <span class="s1">'jellyfish'</span><span class="p">,</span> <span class="s1">'German shepherd'</span><span class="p">,</span> <span class="s1">'bee'</span><span class="p">,</span>
             <span class="s1">'acoustic guitar'</span><span class="p">,</span> <span class="s1">'coffee mug'</span><span class="p">,</span> <span class="s1">'minibus'</span><span class="p">,</span> <span class="s1">'monitor'</span><span class="p">],</span>
                      <span class="n">value</span><span class="o">=</span><span class="s2">"jellyfish"</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">"Category B: "</span><span class="p">)</span>



<span class="n">widgets_ui</span> <span class="o">=</span> <span class="n">VBox</span><span class="p">([</span><span class="n">HBox</span><span class="p">([</span><span class="n">category_A_dropdown</span><span class="p">,</span> <span class="n">z_A_slider</span><span class="p">]),</span>
                   <span class="n">HBox</span><span class="p">([</span><span class="n">category_B_dropdown</span><span class="p">,</span> <span class="n">z_B_slider</span><span class="p">])])</span>

<span class="n">widgets_out</span> <span class="o">=</span> <span class="n">interactive_output</span><span class="p">(</span><span class="n">interpolate_biggan</span><span class="p">,</span>
                                 <span class="p">{</span><span class="s1">'category_A'</span><span class="p">:</span> <span class="n">category_A_dropdown</span><span class="p">,</span>
                                  <span class="s1">'z_magnitude_A'</span><span class="p">:</span> <span class="n">z_A_slider</span><span class="p">,</span>
                                  <span class="s1">'category_B'</span><span class="p">:</span> <span class="n">category_B_dropdown</span><span class="p">,</span>
                                  <span class="s1">'z_magnitude_B'</span><span class="p">:</span> <span class="n">z_B_slider</span><span class="p">})</span>

<span class="n">display</span><span class="p">(</span><span class="n">widgets_ui</span><span class="p">,</span> <span class="n">widgets_out</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4d30e73f4b304b21a30fc70d50738db0"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "b8b7edce0bc8436692e259bbb0270829"}
</script></div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-latent-variable-models">
<h1>Section 2: Latent Variable Models<a class="headerlink" href="#section-2-latent-variable-models" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-2-latent-variable-models">
<h2>Video 2: Latent Variable Models<a class="headerlink" href="#video-2-latent-variable-models" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "097dcf46b0ca48d9b1c0509d7235657f"}
</script></div>
</div>
<p>In the video the concept of a latent variable model was introduced. We saw how PCA (principal component analysis) can be extended into a generative model with latent variables called pPCA. For pPCA the latent variables (z in the video) are the projections onto the principal component axes.</p>
<p>The dimensionality of the principal components is typically set to be substantially lower dimensional than the original data. Thus, the latent variables (the projection onto the principal component axes) are a lower dimensional representation of the original data (dimensionality reduction!). With pPCA we can estimate the original distribution of the high dimensional data. This allows us to generate data with a distribution that “looks” more like the original data than if we were to only use PCA to generate data from the latent variables.</p>
<p>Let’s see how that might look with a simple example. Assume we have two noisy thermometers measuring the temperature of the same room. They both make noisy measurements.  The room tends to be around 25°C (that’s 77°F), but can vary around that temperature.  If we take lots of readings from the two thermometers over time and plot the paired readings, we might see something like the plot generated below:</p>
<p>Generate example datapoints from the two thermometers</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Generate example datapoints from the two thermometers</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">mean_of_temps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">]</span>
<span class="n">cov_of_temps</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]]</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean_of_temps</span><span class="p">,</span>
                                               <span class="n">cov_of_temps</span><span class="p">,</span>
                                               <span class="n">n_samples</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Thermometer 1 ($^\circ$C)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Thermometer 2 ($^\circ$C)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
<img alt="../../../_images/W2D5_Tutorial1_42_1.png" src="../../../_images/W2D5_Tutorial1_42_1.png"/>
</div>
</div>
<p>Let’s model these data with a single principal component. Given that the thermometers are measuring the same actual temperature, the principal component axes will be the identity line. The direction of this axes can be indicated by the unit vector [1 1]/sqrt(2).  We could estimate this axes by applying PCA. We can plot this axes, it tells us something about the data, but we can’t generate from it:</p>
<p>Add first PC axes to the plot</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Add first PC axes to the plot</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">,</span> <span class="s1">'.'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'equal'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Thermometer 1 ($^\circ$C)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Thermometer 2 ($^\circ$C)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">1</span><span class="p">]],</span>
         <span class="p">[</span><span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">()[</span><span class="mi">1</span><span class="p">]])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W2D5_Tutorial1_45_0.png" src="../../../_images/W2D5_Tutorial1_45_0.png"/>
</div>
</div>
</div>
<div class="section" id="coding-exercise-2-ppca">
<h2>Coding Exercise 2: pPCA<a class="headerlink" href="#coding-exercise-2-ppca" title="Permalink to this headline">¶</a></h2>
<p><strong>Step 1:</strong> Calculate the parameters of the pPCA model</p>
<p>This part is completed already, so you don’t need to make any edits:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Project Data onto the principal component axes.</span>
<span class="c1"># We could have "learned" this from the data by applying PCA,</span>
<span class="c1"># but we "know" the value from the problem definition.</span>
<span class="n">pc_axes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span><span class="p">)</span>

<span class="c1"># thermometers data</span>
<span class="n">therm_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">therm1</span><span class="p">,</span> <span class="n">therm2</span><span class="p">])</span>

<span class="c1"># Zero center the data</span>
<span class="n">therm_data_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">therm_data</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">therm_data_center</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">therm_data_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">therm_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">therm_data_zero_centered</span> <span class="o">=</span> <span class="n">therm_data</span> <span class="o">-</span> <span class="n">therm_data_center</span>

<span class="c1"># Calculate the variance of the projection on the PC axes</span>
<span class="n">pc_projection</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">pc_axes</span><span class="p">,</span> <span class="n">therm_data_zero_centered</span><span class="p">);</span>
<span class="n">pc_axes_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">pc_projection</span><span class="p">)</span>

<span class="c1"># Calculate the residual variance (variance not accounted for by projection on the PC axes)</span>
<span class="n">sensor_noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">therm_data_zero_centered</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">pc_axes</span><span class="p">,</span> <span class="n">pc_projection</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">ord</span><span class="o">=</span><span class="mi">2</span><span class="p">))</span>
<span class="n">sensor_noise_var</span> <span class="o">=</span> <span class="n">sensor_noise_std</span> <span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Step 2</strong>: “Generate” from the pPCA model of the thermometer data.</p>
<p>Complete the code so it properly generates from the pPCA model. At present we aren’t accounting for the “sensor noise” the sensor noise is the variance that the PC axes isn’t accounting for. Thus, you’ll note that the current output sits on the PC axes and doesn’t look like the original data distribution!!</p>
<p>Here is the equation for sampling from the pPCA model:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9b39d733-13e2-4584-a808-cfca73a3beb4">
<span class="eqno">(83)<a class="headerlink" href="#equation-9b39d733-13e2-4584-a808-cfca73a3beb4" title="Permalink to this equation">¶</a></span>\[\begin{equation}
x = \mu + W z + \epsilon, ~~~~ where~~ \epsilon \sim \mathcal{N}(0,~\sigma^2 \mathbf{I})
\end{equation}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gen_from_pPCA</span><span class="p">(</span><span class="n">noise_var</span><span class="p">,</span> <span class="n">data_mean</span><span class="p">,</span> <span class="n">pc_axes</span><span class="p">,</span> <span class="n">pc_variance</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Args:</span>
<span class="sd">    noise_var (np.ndarray): sensor noise variance</span>
<span class="sd">    data_mean (np.ndarray): thermometer data mean</span>
<span class="sd">    pc_axes (np.ndarray): principal component axes</span>
<span class="sd">    pc_variance (np.ndarray): the variance of the projection on the PC axes</span>
<span class="sd">  """</span>
  <span class="c1"># We are matching this value to the thermometer data so the visualizations look similar</span>
  <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>

  <span class="c1"># Randomly sample from z (latent space value)</span>
  <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">pc_variance</span><span class="p">),</span> <span class="n">n_samples</span><span class="p">)</span>

  <span class="c1"># sensor noise covariance matrix (∑)</span>
  <span class="n">epsilon_cov</span> <span class="o">=</span> <span class="p">[[</span><span class="n">noise_var</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">noise_var</span><span class="p">]]</span>

  <span class="c1"># data mean reshaped for the generation</span>
  <span class="n">sim_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">data_mean</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span><span class="p">))</span>

  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in all missing code below (...),</span>
  <span class="c1"># then remove or comment the line below to test your class</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the `gen_from_pPCA` function"</span><span class="p">)</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># draw `n_samples` from `np.random.multivariate_normal`</span>
  <span class="n">rand_eps</span> <span class="o">=</span> <span class="o">...</span>
  <span class="n">rand_eps</span> <span class="o">=</span> <span class="n">rand_eps</span><span class="o">.</span><span class="n">T</span>

  <span class="c1"># generate (simulate, draw) `n_samples` from pPCA model</span>
  <span class="n">therm_data_sim</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">return</span> <span class="n">therm_data_sim</span>


<span class="c1">## Uncomment to test your code</span>
<span class="c1"># therm_data_sim = gen_from_pPCA(sensor_noise_var, therm_data_mean, pc_axes, pc_axes_variance)</span>
<span class="c1"># plot_gen_samples_ppca(therm1, therm2, therm_data_sim)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial1_Solution_747de28e.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_747de28e_0.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_747de28e_0.png" style="width: 1120.0px; height: 832.0px;"/></a>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-autoencoders">
<h1>Section 3: Autoencoders<a class="headerlink" href="#section-3-autoencoders" title="Permalink to this headline">¶</a></h1>
<p><strong>Please</strong> run the cell after the video to download MNIST and CIFAR10 image datasets while the video plays.</p>
<div class="section" id="video-3-autoenconders">
<h2>Video 3: Autoenconders<a class="headerlink" href="#video-3-autoenconders" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "ebaa477331704bdcab23c0189e6fbd34"}
</script></div>
</div>
<p>Download MNIST and CIFAR10 image datasets while the above video plays</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Download MNIST and CIFAR10 image datasets while the above video plays</span>
<span class="c1"># See https://pytorch.org/docs/stable/torchvision/datasets.html</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>

<span class="c1"># MNIST contains handwritten digets 0-9, in grayscale images of size (1,28,28)</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'./mnist/'</span><span class="p">,</span>
                          <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">transform</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                          <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnist_val</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'./mnist/'</span><span class="p">,</span>
                              <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                              <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">cifar10</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s1">'./cifar10/'</span><span class="p">,</span>
                              <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                              <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">cifar10_val</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="s1">'./cifar10/'</span><span class="p">,</span>
                                  <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                  <span class="n">transform</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                  <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./mnist/MNIST/raw/train-images-idx3-ubyte.gz
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "13546c7a97d745d7abd3cc04cadcc32a"}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_10452</span><span class="o">/</span><span class="mf">599051573.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>                           <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>                           <span class="n">transform</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
<span class="ne">----&gt; </span><span class="mi">9</span>                           <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span> <span class="n">mnist_val</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="s1">'./mnist/'</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>                               <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/mnist.py</span> in <span class="ni">__init__</span><span class="nt">(self, root, train, transform, target_transform, download)</span>
<span class="g g-Whitespace">     </span><span class="mi">85</span> 
<span class="g g-Whitespace">     </span><span class="mi">86</span>         <span class="k">if</span> <span class="n">download</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">87</span>             <span class="bp">self</span><span class="o">.</span><span class="n">download</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">88</span> 
<span class="g g-Whitespace">     </span><span class="mi">89</span>         <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_check_exists</span><span class="p">():</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/mnist.py</span> in <span class="ni">download</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">177</span>                         <span class="n">url</span><span class="p">,</span> <span class="n">download_root</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">raw_folder</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">178</span>                         <span class="n">filename</span><span class="o">=</span><span class="n">filename</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">179</span>                         <span class="n">md5</span><span class="o">=</span><span class="n">md5</span>
<span class="g g-Whitespace">    </span><span class="mi">180</span>                     <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">181</span>                 <span class="k">except</span> <span class="n">URLError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/utils.py</span> in <span class="ni">download_and_extract_archive</span><span class="nt">(url, download_root, extract_root, filename, md5, remove_finished)</span>
<span class="g g-Whitespace">    </span><span class="mi">411</span>         <span class="n">filename</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">412</span> 
<span class="ne">--&gt; </span><span class="mi">413</span>     <span class="n">download_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">download_root</span><span class="p">,</span> <span class="n">filename</span><span class="p">,</span> <span class="n">md5</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">414</span> 
<span class="g g-Whitespace">    </span><span class="mi">415</span>     <span class="n">archive</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">download_root</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/utils.py</span> in <span class="ni">download_url</span><span class="nt">(url, root, filename, md5, max_redirect_hops)</span>
<span class="g g-Whitespace">    </span><span class="mi">137</span>         <span class="k">try</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">138</span>             <span class="nb">print</span><span class="p">(</span><span class="s1">'Downloading '</span> <span class="o">+</span> <span class="n">url</span> <span class="o">+</span> <span class="s1">' to '</span> <span class="o">+</span> <span class="n">fpath</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">139</span>             <span class="n">_urlretrieve</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">fpath</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">140</span>         <span class="k">except</span> <span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">error</span><span class="o">.</span><span class="n">URLError</span><span class="p">,</span> <span class="ne">IOError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>  <span class="c1"># type: ignore[attr-defined]</span>
<span class="g g-Whitespace">    </span><span class="mi">141</span>             <span class="k">if</span> <span class="n">url</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span> <span class="o">==</span> <span class="s1">'https'</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/utils.py</span> in <span class="ni">_urlretrieve</span><span class="nt">(url, filename, chunk_size)</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span>         <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">"User-Agent"</span><span class="p">:</span> <span class="n">USER_AGENT</span><span class="p">}))</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">32</span>             <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">length</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">33</span>                 <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">),</span> <span class="s2">""</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span>                     <span class="k">if</span> <span class="ow">not</span> <span class="n">chunk</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span>                         <span class="k">break</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torchvision/datasets/utils.py</span> in <span class="ni">&lt;lambda&gt;</span><span class="nt">()</span>
<span class="g g-Whitespace">     </span><span class="mi">31</span>         <span class="k">with</span> <span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">urlopen</span><span class="p">(</span><span class="n">urllib</span><span class="o">.</span><span class="n">request</span><span class="o">.</span><span class="n">Request</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="p">{</span><span class="s2">"User-Agent"</span><span class="p">:</span> <span class="n">USER_AGENT</span><span class="p">}))</span> <span class="k">as</span> <span class="n">response</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">32</span>             <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">response</span><span class="o">.</span><span class="n">length</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">33</span>                 <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="nb">iter</span><span class="p">(</span><span class="k">lambda</span><span class="p">:</span> <span class="n">response</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">chunk_size</span><span class="p">),</span> <span class="s2">""</span><span class="p">):</span>
<span class="g g-Whitespace">     </span><span class="mi">34</span>                     <span class="k">if</span> <span class="ow">not</span> <span class="n">chunk</span><span class="p">:</span>
<span class="g g-Whitespace">     </span><span class="mi">35</span>                         <span class="k">break</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py</span> in <span class="ni">read</span><span class="nt">(self, amt)</span>
<span class="g g-Whitespace">    </span><span class="mi">463</span>             <span class="c1"># Amount is given, implement using readinto</span>
<span class="g g-Whitespace">    </span><span class="mi">464</span>             <span class="n">b</span> <span class="o">=</span> <span class="nb">bytearray</span><span class="p">(</span><span class="n">amt</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">465</span>             <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">readinto</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">466</span>             <span class="k">return</span> <span class="nb">memoryview</span><span class="p">(</span><span class="n">b</span><span class="p">)[:</span><span class="n">n</span><span class="p">]</span><span class="o">.</span><span class="n">tobytes</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">467</span>         <span class="k">else</span><span class="p">:</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/http/client.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">507</span>         <span class="c1"># connection, and the user is reading more bytes than will be provided</span>
<span class="g g-Whitespace">    </span><span class="mi">508</span>         <span class="c1"># (for example, reading in 1k chunks)</span>
<span class="ne">--&gt; </span><span class="mi">509</span>         <span class="n">n</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fp</span><span class="o">.</span><span class="n">readinto</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">510</span>         <span class="k">if</span> <span class="ow">not</span> <span class="n">n</span> <span class="ow">and</span> <span class="n">b</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">511</span>             <span class="c1"># Ideally, we would raise IncompleteRead if the content-length</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/socket.py</span> in <span class="ni">readinto</span><span class="nt">(self, b)</span>
<span class="g g-Whitespace">    </span><span class="mi">587</span>         <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">588</span>             <span class="k">try</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">589</span>                 <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sock</span><span class="o">.</span><span class="n">recv_into</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">590</span>             <span class="k">except</span> <span class="n">timeout</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">591</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_timeout_occurred</span> <span class="o">=</span> <span class="kc">True</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="section" id="select-a-dataset">
<h3>Select a dataset<a class="headerlink" href="#select-a-dataset" title="Permalink to this headline">¶</a></h3>
<p>We’ve built today’s tutorial to be flexible. It should work more-or-less out of the box with both MNIST and CIFAR (and other image datasets). MNIST is in many ways simpler, and the results will likely look better and run a bit faster if using MNIST. But we are leaving it up to you to pick which one you want to experiment with!</p>
<p>We encourage pods to coordinate so that some members use MNIST and others use CIFAR10. Keep in mind that the CIFAR dataset may require more learning epochs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'mnist'</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">'mnist'</span><span class="p">:</span>
    <span class="n">my_dataset_name</span> <span class="o">=</span> <span class="s2">"MNIST"</span>
    <span class="n">my_dataset</span> <span class="o">=</span> <span class="n">mnist</span>
    <span class="n">my_valset</span> <span class="o">=</span> <span class="n">mnist_val</span>
    <span class="n">my_dataset_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>
    <span class="n">my_dataset_size</span> <span class="o">=</span> <span class="mi">28</span> <span class="o">*</span> <span class="mi">28</span>
  <span class="k">elif</span> <span class="n">name</span> <span class="o">==</span> <span class="s1">'cifar10'</span><span class="p">:</span>
    <span class="n">my_dataset_name</span> <span class="o">=</span> <span class="s2">"CIFAR10"</span>
    <span class="n">my_dataset</span> <span class="o">=</span> <span class="n">cifar10</span>
    <span class="n">my_valset</span> <span class="o">=</span> <span class="n">cifar10_val</span>
    <span class="n">my_dataset_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">my_dataset_size</span> <span class="o">=</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">32</span> <span class="o">*</span> <span class="mi">32</span>

  <span class="k">return</span> <span class="n">my_dataset</span><span class="p">,</span> <span class="n">my_dataset_name</span><span class="p">,</span> <span class="n">my_dataset_shape</span><span class="p">,</span> <span class="n">my_dataset_size</span><span class="p">,</span> <span class="n">my_valset</span>


<span class="n">train_set</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">,</span> <span class="n">data_size</span><span class="p">,</span> <span class="n">valid_set</span> <span class="o">=</span> <span class="n">get_data</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s1">'mnist'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="section-3-1-conceptual-introduction-to-autoencoders">
<h2>Section 3.1: Conceptual introduction to AutoEncoders<a class="headerlink" href="#section-3-1-conceptual-introduction-to-autoencoders" title="Permalink to this headline">¶</a></h2>
<p>Now we’ll create our first autoencoder. It will reduce images down to <span class="math notranslate nohighlight">\(K\)</span> dimensions. The architecture will be quite simple: the input will be linearly mapped to a single hidden (or latent) layer <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> with <span class="math notranslate nohighlight">\(K\)</span> units, which will then be linearly mapped back to an output that is the same size as the input:</p>
<div class="amsmath math notranslate nohighlight" id="equation-1db82793-9e3e-4d93-801c-7b1323c73539">
<span class="eqno">(84)<a class="headerlink" href="#equation-1db82793-9e3e-4d93-801c-7b1323c73539" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{x} \longrightarrow \mathbf{h} \longrightarrow \mathbf{x'}
\end{equation}\]</div>
<p>The loss function we’ll use will simply be mean squared error (MSE) quantifying how well the reconstruction (<span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>) matches the original image (<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-9219743c-66fc-46a5-a693-fac7733d1a65">
<span class="eqno">(85)<a class="headerlink" href="#equation-9219743c-66fc-46a5-a693-fac7733d1a65" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\text{MSE Loss} = \sum_{i=1}^{N} ||\mathbf{x}_i - \mathbf{x'}_i||^2_2
\end{equation}\]</div>
<p>If all goes well, then the AutoEncoder will learn, <strong>end to end</strong>, a good “encoding” or “compression” of inputs to a latent representation (<span class="math notranslate nohighlight">\(\mathbf{x \longrightarrow h}\)</span>) as well as a good “decoding” of that latent representation to a reconstruction of the original input (<span class="math notranslate nohighlight">\(\mathbf{h \longrightarrow x'}\)</span>).</p>
<p>The first choice to make is the dimensionality of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>. We’ll see more on this below, but For MNIST, 5 to 20 is plenty. For CIFAR, we need more like 50 to 100 dimensions.</p>
<p>Coordinate with your pod to try a variety of values for <span class="math notranslate nohighlight">\(K\)</span> in each dataset so you can compare results.</p>
<div class="section" id="coding-exercise-3-1-linear-autoencoder-architecture">
<h3>Coding Exercise 3.1: Linear AutoEncoder Architecture<a class="headerlink" href="#coding-exercise-3-1-linear-autoencoder-architecture" title="Permalink to this headline">¶</a></h3>
<p>Complete the missing parts of the <code class="docutils literal notranslate"><span class="pre">LinearAutoEncoder</span></code> class.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">LinearAutoEncoder</span></code> as two stages: an <code class="docutils literal notranslate"><span class="pre">encoder</span></code> which linearly maps from inputs of size <code class="docutils literal notranslate"><span class="pre">x_dim</span> <span class="pre">=</span> <span class="pre">my_dataset_dim</span></code> to a hidden layer of size <code class="docutils literal notranslate"><span class="pre">h_dim</span> <span class="pre">=</span> <span class="pre">K</span></code> (with no nonlinearity), and a <code class="docutils literal notranslate"><span class="pre">decoder</span></code> which maps back from <code class="docutils literal notranslate"><span class="pre">K</span></code> up to the number of pixels in each image.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown #### Run to define the `train_autoencoder` function.</span>
<span class="c1"># @markdown Feel free to inspect the training function if the time allows.</span>
<span class="c1"># @markdown `train_autoencoder(autoencoder, dataset, device, epochs=20, batch_size=250, seed=0)`</span>


<span class="k">def</span> <span class="nf">train_autoencoder</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
                      <span class="n">seed</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
  <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">optim</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">autoencoder</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span>
                           <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
                           <span class="n">weight_decay</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
  <span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span>
                      <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                      <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                      <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                      <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                      <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="n">mse_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">epochs</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
  <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Epoch'</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">im_batch</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
      <span class="n">im_batch</span> <span class="o">=</span> <span class="n">im_batch</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">optim</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">autoencoder</span><span class="p">(</span><span class="n">im_batch</span><span class="p">)</span>
      <span class="c1"># write the loss calculation</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">reconstruction</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                     <span class="n">target</span><span class="o">=</span><span class="n">im_batch</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="n">mse_loss</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
      <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="c1"># After training completes, make sure the model is on CPU so we can easily</span>
  <span class="c1"># do more visualizations and demos.</span>
  <span class="n">autoencoder</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mse_loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">LinearAutoEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">):</span>
    <span class="sd">"""A Linear AutoEncoder</span>

<span class="sd">    Args:</span>
<span class="sd">      x_dim (int): input dimension</span>
<span class="sd">      h_dim (int): hidden dimension, bottleneck dimension, K</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your class</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the LinearAutoEncoder class!"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># encoder layer (a linear mapping from x_dim to K)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span> <span class="o">=</span> <span class="o">...</span>
    <span class="c1"># decoder layer (a linear mapping from K to x_dim)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span> <span class="o">=</span> <span class="o">...</span>

  <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the `encode` function!"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">h</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">h</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the `decode` function!"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="n">x_prime</span> <span class="o">=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">x_prime</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">flat_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">flat_x</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">h</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>


<span class="c1"># Pick your own K</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your code</span>
<span class="c1"># lin_ae = LinearAutoEncoder(data_size, K)</span>
<span class="c1"># lin_losses = train_autoencoder(lin_ae, train_set, device=DEVICE, seed=SEED)</span>
<span class="c1"># plot_linear_ae(lin_losses)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial1_Solution_cebd6833.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_cebd6833_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_cebd6833_3.png" style="width: 1119.0px; height: 832.0px;"/></a>
</div>
<div class="section" id="comparison-to-pca">
<h3>Comparison to PCA<a class="headerlink" href="#comparison-to-pca" title="Permalink to this headline">¶</a></h3>
<p>One way to think about AutoEncoders is as a form of dimensionality-reduction. The dimensionality of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is much smaller than the dimensionality of <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>Another common technique for dimensionality reduction is to project data onto the top <span class="math notranslate nohighlight">\(K\)</span> <strong>principal components</strong> (Principal Component Analysis or PCA). For comparison, let’s also apply PCA for dimensionality reduction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PCA requires finding the top K eigenvectors of the data covariance. Start by</span>
<span class="c1"># finding the mean and covariance of the pixels in our dataset</span>
<span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
                    <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                    <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

<span class="n">mu</span><span class="p">,</span> <span class="n">cov</span> <span class="o">=</span> <span class="n">image_moments</span><span class="p">((</span><span class="n">im</span> <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">),</span>
                        <span class="n">n_batches</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span> <span class="o">//</span> <span class="mi">32</span><span class="p">)</span>

<span class="n">pca_encode</span><span class="p">,</span> <span class="n">pca_decode</span> <span class="o">=</span> <span class="n">pca_encoder_decoder</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">cov</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize some of the reconstructions (<span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>) side-by-side with the input images (<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>).</p>
<p>Visualize the reconstructions <span class="math notranslate nohighlight">\(\mathbf{x}'\)</span>, run this code a few times to see different examples.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Visualize the reconstructions $\mathbf{x}'$, run this code a few times to see different examples.</span>

<span class="n">n_plot</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_plot</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">())</span>
  <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
  <span class="c1"># Get reconstructed image from autoencoder</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">reconstruction</span> <span class="o">=</span> <span class="n">lin_ae</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="c1"># Get reconstruction from PCA dimensionality reduction</span>
  <span class="n">h_pca</span> <span class="o">=</span> <span class="n">pca_encode</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="n">recon_pca</span> <span class="o">=</span> <span class="n">pca_decode</span><span class="p">(</span><span class="n">h_pca</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Original</span><span class="se">\n</span><span class="s1">Image'</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">reconstruction</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Lin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">recon_pca</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">'PCA</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="think-3-1-pca-vs-linear-autoenconder">
<h3>Think! 3.1: PCA vs. Linear autoenconder<a class="headerlink" href="#think-3-1-pca-vs-linear-autoenconder" title="Permalink to this headline">¶</a></h3>
<p>Compare the PCA-based reconstructions to those from the linear autoencoder. Is one better than the other? Are they equally good? Equally bad? How does the choice of <span class="math notranslate nohighlight">\(K\)</span> impact reconstruction quality?</p>
</div>
</div>
<div class="section" id="section-3-2-building-a-nonlinear-convolutional-autoencoder">
<h2>Section 3.2: Building a nonlinear convolutional autoencoder<a class="headerlink" href="#section-3-2-building-a-nonlinear-convolutional-autoencoder" title="Permalink to this headline">¶</a></h2>
<p><strong>Nonlinear:</strong> We’d like to apply autoencoders to learn a more flexible nonlinear mapping between the latent space and the images. Such a mapping can provide a more “expressive” model that better describes the image data than a linear mapping. This can be achieved by adding nonlinear activation functions to our encoder and decoder!</p>
<p><strong>Convolutional:</strong> As you saw on the day dedicated to RNNs and CNNs, parameter sharing is often a good idea for images! It’s quite common to use convolutional layers in autoencoders to share parameters across locations in the image.</p>
<p><strong>Side Note:</strong> The <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layer (used in the linear autoencoder above) has a “bias” term, which is a learnable offset parameter separate for each output unit. Just like PCA “centers” the data by subtracting off the mean image (<code class="docutils literal notranslate"><span class="pre">mu</span></code>) before encoding and adds the average back in during decoding, a bias term in the decoder can effectively account for the first moment (mean) of the data (i.e. the average of all images in the training set). Convolution layers do have bias parameters, but the bias is applied per filter rather than per pixel location. If we’re generating grayscale images (like those in MNIST), then <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> will learn only one bias across the entire image.</p>
<p>For some conceptual continuity with both PCA and the <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layers above, the next block defines a custom <code class="docutils literal notranslate"><span class="pre">BiasLayer</span></code> for adding a learnable per-pixel offset. This custom layer will be used twice: as the first stage of the encoder and as the final stage of the decoder. Ideally, this means that the rest of the neural net can focus on fitting more interesting fine-grained structure.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">BiasLayer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">BiasLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">init_bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">init_bias</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
</pre></div>
</div>
</div>
</div>
<p>With that out of the way, we will next define a <strong>nonlinear</strong> and <strong>convolutional</strong> autoencoder. Here’s a quick tour of the architecture:</p>
<ol class="simple">
<li><p>The <strong>encoder</strong> once again maps from images to <span class="math notranslate nohighlight">\(\mathbf{h}\in\mathbb{R}^K\)</span>. This will use a <code class="docutils literal notranslate"><span class="pre">BiasLayer</span></code> followed by two convolutional layers (<code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code>), followed by flattening and linearly projecting down to <span class="math notranslate nohighlight">\(K\)</span> dimensions. The convolutional layers will have <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> nonlinearities on their outputs.</p></li>
<li><p>The <strong>decoder</strong> inverts this process, taking in vectors of length <span class="math notranslate nohighlight">\(K\)</span> and outputting images. Roughly speaking, its architecture is a “mirror image” of the encoder: the first decoder layer is linear, followed by two <strong>deconvolution</strong> layers (<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html"><code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code></a>). The <code class="docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code>layers will have <code class="docutils literal notranslate"><span class="pre">ReLU</span></code> nonlinearities on their <em>inputs</em>. This “mirror image” between the encoder and decoder is a useful and near-ubiquitous convention. The idea is that the decoder can then learn to approximately invert the encoder, but it is not a strict requirement (and it does not guarantee the decoder will be an exact inverse of the encoder!).</p></li>
</ol>
<p>Below is a schematic of the architecture for MNIST. Notice that the width and height dimensions of the image planes reduce after each <code class="docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> and increase after each <code class="docutils literal notranslate"><span class="pre">nn.ConvTranspose2d</span></code>. With CIFAR10, the architecture is the same but the exact sizes will differ a bit.</p>
<img alt="https://raw.githubusercontent.com/CIS-522/course-content/main/tutorials/W08_AutoEncoders_GANs/static/conv_sizes.png" src="https://raw.githubusercontent.com/CIS-522/course-content/main/tutorials/W08_AutoEncoders_GANs/static/conv_sizes.png"/>
<p><a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html"><code class="docutils literal notranslate"><span class="pre">torch.nn.ConvTranspose2d</span></code></a> module can be seen as the gradient of <code class="docutils literal notranslate"><span class="pre">Conv2d</span></code> with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation). The following code demonstrates this change in sizes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dummy_image</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">in_channels</span> <span class="o">=</span> <span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">out_channels</span> <span class="o">=</span> <span class="mi">7</span>

<span class="n">dummy_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                       <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                       <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">dummy_deconv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
                                  <span class="n">out_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
                                  <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Size of image is </span><span class="si">{</span><span class="n">dummy_image</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Size of Conv2D(image) </span><span class="si">{</span><span class="n">dummy_conv</span><span class="p">(</span><span class="n">dummy_image</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Size of ConvTranspose2D(Conv2D(image)) </span><span class="si">{</span><span class="n">dummy_deconv</span><span class="p">(</span><span class="n">dummy_conv</span><span class="p">(</span><span class="n">dummy_image</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module">
<h3>Coding Exercise 3.2: Fill in code for the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> module<a class="headerlink" href="#coding-exercise-3-2-fill-in-code-for-the-convautoencoder-module" title="Permalink to this headline">¶</a></h3>
<p>Complete the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> class. We use the helper function <code class="docutils literal notranslate"><span class="pre">cout(torch.Tensor,</span> <span class="pre">nn.Conv2D)</span></code> to calculate the output shape of a <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"><code class="docutils literal notranslate"><span class="pre">nn.Conv2D</span></code></a> layer given a tensor with shape (channels, height, width).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ConvAutoEncoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_dim</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">,</span> <span class="n">n_filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="sd">"""A Convolutional AutoEncoder</span>

<span class="sd">    Args:</span>
<span class="sd">      x_dim (tuple): input dimensions (channels, height, widths)</span>
<span class="sd">      h_dim (int): hidden dimension, bottleneck dimension, K</span>
<span class="sd">      n_filters (int): number of filters (number of output channels)</span>
<span class="sd">      filter_size (int): kernel size</span>
<span class="sd">    """</span>
    <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="n">channels</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">widths</span> <span class="o">=</span> <span class="n">x_dim</span>

    <span class="c1"># encoder input bias layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">x_dim</span><span class="p">)</span>

    <span class="c1"># first encoder conv2d layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># output shape of the first encoder conv2d layer given x_dim input</span>
    <span class="n">conv_1_shape</span> <span class="o">=</span> <span class="n">cout</span><span class="p">(</span><span class="n">x_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span><span class="p">)</span>

    <span class="c1"># second encoder conv2d layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># output shape of the second encoder conv2d layer given conv_1_shape input</span>
    <span class="n">conv_2_shape</span> <span class="o">=</span> <span class="n">cout</span><span class="p">(</span><span class="n">conv_1_shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span><span class="p">)</span>

    <span class="c1"># The bottleneck is a dense layer, therefore we need a flattenning layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>

    <span class="c1"># conv output shape is (depth, height, width), so the flatten size is:</span>
    <span class="n">flat_after_conv</span> <span class="o">=</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">conv_2_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># encoder Linear layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">flat_after_conv</span><span class="p">,</span> <span class="n">h_dim</span><span class="p">)</span>

    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your class</span>
    <span class="c1"># Remember that decoder is "undo"-ing what the encoder has done!</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the `ConvAutoEncoder` class!"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># decoder Linear layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># unflatten data to (depth, height, width) shape</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_unflatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">unflattened_size</span><span class="o">=</span><span class="n">conv_2_shape</span><span class="p">)</span>

    <span class="c1"># first "deconvolution" layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">n_filters</span><span class="p">,</span> <span class="n">n_filters</span><span class="p">,</span> <span class="n">filter_size</span><span class="p">)</span>

    <span class="c1"># second "deconvolution" layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_2</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># decoder output bias layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">dec_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">x_dim</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">encode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_bias</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enc_conv_2</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_flatten</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">enc_lin</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">h</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">h</span><span class="p">):</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec_lin</span><span class="p">(</span><span class="n">h</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_unflatten</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_deconv_2</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">x_prime</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dec_bias</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_prime</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="n">K</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your solution</span>
<span class="c1"># trained_conv_AE = ConvAutoEncoder(data_shape, K)</span>
<span class="c1"># assert trained_conv_AE.encode(train_set[0][0].unsqueeze(0)).numel() == K, "Encoder output size should be K!"</span>
<span class="c1"># conv_losses = train_autoencoder(trained_conv_AE, train_set, device=DEVICE, seed=SEED)</span>
<span class="c1"># plot_conv_ae(lin_losses, conv_losses)</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial1_Solution_b45e8b94.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_b45e8b94_3.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_b45e8b94_3.png" style="width: 1119.0px; height: 832.0px;"/></a>
<p>You should see that the <code class="docutils literal notranslate"><span class="pre">ConvAutoEncoder</span></code> achieved lower MSE loss than the linear one. If not, you may need to retrain it (or run another few training epochs from where it left off). We make fewer guarantees on this working with CIFAR10, but it should definitely work with MNIST.</p>
<p>Now let’s visually compare the reconstructed images from the linear and nonlinear autoencoders. Keep in mind that both have the same dimensionality for <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>!</p>
<p>Visualize the linear and nonlinear AE outputs</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Visualize the linear and nonlinear AE outputs</span>
<span class="n">n_plot</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_plot</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="p">())</span>
  <span class="n">image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_set</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1"># Get reconstructed image from linear autoencoder</span>
    <span class="n">lin_recon</span> <span class="o">=</span> <span class="n">lin_ae</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># Get reconstruction from deep (nonlinear) autoencoder</span>
    <span class="n">nonlin_recon</span> <span class="o">=</span> <span class="n">trained_conv_AE</span><span class="p">(</span><span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Original</span><span class="se">\n</span><span class="s1">Image'</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">lin_recon</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Lin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>

  <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">n_plot</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">2</span><span class="o">*</span><span class="n">n_plot</span><span class="p">)</span>
  <span class="n">plot_torch_image</span><span class="p">(</span><span class="n">nonlin_recon</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">f</span><span class="s1">'NonLin AE</span><span class="se">\n</span><span class="s1">(K=</span><span class="si">{</span><span class="n">K</span><span class="si">}</span><span class="s1">)'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-variational-auto-encoders-vaes">
<h1>Section 4: Variational Auto-Encoders (VAEs)<a class="headerlink" href="#section-4-variational-auto-encoders-vaes" title="Permalink to this headline">¶</a></h1>
<p><strong>Please</strong> run the cell after the video to train a VAE for MNIST while watching it.</p>
<div class="section" id="video-4-variational-autoencoders">
<h2>Video 4: Variational Autoencoders<a class="headerlink" href="#video-4-variational-autoencoders" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
<p>Train a VAE for MNIST while watching the video. (Note: this VAE has a 2D latent space. If you are feeling ambitious, edit the code and modify the latent space dimensionality and see what happens.)</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Train a VAE for MNIST while watching the video. (Note: this VAE has a 2D latent space. If you are feeling ambitious, edit the code and modify the latent space dimensionality and see what happens.)</span>
<span class="n">K_VAE</span> <span class="o">=</span> <span class="mi">2</span>


<span class="k">class</span> <span class="nc">ConvVAE</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">num_filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">filter_size</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">ConvVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="c1"># With padding=0, the number of pixels cut off from each image dimension</span>
    <span class="c1"># is filter_size // 2. Double it to get the amount of pixels lost in</span>
    <span class="c1"># width and height per Conv2D layer, or added back in per</span>
    <span class="c1"># ConvTranspose2D layer.</span>
    <span class="n">filter_reduction</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">filter_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>

    <span class="c1"># After passing input through two Conv2d layers, the shape will be</span>
    <span class="c1"># 'shape_after_conv'. This is also the shape that will go into the first</span>
    <span class="c1"># deconvolution layer in the decoder</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_filters</span><span class="p">,</span>
                              <span class="n">data_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">filter_reduction</span><span class="p">,</span>
                              <span class="n">data_shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">filter_reduction</span><span class="p">)</span>
    <span class="n">flat_size_after_conv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> \
        <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> \
        <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

    <span class="c1"># Define the recognition model (encoder or q) part</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_conv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_conv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_flatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">q_fc_phi</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">flat_size_after_conv</span><span class="p">,</span> <span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Define the generative model (decoder or p) part</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_fc_upsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">flat_size_after_conv</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_unflatten</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unflatten</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">num_filters</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="n">num_filters</span><span class="p">,</span> <span class="n">data_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">p_bias</span> <span class="o">=</span> <span class="n">BiasLayer</span><span class="p">(</span><span class="n">data_shape</span><span class="p">)</span>

    <span class="c1"># Define a special extra parameter to learn scalar sig_x for all pixels</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">log_sig_x</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(()))</span>

  <span class="k">def</span> <span class="nf">infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">"""Map (batch of) x to (batch of) phi which can then be passed to</span>
<span class="sd">    rsample to get z</span>
<span class="sd">    """</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_bias</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_conv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">q_conv_2</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">flat_s</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">s</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">q_fc_phi</span><span class="p">(</span><span class="n">flat_s</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">phi</span>

  <span class="k">def</span> <span class="nf">generate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
    <span class="sd">"""Map [b,n,k] sized samples of z to [b,n,p] sized images</span>
<span class="sd">    """</span>
    <span class="c1"># Note that for the purposes of passing through the generator, we need</span>
    <span class="c1"># to reshape zs to be size [b*n,k]</span>
    <span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">zs</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="o">*</span><span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_fc_upsample</span><span class="p">(</span><span class="n">s</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">((</span><span class="n">b</span><span class="o">*</span><span class="n">n</span><span class="p">,)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape_after_conv</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_1</span><span class="p">(</span><span class="n">s</span><span class="p">))</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_deconv_2</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">p_bias</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
    <span class="n">mu_xs</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mu_xs</span>

  <span class="k">def</span> <span class="nf">decode</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zs</span><span class="p">):</span>
    <span class="c1"># Included for compatability with conv-AE code</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># VAE.forward() is not used for training, but we'll treat it like a</span>
    <span class="c1"># classic autoencoder by taking a single sample of z ~ q</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">zs</span> <span class="o">=</span> <span class="n">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>

  <span class="k">def</span> <span class="nf">elbo</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="sd">"""Run input end to end through the VAE and compute the ELBO using n</span>
<span class="sd">    samples of z</span>
<span class="sd">    """</span>
    <span class="n">phi</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">infer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">zs</span> <span class="o">=</span> <span class="n">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">mu_xs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">zs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">log_p_x</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu_xs</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_sig_x</span><span class="o">.</span><span class="n">exp</span><span class="p">())</span> <span class="o">-</span> <span class="n">kl_q_p</span><span class="p">(</span><span class="n">zs</span><span class="p">,</span> <span class="n">phi</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">expected_z</span><span class="p">(</span><span class="n">phi</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">phi</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">rsample</span><span class="p">(</span><span class="n">phi</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">):</span>
  <span class="sd">"""Sample z ~ q(z;phi)</span>
<span class="sd">  Ouput z is size [b,n_samples,K] given phi with shape [b,K+1]. The first K</span>
<span class="sd">  entries of each row of phi are the mean of q, and phi[:,-1] is the log</span>
<span class="sd">  standard deviation</span>
<span class="sd">  """</span>
  <span class="n">b</span><span class="p">,</span> <span class="n">kplus1</span> <span class="o">=</span> <span class="n">phi</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
  <span class="n">k</span> <span class="o">=</span> <span class="n">kplus1</span><span class="o">-</span><span class="mi">1</span>
  <span class="n">mu</span><span class="p">,</span> <span class="n">sig</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">phi</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">exp</span><span class="p">()</span>
  <span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">n_samples</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">phi</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">eps</span><span class="o">*</span><span class="n">sig</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">mu</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">b</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">k</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train_vae</span><span class="p">(</span><span class="n">vae</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
  <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">vae</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">elbo_vals</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">pin_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">trange</span><span class="p">(</span><span class="n">epochs</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Epochs'</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">im</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span> <span class="o">//</span> <span class="mi">250</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s1">'Batches'</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
      <span class="n">im</span> <span class="o">=</span> <span class="n">im</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
      <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">vae</span><span class="o">.</span><span class="n">elbo</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="n">elbo_vals</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="o">-</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">)</span>
  <span class="n">vae</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">elbo_vals</span>


<span class="n">trained_conv_VarAE</span> <span class="o">=</span> <span class="n">ConvVAE</span><span class="p">(</span><span class="n">K</span><span class="o">=</span><span class="n">K_VAE</span><span class="p">)</span>
<span class="n">elbo_vals</span> <span class="o">=</span> <span class="n">train_vae</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="p">,</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Learned sigma_x is </span><span class="si">{</span><span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">trained_conv_VarAE</span><span class="o">.</span><span class="n">log_sig_x</span><span class="p">)</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>

<span class="c1"># Uncomment below if you'd like to see the the training</span>
<span class="c1"># curve of the evaluated ELBO loss function</span>
<span class="c1"># ELBO is the loss function used to train VAEs (see lecture!)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">elbo_vals</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch #'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'ELBO'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-4-1-components-of-a-vae">
<h2>Section 4.1: Components of a VAE<a class="headerlink" href="#section-4-1-components-of-a-vae" title="Permalink to this headline">¶</a></h2>
<p><em>Recognition models and density networks</em></p>
<p>Variational AutoEncoders (VAEs) are a lot like the classic AutoEncoders (AEs), but where we explicitly think about probability distributions. In the language of VAEs, the <strong>encoder</strong> is replaced with a <strong>recognition model</strong>, and the <strong>decoder</strong> is replaced with a <strong>density network</strong>.</p>
<p>Where in a classic autoencoder the encoder maps from images to a single hidden vector,</p>
<div class="amsmath math notranslate nohighlight" id="equation-5cf54dd7-9874-4950-9ae5-0277cb4be2f1">
<span class="eqno">(86)<a class="headerlink" href="#equation-5cf54dd7-9874-4950-9ae5-0277cb4be2f1" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{x} \overset{\text{AE}}{\longrightarrow} \mathbf{h} \, ,
\end{equation}\]</div>
<p>in a VAE we would say that a recognition model maps from inputs to entire <strong>distributions</strong> over hidden vectors,</p>
<div class="amsmath math notranslate nohighlight" id="equation-f4e6b52e-20ed-4424-8d4c-fd34b2b91995">
<span class="eqno">(87)<a class="headerlink" href="#equation-f4e6b52e-20ed-4424-8d4c-fd34b2b91995" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{x} \overset{\text{VAE}}{\longrightarrow} q_{\mathbf{w_e}}(\mathbf{z}) \, ,
\end{equation}\]</div>
<p>which we will then sample from. Here <span class="math notranslate nohighlight">\(\mathbf{w_e}\)</span> refers to the weights of the recognition model, which parametarize our distribution generating network. We’ll say more in a moment about what kind of distribution <span class="math notranslate nohighlight">\(q_{\mathbf{w_e}}(\mathbf{z})\)</span> is.
Part of what makes VAEs work is that the loss function will require good reconstructions of the input not just for a single <span class="math notranslate nohighlight">\(\mathbf{z}\)</span>, but <em>on average</em> from samples of <span class="math notranslate nohighlight">\(\mathbf{z} \sim q_{\mathbf{w_e}}(\mathbf{z})\)</span>.</p>
<p>In the classic autoencoder, we had a decoder which maps from hidden vectors to reconstructions of the input:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4789b253-8eee-4a34-ab36-773b56c1851d">
<span class="eqno">(88)<a class="headerlink" href="#equation-4789b253-8eee-4a34-ab36-773b56c1851d" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{h} \overset{\text{AE}}{\longrightarrow} \mathbf{x'} \, .
\end{equation}\]</div>
<p>In a density network, reconstructions are expressed in terms of a distribution:</p>
<div class="amsmath math notranslate nohighlight" id="equation-56897a01-d2c2-43fd-bbb7-f09657eac219">
<span class="eqno">(89)<a class="headerlink" href="#equation-56897a01-d2c2-43fd-bbb7-f09657eac219" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{z} \overset{\text{VAE}}{\longrightarrow} p_{\mathbf{w_d}}(\mathbf{x}|\mathbf{z})
\end{equation}\]</div>
<p>where, as above, <span class="math notranslate nohighlight">\(p_{\mathbf{w_d}}(\mathbf{x}|\mathbf{z})\)</span> is defined by mapping <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> through a density network then treating the resulting <span class="math notranslate nohighlight">\(f(\mathbf{z};\mathbf{w_d})\)</span> as the mean of a (Gaussian) distribution over <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Similarly, our reconstruction distribution is parametarized by the weights of the density network.</p>
</div>
<div class="section" id="section-4-2-generating-novel-images-from-the-decoder">
<h2>Section 4.2: Generating novel images from the decoder<a class="headerlink" href="#section-4-2-generating-novel-images-from-the-decoder" title="Permalink to this headline">¶</a></h2>
<p>If we isolate the decoder part of the AutoEncoder, what we have is a neural network that takes as input a vector of size <span class="math notranslate nohighlight">\(K\)</span> and produces as output an image that looks something like our training data. Recall that in our earlier notation, we had an input <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that was mapped to a low-dimensional hidden representation <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> which was then decoded into a reconstruction of the input, <span class="math notranslate nohighlight">\(\mathbf{x'}\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-76db751e-4151-453c-a861-e65417dcacdb">
<span class="eqno">(90)<a class="headerlink" href="#equation-76db751e-4151-453c-a861-e65417dcacdb" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{x} \overset{\text{encode}}{\longrightarrow} \mathbf{h} \overset{\text{decode}}{\longrightarrow} \mathbf{x'}\, .
\end{equation}\]</div>
<p>Partly as a matter of convention, and partly to distinguish where we are going next from the previous section, we’re going to introduce a new variable, <span class="math notranslate nohighlight">\(\mathbf{z} \in \mathbb{R}^K\)</span>, which will take the place of <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>. The key difference is that while <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> is produced by the encoder for a particular <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, <span class="math notranslate nohighlight">\(\mathbf{z}\)</span> will be drawn out of thin air from a prior of our choosing:</p>
<div class="amsmath math notranslate nohighlight" id="equation-bbe190ff-fb36-45d3-8c86-cd2340adf084">
<span class="eqno">(91)<a class="headerlink" href="#equation-bbe190ff-fb36-45d3-8c86-cd2340adf084" title="Permalink to this equation">¶</a></span>\[\begin{equation}
\mathbf{z} \sim p(\mathbf{z})\\ \mathbf{z} \overset{\text{decode}}{\longrightarrow} \mathbf{x}\, .
\end{equation}\]</div>
<p>(Note that it is also common convention to drop the “prime” on <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> when it is no longer being thought of as a “reconstruction”).</p>
<div class="section" id="coding-exercise-4-2-generating-images">
<h3>Coding Exercise 4.2: Generating images<a class="headerlink" href="#coding-exercise-4-2-generating-images" title="Permalink to this headline">¶</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_images</span><span class="p">(</span><span class="n">autoencoder</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">n_images</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
  <span class="sd">"""Generate n_images 'new' images from the decoder part of the given</span>
<span class="sd">  autoencoder.</span>

<span class="sd">  returns (n_images, channels, height, width) tensor of images</span>
<span class="sd">  """</span>
  <span class="c1"># Concatenate tuples to get (n_images, channels, height, width)</span>
  <span class="n">output_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">n_images</span><span class="p">,)</span> <span class="o">+</span> <span class="n">data_shape</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># Fill in all missing code below (...),</span>
    <span class="c1"># then remove or comment the line below to test your function</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Please complete the `generate_images` function!"</span><span class="p">)</span>
    <span class="c1">####################################################################</span>
    <span class="c1"># sample z from a unit gaussian, pass through autoencoder.decode()</span>
    <span class="n">z</span> <span class="o">=</span> <span class="o">...</span>
    <span class="n">x</span> <span class="o">=</span> <span class="o">...</span>

    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">output_shape</span><span class="p">)</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment to test your solution</span>
<span class="c1"># images = generate_images(trained_conv_AE, K, n_images=9)</span>
<span class="c1"># plot_images(images, plt_title='Images Generated from the Conv-AE')</span>
<span class="c1"># images = generate_images(trained_conv_VarAE, K_VAE, n_images=9)</span>
<span class="c1"># plot_images(images, plt_title='Images Generated from a Conv-Variational-AE')</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W2D5_GenerativeModels/solutions/W2D5_Tutorial1_Solution_ed134be2.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_ed134be2_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_ed134be2_1.png" style="width: 826.0px; height: 886.0px;"/></a>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_ed134be2_2.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W2D5_GenerativeModels/static/W2D5_Tutorial1_Solution_ed134be2_2.png" style="width: 855.0px; height: 886.0px;"/></a>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-5-state-of-the-art-vaes-and-wrap-up">
<h1>Section 5: State of the art VAEs and Wrap-up<a class="headerlink" href="#section-5-state-of-the-art-vaes-and-wrap-up" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-5-state-of-the-art-vaes">
<h2>Video 5: State-Of-The-Art VAEs<a class="headerlink" href="#video-5-state-of-the-art-vaes" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Through this tutorial, we have learned</p>
<ul class="simple">
<li><p>What a generative model is and why we are interested in them.</p></li>
<li><p>How latent variable models relate to generative models with the example of pPCA.</p></li>
<li><p>What a basic AutoEncoder is and how they relate to other latent variable models.</p></li>
<li><p>The basics of Variational AutoEncoders and how they function as generative models.</p></li>
<li><p>An introduction to the broad applications of VAEs.</p></li>
</ul>
<p>In the next two tutorials we will cover GANs and how to train them.</p>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W2D5_GenerativeModels/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="../chapter_title.html" id="prev-link" title="previous page">Generative Models</a>
<a class="right-next" href="W2D5_Tutorial2.html" id="next-link" title="next page">Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br/>
        
            © Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>