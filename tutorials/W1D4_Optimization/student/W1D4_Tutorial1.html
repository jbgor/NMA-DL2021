
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 1: Optimization techniques â€” Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.5f77b4aec8189eecf79907ce328c390d.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-dl-logo-square-4xp.jpeg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../../W1D5_Regularization/chapter_title.html" rel="next" title="Regularization"/>
<link href="../chapter_title.html" rel="prev" title="Optimization"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.jpeg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Optimization (W1D4)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/TheBasics.html">
   Deep Learning: The Basics Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing More With Fewer Parameters
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial2.html">
     (Bonus) Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_GenerativeModels/chapter_title.html">
   Generative Models (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial4.html">
     (Bonus) Tutorial 4: Deploying Neural Networks on the Web
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/DoingMoreWithFewerParameters.html">
   Deep Learning: Doing more with fewer parameters Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Advanced Topics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ContinualLearning/chapter_title.html">
   Continual Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Introduction to Continual Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../Module_WrapUps/AdvancedTopics.html">
   Deep Learning: Advanced Topics Wrap-up
  </a>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Something Screwy - image recognition, detection, and classification of screws
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/image_alignment.html">
       Image Alignment
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W1D4_Optimization/student/W1D4_Tutorial1.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D4_Optimization/student/W1D4_Tutorial1.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Optimization techniques
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-introduction">
   Section 1. Introduction
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction">
     Video 1: Introduction
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#discuss-unexpected-consequences">
     Discuss: Unexpected consequences
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-case-study-successfully-training-an-mlp-for-image-classification">
   Section 2: Case study: successfully training an MLP for image classification
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-case-study-mlp-classification">
     Video 2: Case Study - MLP Classification
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-1-data">
     Section 2.1: Data
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-mnist-dataset">
       Download MNIST dataset
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#run-me">
       Run me!
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-2-model">
     Section 2.2: Model
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-3-loss">
     Section 2.3: Loss
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-4-interpretability">
     Section 2.4: Interpretability
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-high-dimensional-search">
   Section 3: High dimensional search
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-optimization-of-an-objective-function">
     Video 3: Optimization of an Objective Function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-3-implement-gradient-descent">
     Coding Exercise 3: Implement gradient descent
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#comparing-updates">
     Comparing updates
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-3-gradient-descent-vs-random-search">
     Think! 3: Gradient descent vs. random search
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#student-response">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-poor-conditioning">
   Section 4: Poor conditioning
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-momentum">
     Video 4: Momentum
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-4-implement-momentum">
     Coding Exercise 4: Implement momentum
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-4-momentum-vs-gd">
     Interactive Demo 4: Momentum vs. GD
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-4-momentum-and-oscillations">
     Think! 4: Momentum and oscillations
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id1">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-non-convexity">
   Section 5: Non-convexity
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-overparametrization">
     Video 5: Overparametrization
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-5-overparametrization-to-the-rescue">
     Interactive Demo 5: Overparametrization to the rescue!
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-5-1-width-and-depth-of-the-network">
       Think! 5.1: Width and depth of the network
      </a>
<ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry">
<a class="reference internal nav-link" href="#id2">
         Student Response
        </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-6-full-gradients-are-expensive">
   Section 6: Full gradients are expensive
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-6-mini-batches">
     Video 6: Mini-batches
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-6-1-cost-of-computation">
     Interactive Demo 6.1: Cost of computation
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-6-implement-minibatch-sampling">
     Coding Exercise 6: Implement minibatch sampling
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-6-2-compare-different-minibatch-sizes">
     Interactive Demo 6.2:
     <em>
      Compare
     </em>
     different minibatch sizes
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-7-adaptive-methods">
   Section 7: Adaptive methods
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-7-adaptive-methods">
     Video 7: Adaptive Methods
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-7-implement-rmsprop">
     Coding Exercise 7: Implement RMSprop
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#interactive-demo-7-compare-optimizers">
     Interactive Demo 7: Compare optimizers
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#discussion">
<strong>
        Discussion
       </strong>
</a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#locality-of-gradients">
       Locality of Gradients
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-7-loss-function-and-optimization">
     Think! 7: Loss function and optimization
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#id3">
       Student Response
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-8-ethical-concerns">
   Section 8: Ethical concerns
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-8-ethical-concerns">
     Video 8: Ethical concerns
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#airtable-submission-link">
     Airtable Submission Link
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#bonus-putting-it-all-together">
   Bonus: Putting it all together
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-9-putting-it-all-together">
     Video 9: Putting it all together
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#download-parameters-of-the-benchmark-model">
     Download parameters of the benchmark model
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-bonus-train-your-own-model">
     Exercise Bonus: Train your own model
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-bonus-metrics">
     Think! Bonus: Metrics
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#evaluation">
       Evaluation
      </a>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W1D4_Optimization/student/W1D4_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a> Â  <a href="https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D4_Optimization/student/W1D4_Tutorial1.ipynb" target="_blank"><img alt="Open in Kaggle" src="https://kaggle.com/static/images/open-in-kaggle.svg"/></a></p>
<div class="section" id="tutorial-1-optimization-techniques">
<h1>Tutorial 1: Optimization techniques<a class="headerlink" href="#tutorial-1-optimization-techniques" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Week 1, Day 4: Optimization</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Jose Gallego-Posada, Ioannis Mitliagkas</p>
<p><strong>Content reviewers:</strong> Piyush Chauhan, Vladimir Haltakov, Siwei Bai, Kelson Shilling-Scrivo</p>
<p><strong>Content editors:</strong> Charles J Edelson, Gagana B, Spiros Chavlis</p>
<p><strong>Production editors:</strong> Arush Tagade, Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">Â¶</a></h1>
<p>Objectives:</p>
<ul class="simple">
<li><p>Necessity and importance of optimization</p></li>
<li><p>Introduction to commonly used optimization techniques</p></li>
<li><p>Optimization in non-convex loss landscapes</p></li>
<li><p>â€˜Adaptiveâ€™ hyperparameter tuning</p></li>
<li><p>Ethical concerns</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/ft2sz/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet
<span class="kn">from</span> <span class="nn">evaltools.airtable</span> <span class="kn">import</span> <span class="n">AirtableForm</span>

<span class="c1"># generate airtable form</span>
<span class="n">atform</span> <span class="o">=</span> <span class="n">AirtableForm</span><span class="p">(</span><span class="s1">'appn7VdPRseSoMXEG'</span><span class="p">,</span><span class="s1">'W1D4_T1'</span><span class="p">,</span><span class="s1">'https://portal.neuromatchacademy.org/api/redirect/to/9548a279-c9f9-4586-b89c-f0ceceba5c14'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>

<span class="kn">from</span> <span class="nn">tqdm.auto</span> <span class="kn">import</span> <span class="n">tqdm</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'axes'</span><span class="p">,</span> <span class="n">unicode_minus</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>
<span class="k">def</span> <span class="nf">print_params</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
  <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
      <span class="nb">print</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">Â¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
        <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
        <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-introduction">
<h1>Section 1. Introduction<a class="headerlink" href="#section-1-introduction" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~15 mins</em></p>
<div class="section" id="video-1-introduction">
<h2>Video 1: Introduction<a class="headerlink" href="#video-1-introduction" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "1234bfec013142b0b62329b42cbaae15"}
</script></div>
</div>
</div>
<div class="section" id="discuss-unexpected-consequences">
<h2>Discuss: Unexpected consequences<a class="headerlink" href="#discuss-unexpected-consequences" title="Permalink to this headline">Â¶</a></h2>
<p>Can you think of examples from your own experience/life where poorly chosen incentives or objectives have lead to unexpected consequences?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_b8bbba6f.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-case-study-successfully-training-an-mlp-for-image-classification">
<h1>Section 2: Case study: successfully training an MLP for image classification<a class="headerlink" href="#section-2-case-study-successfully-training-an-mlp-for-image-classification" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~40 mins</em></p>
<p>Many of the core ideas (and tricks) in modern optimization for deep learning can be illustrated in the simple setting of training an MLP to solve an image classification task. In this tutorial we will guide you through the key challenges that arise when optimizing high-dimensional, non-convex<span class="math notranslate nohighlight">\(^\dagger\)</span> problems. We will use these challenges to motivate and explain some commonly used solutions.</p>
<p><strong>Disclaimer:</strong> Some of the functions you will code in this tutorial are already implemented in Pytorch and many other libraries. For pedagogical reasons, we decided to bring these simple coding tasks into the spotlight and place a relatively higher emphasis in your understanding of the algorithms, rather than the use of a specific library.</p>
<p>In â€˜day-to-dayâ€™ research projects you will likely to rely on the community-vetted, optimized libraries rather than the â€˜manual implementationsâ€™ you will write today. In Section 8 you will have a chance to â€˜put it all togetherâ€™ and use the full power of Pytorch to tune the parameters of an MLP to classify handwritten digits.</p>
<p><span class="math notranslate nohighlight">\(^\dagger\)</span>: A <strong>convex</strong> function has one, global minimum - a nice property, as an optimization algorithm wonâ€™t get stuck in a local minimum that isnâ€™t a global one (e.g., <span class="math notranslate nohighlight">\(f(x)=x^2 + 2x + 1\)</span>). A <strong>non-convex</strong> function is wavy - has some â€˜valleysâ€™ (local minima) that arenâ€™t as deep as the overall deepest â€˜valleyâ€™ (global minimum). Thus, the optimization algorithms can get stuck in the local minimum, and it can be hard to tell when this happens (e.g., <span class="math notranslate nohighlight">\(f(x) = x^4 + x^3 - 2x^2 - 2x\)</span>). See also <strong>Section 5</strong> for more details.</p>
<div class="section" id="video-2-case-study-mlp-classification">
<h2>Video 2: Case Study - MLP Classification<a class="headerlink" href="#video-2-case-study-mlp-classification" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f859a992ce434968a2caf87c367c85c6"}
</script></div>
</div>
</div>
<div class="section" id="section-2-1-data">
<h2>Section 2.1: Data<a class="headerlink" href="#section-2-1-data" title="Permalink to this headline">Â¶</a></h2>
<p>We will use the MNIST dataset of handwritten digits. We load the data via the Pytorch <code class="docutils literal notranslate"><span class="pre">datasets</span></code> module, as you learned in W1D1.</p>
<p><strong>Note:</strong> Although we can download the MNIST dataset directly from <code class="docutils literal notranslate"><span class="pre">datasets</span></code> using the optional argument <code class="docutils literal notranslate"><span class="pre">download=True</span></code>, we are going to download them from NMA directory on OSF to ensure network reliability.</p>
<div class="section" id="download-mnist-dataset">
<h3>Download MNIST dataset<a class="headerlink" href="#download-mnist-dataset" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download MNIST dataset</span>
<span class="kn">import</span> <span class="nn">tarfile</span><span class="o">,</span> <span class="nn">requests</span><span class="o">,</span> <span class="nn">os</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s1">'MNIST.tar.gz'</span>
<span class="n">name</span> <span class="o">=</span> <span class="s1">'MNIST'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">'https://osf.io/y2fj6/download'</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading MNIST dataset...'</span><span class="p">)</span>
  <span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading MNIST completed.'</span><span class="p">)</span>

<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
  <span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
    <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">()</span>
    <span class="n">os</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'MNIST dataset has been dowloaded.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading MNIST dataset...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading MNIST completed.
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_mnist_data</span><span class="p">(</span><span class="n">change_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">"""Load training and test examples for the MNIST digits dataset</span>

<span class="sd">  Returns:</span>
<span class="sd">    train_data (tensor): training input tensor of size (train_size x 784)</span>
<span class="sd">    train_target (tensor): training 0-9 integer label tensor of size (train_size)</span>
<span class="sd">    test_data (tensor): test input tensor of size (70k-train_size x 784)</span>
<span class="sd">    test_target (tensor): training 0-9 integer label tensor of size (70k-train_size)</span>

<span class="sd">  """</span>
  <span class="c1"># Load train and test sets</span>
  <span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                             <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>
  <span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                            <span class="n">transform</span><span class="o">=</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">())</span>

  <span class="c1"># Original data is in range [0, 255]. We normalize the data wrt its mean and std_dev.</span>
  <span class="c1">## Note that we only used *training set* information to compute mean and std</span>
  <span class="n">mean</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
  <span class="n">std</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>

  <span class="k">if</span> <span class="n">change_tensors</span><span class="p">:</span>
    <span class="c1"># Apply normalization directly to the tensors containing the dataset</span>
    <span class="n">train_set</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
    <span class="n">test_set</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="p">(</span><span class="n">test_set</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">tform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                            <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="n">mean</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="n">std</span> <span class="o">/</span> <span class="mf">255.</span><span class="p">])</span>
                                            <span class="p">])</span>
    <span class="n">train_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                               <span class="n">transform</span><span class="o">=</span><span class="n">tform</span><span class="p">)</span>
    <span class="n">test_set</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">MNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">'.'</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="n">download</span><span class="p">,</span>
                              <span class="n">transform</span><span class="o">=</span><span class="n">tform</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span>


<span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">load_mnist_data</span><span class="p">(</span><span class="n">change_tensors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As we are just getting started, we will concentrate on a small subset of only 500 examples out of the 60.000 data points contained in the whole training set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Sample a random subset of 500 indices</span>
<span class="n">subset_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="mi">500</span><span class="p">)</span>

<span class="c1"># We will use these symbols to represent the training data and labels, to stay</span>
<span class="c1"># as close to the mathematical expressions as possible.</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">subset_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">subset_index</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Run the following cell to visualize the content of three examples in our training set. Note how the pre-processing we applied to the data changes the range of pixel values after normalization.</p>
</div>
<div class="section" id="run-me">
<h3>Run me!<a class="headerlink" href="#run-me" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Run me!</span>
<span class="n">num_figures</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_figures</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span> <span class="o">*</span> <span class="n">num_figures</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">sample_id</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">axs</span><span class="p">):</span>
  <span class="c1"># Plot the pixel values for each image</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">sample_id</span><span class="p">,</span> <span class="p">:],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray_r'</span><span class="p">)</span>
  <span class="c1"># 'Write' the pixel value in the corresponding location</span>
  <span class="k">for</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">),</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">ndenumerate</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">sample_id</span><span class="p">,</span> <span class="p">:]):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="s1">'</span><span class="si">{:.1f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span>
            <span class="n">va</span><span class="o">=</span><span class="s1">'center'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'steelblue'</span><span class="p">)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Label: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">sample_id</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W1D4_Tutorial1_38_0.png" src="../../../_images/W1D4_Tutorial1_38_0.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-2-model">
<h2>Section 2.2: Model<a class="headerlink" href="#section-2-2-model" title="Permalink to this headline">Â¶</a></h2>
<p>As you will see next week, there are specific model architectures that are better suited to image-like data, such as Convolutional Neural Networks (CNNs). For simplicity, in this tutorial we will focus exclusively on Multi-Layer Perceptron (MLP) models as they allow us to highlight many important optimization challenges shared with more advanced neural network designs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="sd">""" This class implements MLPs in Pytorch of an arbitrary number of hidden</span>
<span class="sd">  layers of potentially different sizes. Since we concentrate on classification</span>
<span class="sd">  tasks in this tutorial, we have a log_softmax layer at prediction time.</span>
<span class="sd">  """</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[],</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="sd">"""Constructs a MultiLayerPerceptron</span>

<span class="sd">    Args:</span>
<span class="sd">        in_dim (int): dimensionality of input data</span>
<span class="sd">        out_dim (int): number of classes</span>
<span class="sd">        hidden_dims (list): contains the dimensions of the hidden layers, an empty</span>
<span class="sd">            list corresponds to a linear model (in_dim, out_dim)</span>
<span class="sd">    """</span>

    <span class="nb">super</span><span class="p">(</span><span class="n">MLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span> <span class="o">=</span> <span class="n">in_dim</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out_dim</span> <span class="o">=</span> <span class="n">out_dim</span>

    <span class="c1"># If we have no hidden layer, just initialize a linear model (e.g. in logistic regression)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
      <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="c1"># 'Actual' MLP with dimensions in_dim - num_hidden_layers*[hidden_dim] - out_dim</span>
      <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()]</span>

      <span class="c1"># Loop until before the last layer</span>
      <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_dim</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">),</span>
                   <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()]</span>

      <span class="c1"># Add final layer to the number of classes</span>
      <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dims</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">out_dim</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">use_bias</span><span class="p">)]</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">main</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># Flatten the images into 'vectors'</span>
    <span class="n">transformed_x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_dim</span><span class="p">)</span>
    <span class="n">hidden_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">main</span><span class="p">(</span><span class="n">transformed_x</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">hidden_output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>
</pre></div>
</div>
</div>
</div>
<p>Linear models constitute a very special kind of MLPs: they are equivalent to an MLP with <em>zero</em> hidden layers. This is simply an affine transformation, in other words a â€˜linearâ€™ map <span class="math notranslate nohighlight">\(W x\)</span> with an â€˜offsetâ€™ <span class="math notranslate nohighlight">\(b\)</span>; followed by a softmax function.</p>
<div class="math notranslate nohighlight">
\[f(x) = \text{softmax}(W x + b)\]</div>
<p>Here <span class="math notranslate nohighlight">\(x \in \mathbb{R}^{784}\)</span>, <span class="math notranslate nohighlight">\(W \in \mathbb{R}^{10 \times 784}\)</span> and <span class="math notranslate nohighlight">\(b \in \mathbb{R}^{10}\)</span>. Notice that the dimensions of the weight matrix are <span class="math notranslate nohighlight">\(10 \times 784\)</span> as the input tensors are flattened images, i.e., <span class="math notranslate nohighlight">\(28 \times 28 = 784\)</span>-dimensional tensors and the output layer consists of <span class="math notranslate nohighlight">\(10\)</span> nodes.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Empty hidden_dims means we take a model with zero hidden layers.</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>

<span class="c1"># We print the model structure with 784 inputs and 10 outputs</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>MLP(
  (main): Sequential(
    (0): Linear(in_features=784, out_features=10, bias=True)
  )
)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-3-loss">
<h2>Section 2.3: Loss<a class="headerlink" href="#section-2-3-loss" title="Permalink to this headline">Â¶</a></h2>
<p>While we care about the accuracy of the model, the â€˜discreteâ€™ nature of the 0-1 loss makes it challenging to optimize. In order to learn good parameters for this model, we will use the cross entropy loss (negative log-likelihood), which you saw in last lecture, as a surrogate objective to be minimized.</p>
<p>This particular choice of model and optimization objective leads to a <em>convex</em> optimization problem with respect to the parameters <span class="math notranslate nohighlight">\(W\)</span> and <span class="math notranslate nohighlight">\(b\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">nll_loss</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-2-4-interpretability">
<h2>Section 2.4: Interpretability<a class="headerlink" href="#section-2-4-interpretability" title="Permalink to this headline">Â¶</a></h2>
<p>In last lecture, you saw that inspecting the weights of a model can provide insights on what â€˜conceptsâ€™ the model has learned. Here we show the weights of a partially trained model. The weights corresponding to each class â€˜learnâ€™ to <em>fire</em> when an input of the class is detected.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#@markdown Run _this cell_ to train the model. If you are curious about how the training</span>
<span class="c1">#@markdown takes place, double-click this cell to find out. At the end of this tutorial</span>
<span class="c1">#@markdown you will have the opportunity to train a more complex model on your own.</span>

<span class="n">cell_verbose</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">partial_trained_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>

<span class="k">if</span> <span class="n">cell_verbose</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Init loss'</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">partial_trained_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1"># This matches around np.log(10 = # of classes)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">partial_trained_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">7e-4</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">200</span><span class="p">):</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">partial_trained_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

<span class="k">if</span> <span class="n">cell_verbose</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'End loss'</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">partial_trained_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="c1"># This should be less than 1e-2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Show class filters of a trained model</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">partial_trained_model</span><span class="o">.</span><span class="n">main</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="k">for</span> <span class="n">class_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
  <span class="n">axs</span><span class="p">[</span><span class="n">class_id</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">W</span><span class="p">[</span><span class="n">class_id</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">),</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'gray_r'</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="n">class_id</span><span class="p">]</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="n">class_id</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Class '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">class_id</span><span class="p">)</span> <span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W1D4_Tutorial1_48_0.png" src="../../../_images/W1D4_Tutorial1_48_0.png"/>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-high-dimensional-search">
<h1>Section 3: High dimensional search<a class="headerlink" href="#section-3-high-dimensional-search" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~25 mins</em></p>
<p>We now have a model with its corresponding trainable parameters as well as an objective to optimize. Where do we go to next? How do we find a â€˜goodâ€™ configuration of parameters?</p>
<p>One idea is to choose a random direction and move only if the objective is reduced. However, this is inefficient in high dimensions and you will see how gradient descent (with a suitable step-size) can guarantee consistent improvement in terms of the objective function.</p>
<div class="section" id="video-3-optimization-of-an-objective-function">
<h2>Video 3: Optimization of an Objective Function<a class="headerlink" href="#video-3-optimization-of-an-objective-function" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "3b5cad283ac0493c87ed0ad167eb1d6b"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-3-implement-gradient-descent">
<h2>Coding Exercise 3: Implement gradient descent<a class="headerlink" href="#coding-exercise-3-implement-gradient-descent" title="Permalink to this headline">Â¶</a></h2>
<p>In this exercise you will use PyTorch automatic differentiation capabilities to compute the gradient of the loss with respect to the parameters of the model. You will then use these gradients to implement the update performed by the gradient descent method.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="n">params</span><span class="p">):</span>
  <span class="sd">"""Clear up gradients as Pytorch automatically accumulates gradients from</span>
<span class="sd">  successive backward calls</span>
<span class="sd">  """</span>
  <span class="k">for</span> <span class="n">par</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
    <span class="k">if</span> <span class="ow">not</span><span class="p">(</span><span class="n">par</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
      <span class="n">par</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">random_update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">noise_scale</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">normalized</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">""" Performs a random update on the parameters of the model</span>
<span class="sd">  """</span>
  <span class="k">for</span> <span class="n">par</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">noise</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">par</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">normalized</span><span class="p">:</span>
      <span class="n">noise</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">noise</span><span class="p">)</span>
    <span class="n">par</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span>  <span class="n">noise_scale</span> <span class="o">*</span> <span class="n">noise</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gradient_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">):</span>
  <span class="sd">"""Perform a gradient descent update on a given loss over a collection of parameters</span>

<span class="sd">  Args:</span>
<span class="sd">    loss (tensor): A scalar tensor containing the loss whose gradient will be computed</span>
<span class="sd">    params (iterable): Collection of parameters with respect to which we compute gradients</span>
<span class="sd">    lr (float): Scalar specifying the learning rate or step-size for the update</span>
<span class="sd">  """</span>
  <span class="c1"># Clear up gradients as Pytorch automatically accumulates gradients from</span>
  <span class="c1"># successive backward calls</span>
  <span class="n">zero_grad</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>

  <span class="c1"># Compute gradients on given objective</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">par</span> <span class="ow">in</span> <span class="n">params</span><span class="p">:</span>
      <span class="c1">#################################################</span>
      <span class="c1">## TODO for students: update the value of the parameter ##</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement gradient update"</span><span class="p">)</span>
      <span class="c1">#################################################</span>
      <span class="c1"># Here we work with the 'data' attribute of the parameter rather than the</span>
      <span class="c1"># parameter itself.</span>
      <span class="n">par</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="o">...</span>


<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 3: Implement gradient descent'</span><span class="p">)</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model1</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> The model1 parameters before the update are: </span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">print_params</span><span class="p">(</span><span class="n">model1</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model1</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># gradient_update(loss, list(model1.parameters()), lr=1e-1)</span>
<span class="c1"># print('\n The model1 parameters after the update are: \n')</span>
<span class="c1"># print_params(model1)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.

 The model1 parameters before the update are: 

main.0.weight tensor([[-0.0264,  0.0010,  0.0173,  ...,  0.0297,  0.0278, -0.0221],
        [-0.0040, -0.0295, -0.0086,  ..., -0.0070,  0.0254, -0.0233],
        [ 0.0240, -0.0231,  0.0342,  ...,  0.0124,  0.0270, -0.0180],
        ...,
        [-0.0005,  0.0157,  0.0111,  ...,  0.0144, -0.0301, -0.0144],
        [ 0.0181,  0.0303,  0.0255,  ..., -0.0110, -0.0175,  0.0205],
        [ 0.0208, -0.0353, -0.0183,  ..., -0.0271,  0.0099,  0.0003]])
main.0.bias tensor([-0.0290, -0.0033,  0.0100, -0.0320,  0.0022,  0.0221,  0.0307,  0.0243,
         0.0159, -0.0064])
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_1c2b3d1a.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">The</span> <span class="n">model1</span> <span class="n">parameters</span> <span class="n">after</span> <span class="n">the</span> <span class="n">update</span> <span class="n">are</span><span class="p">:</span> 

<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">weight</span> <span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0263</span><span class="p">,</span>  <span class="mf">0.0010</span><span class="p">,</span>  <span class="mf">0.0174</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0298</span><span class="p">,</span>  <span class="mf">0.0278</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0220</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0047</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0302</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0093</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0077</span><span class="p">,</span>  <span class="mf">0.0248</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0240</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0234</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0237</span><span class="p">,</span>  <span class="mf">0.0335</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0117</span><span class="p">,</span>  <span class="mf">0.0263</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0187</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0006</span><span class="p">,</span>  <span class="mf">0.0156</span><span class="p">,</span>  <span class="mf">0.0110</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0143</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0302</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0145</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0164</span><span class="p">,</span>  <span class="mf">0.0286</span><span class="p">,</span>  <span class="mf">0.0238</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0127</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0191</span><span class="p">,</span>  <span class="mf">0.0188</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0206</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0354</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0184</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0272</span><span class="p">,</span>  <span class="mf">0.0098</span><span class="p">,</span>  <span class="mf">0.0002</span><span class="p">]])</span>
<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">bias</span> <span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0292</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0018</span><span class="p">,</span>  <span class="mf">0.0115</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0370</span><span class="p">,</span>  <span class="mf">0.0054</span><span class="p">,</span>  <span class="mf">0.0155</span><span class="p">,</span>  <span class="mf">0.0317</span><span class="p">,</span>  <span class="mf">0.0246</span><span class="p">,</span>
         <span class="mf">0.0198</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0061</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="comparing-updates">
<h2>Comparing updates<a class="headerlink" href="#comparing-updates" title="Permalink to this headline">Â¶</a></h2>
<p>These plots compare the effectiveness of updating random directions for the problem of optimizing the parameters of a high-dimensional linear model. We contrast the behavior at initialization and during an intermediate stage of training by showing the histograms of change in loss over 100 different random directions vs the changed in loss induced by the gradient descent update</p>
<p><strong>Remember:</strong> since we are trying to minimize, here negative is better!</p>
<p><em>Run this cell</em> to visualize the results</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown _Run this cell_ to visualize the results</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">my_model</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">([(</span><span class="s1">'Initialization'</span><span class="p">,</span> <span class="n">model</span><span class="p">),</span>
                                              <span class="p">(</span><span class="s1">'Partially trained'</span><span class="p">,</span> <span class="n">partial_trained_model</span><span class="p">)]):</span>
  <span class="c1"># Compue the loss we will be comparing to</span>
  <span class="n">base_loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">my_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>

  <span class="c1"># Compute the improvement via gradient descent</span>
  <span class="n">dummy_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">my_model</span><span class="p">)</span>
  <span class="n">loss1</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">dummy_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">gradient_update</span><span class="p">(</span><span class="n">loss1</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">dummy_model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
  <span class="n">gd_delta</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">dummy_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">base_loss</span>

  <span class="n">deltas</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">trial_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">100</span><span class="p">):</span>
    <span class="c1"># Compute the improvement obtained with a random direction</span>
    <span class="n">dummy_model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">my_model</span><span class="p">)</span>
    <span class="n">random_update</span><span class="p">(</span><span class="n">dummy_model</span><span class="p">,</span> <span class="n">noise_scale</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
    <span class="n">deltas</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">dummy_model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="n">base_loss</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

  <span class="c1"># Plot histogram for random direction and vertical line for gradient descent</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">deltas</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Random Directions'</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">model_name</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Change in loss'</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'</span><span class="si">% s</span><span class="s1">amples'</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'green'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
  <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">gd_delta</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                  <span class="n">label</span><span class="o">=</span><span class="s1">'Gradient Descent'</span><span class="p">)</span>


<span class="n">handles</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">axs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span><span class="o">.</span><span class="n">get_legend_handles_labels</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'upper center'</span><span class="p">,</span>
           <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">),</span>
           <span class="n">fancybox</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>

</div>
</div>
<div class="section" id="think-3-gradient-descent-vs-random-search">
<h2>Think! 3: Gradient descent vs. random search<a class="headerlink" href="#think-3-gradient-descent-vs-random-search" title="Permalink to this headline">Â¶</a></h2>
<p>Compare the behavior of gradient descent and random search based on the histograms above. Is any of the two methods more reliable? How can you explain the changes between behavior of the methods at initialization vs during training?</p>
<div class="section" id="student-response">
<h3>Student Response<a class="headerlink" href="#student-response" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q1'</span> <span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4c2e0b2584584ed8ba5dbdbe71dc6383"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "2435ae15ae8a40c88820246bff43411f"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_2de57667.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-poor-conditioning">
<h1>Section 4: Poor conditioning<a class="headerlink" href="#section-4-poor-conditioning" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~30 mins</em></p>
<p>Already in this â€˜simpleâ€™ logistic regression problem, the issue of bad conditioning is haunting us. Not all parameters are created equal and the sensitivity of the network to changes on the parameters will have a big impact in the dynamics of the optimization.</p>
<div class="section" id="video-4-momentum">
<h2>Video 4: Momentum<a class="headerlink" href="#video-4-momentum" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "4ff7ff0407a24566a851c7b2bc137135"}
</script></div>
</div>
<p>We illustrate this issue in a 2-dimensional setting. We freeze all but two parameters of the network: one of them is an element of the weight matrix (filter) for class 0, while the other is the bias for class 7. This results in an optimization with two decision variables.</p>
<p>How much difference is there in the behavior of these two parameters under gradient descent? What is the effect of momentum in bridging that gap?</p>
<p><em>Run this cell</em> to setup some helper functions.</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown _Run this cell_ to setup some helper functions.</span>

<span class="k">def</span> <span class="nf">loss_2d</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">mask_idx</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">378</span><span class="p">),</span> <span class="n">bias_id</span><span class="o">=</span><span class="mi">7</span><span class="p">):</span>
  <span class="sd">"""Defines a 2-dim function by freezing all but two parameters of a linear</span>
<span class="sd">  model.</span>

<span class="sd">  Args:</span>
<span class="sd">    model (torch module): a pytorch 0-hidden layer (linear) model</span>
<span class="sd">    u (scalar): first free parameter</span>
<span class="sd">    v (scalar): second free parameter</span>
<span class="sd">    mask_idx (tuple): selects parameter in weight matrix replaced by u</span>
<span class="sd">    bias_idx (int): selects parameter in bias vector replaced by v</span>

<span class="sd">  Returns:</span>
<span class="sd">    scalar: loss of the 'new' model over inputs X, y (defined externally)</span>
<span class="sd">  """</span>

  <span class="c1"># We zero out the element of the weight tensor that will be</span>
  <span class="c1"># replaced by u</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">main</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
  <span class="n">mask</span><span class="p">[</span><span class="n">mask_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mask_idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">0.</span>
  <span class="n">masked_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">main</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span> <span class="o">*</span> <span class="n">mask</span>

  <span class="c1"># u is replacing an element of the weight matrix</span>
  <span class="n">masked_weights</span><span class="p">[</span><span class="n">mask_idx</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">mask_idx</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">u</span>

  <span class="n">res</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">784</span><span class="p">)</span> <span class="o">@</span> <span class="n">masked_weights</span><span class="o">.</span><span class="n">T</span> <span class="o">+</span> <span class="n">model</span><span class="o">.</span><span class="n">main</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span>

  <span class="c1"># v is replacing a bias for class 7</span>
  <span class="n">res</span><span class="p">[:,</span> <span class="mi">7</span><span class="p">]</span> <span class="o">+=</span> <span class="n">v</span> <span class="o">-</span> <span class="n">model</span><span class="o">.</span><span class="n">main</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">bias</span><span class="p">[</span><span class="mi">7</span><span class="p">]</span>
  <span class="n">res</span> <span class="o">=</span>  <span class="n">F</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">res</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_surface</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">fig</span><span class="p">):</span>
  <span class="sd">""" Plot a 3D loss surface given meshed inputs U, V and values Z</span>
<span class="sd">  """</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">projection</span><span class="o">=</span><span class="s1">'3d'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">view_init</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span> <span class="o">-</span><span class="mi">130</span><span class="p">)</span>

  <span class="n">surf</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">coolwarm</span><span class="p">,</span>
                      <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">antialiased</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

  <span class="c1"># Select certain level contours to plot</span>
  <span class="c1"># levels = Z.min() * np.array([1.005, 1.1, 1.3, 1.5, 2.])</span>
  <span class="c1"># plt.contour(U, V, Z)# levels=levels, alpha=0.5)</span>

  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Weight'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Bias'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">plot_param_distance</span><span class="p">(</span><span class="n">best_u</span><span class="p">,</span> <span class="n">best_v</span><span class="p">,</span> <span class="n">trajs</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">styles</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span>
                        <span class="n">use_log</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">y_min_v</span><span class="o">=-</span><span class="mf">12.0</span><span class="p">,</span> <span class="n">y_max_v</span><span class="o">=</span><span class="mf">1.5</span><span class="p">):</span>
  <span class="sd">""" Plot the distance to each of the two parameters for a collection of 'trajectories'</span>
<span class="sd">  """</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">traj</span><span class="p">,</span> <span class="n">style</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">trajs</span><span class="p">,</span> <span class="n">styles</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="n">d0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">best_u</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">])</span>
    <span class="n">d1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">_</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">best_v</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">traj</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">use_log</span><span class="p">:</span>
      <span class="n">d0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1e-16</span> <span class="o">+</span> <span class="n">d0</span><span class="p">)</span>
      <span class="n">d1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">1e-16</span> <span class="o">+</span> <span class="n">d1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)),</span> <span class="n">d0</span><span class="p">,</span> <span class="n">style</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'weight - '</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">traj</span><span class="p">)),</span> <span class="n">d1</span><span class="p">,</span> <span class="n">style</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'bias - '</span> <span class="o">+</span> <span class="n">label</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">use_log</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Log distance to optimum (per dimension)'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_min_v</span><span class="p">,</span> <span class="n">y_max_v</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Abs distance to optimum (per dimension)'</span><span class="p">)</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'right'</span><span class="p">,</span> <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span>
            <span class="n">fancybox</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">shadow</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">ax</span>


<span class="k">def</span> <span class="nf">run_optimizer</span><span class="p">(</span><span class="n">inits</span><span class="p">,</span> <span class="n">eval_fn</span><span class="p">,</span> <span class="n">update_fn</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
                  <span class="n">optim_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span><span class="mf">1e-2</span><span class="p">},</span> <span class="n">log_traj</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">"""Runs an optimizer on a given objective and logs parameter trajectory</span>

<span class="sd">  Args:</span>
<span class="sd">      inits list(scalar): initialization of parameters</span>
<span class="sd">      eval_fn (callable): function computing the objective to be minimized</span>
<span class="sd">      update_fn (callable): function executing parameter update</span>
<span class="sd">      max_steps (int): number of iterations to run</span>
<span class="sd">      optim_kwargs (dict): customize optimizer hyperparameters</span>

<span class="sd">  Returns:</span>
<span class="sd">      list[list]: trajectory information [*params, loss] for each optimization step</span>
<span class="sd">  """</span>

  <span class="c1"># Initialize parameters and optimizer</span>
  <span class="n">params</span> <span class="o">=</span> <span class="p">[</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">_</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">inits</span><span class="p">]</span>
  <span class="c1"># Methods like momentum and rmsprop keep and auxiliary vector of parameters</span>
  <span class="n">aux_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">log_traj</span><span class="p">:</span>
    <span class="n">traj</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_steps</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
    <span class="c1"># Evaluate loss</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">eval_fn</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">)</span>
    <span class="c1"># Store 'trajectory' information</span>
    <span class="k">if</span> <span class="n">log_traj</span><span class="p">:</span>
      <span class="n">traj</span><span class="p">[</span><span class="n">_</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="p">[</span><span class="n">_</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
    <span class="c1"># Perform update</span>
    <span class="k">if</span> <span class="n">update_fn</span> <span class="o">==</span> <span class="n">gradient_update</span><span class="p">:</span>
      <span class="n">gradient_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">optim_kwargs</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">update_fn</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">aux_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">optim_kwargs</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">log_traj</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">traj</span>


<span class="n">L</span> <span class="o">=</span> <span class="mf">4.</span>
<span class="n">xs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">L</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">ys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">L</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="n">U</span><span class="p">,</span> <span class="n">V</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xs</span><span class="p">,</span> <span class="n">ys</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="coding-exercise-4-implement-momentum">
<h2>Coding Exercise 4: Implement momentum<a class="headerlink" href="#coding-exercise-4-implement-momentum" title="Permalink to this headline">Â¶</a></h2>
<p>In this exercise you will implement the momentum update given by:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c574a40e-2b4e-408e-bc58-198f8009dbd3">
<span class="eqno">(43)<a class="headerlink" href="#equation-c574a40e-2b4e-408e-bc58-198f8009dbd3" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
w_{t+1} = w_t - \eta \nabla J(w_t) + \beta (w_t - w_{t-1})
\end{equation}\]</div>
<p>It is convenient to re-express this update rule in terms of a recursion. For that, we define â€˜velocityâ€™ as the quantity:</p>
<div class="amsmath math notranslate nohighlight" id="equation-54427ff6-4115-411c-a0b0-106b4c800dfe">
<span class="eqno">(44)<a class="headerlink" href="#equation-54427ff6-4115-411c-a0b0-106b4c800dfe" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
v_{t-1} := w_{t} - w_{t-1}
\end{equation}\]</div>
<p>which leads to the two-step update rule:</p>
<div class="amsmath math notranslate nohighlight" id="equation-386833df-93e4-4105-8026-152f6dc1780a">
<span class="eqno">(45)<a class="headerlink" href="#equation-386833df-93e4-4105-8026-152f6dc1780a" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
v_t = - \eta \nabla J(w_t) + \beta (\underbrace{w_t - w_{t-1}}_{v_{t-1}})
\end{equation}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-cdad413a-0017-43cd-bb28-e8114d4b2b3e">
<span class="eqno">(46)<a class="headerlink" href="#equation-cdad413a-0017-43cd-bb28-e8114d4b2b3e" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
w_{t+1} \leftarrow w_t + v_{t}
\end{equation}\]</div>
<p>Pay attention to the positive sign of the update in the last equation, given the definition of <span class="math notranslate nohighlight">\(v_t\)</span>, above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">momentum_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grad_vel</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="mf">0.8</span><span class="p">):</span>
  <span class="sd">"""Perform a momentum update over a collection of parameters given a loss and 'velocities'</span>

<span class="sd">  Args:</span>
<span class="sd">    loss (tensor): A scalar tensor containing the loss whose gradient will be computed</span>
<span class="sd">    params (iterable): Collection of parameters with respect to which we compute gradients</span>
<span class="sd">    grad_vel (iterable): Collection containing the 'velocity' v_t for each parameter</span>
<span class="sd">    lr (float): Scalar specifying the learning rate or step-size for the update</span>
<span class="sd">    beta (float): Scalar 'momentum' parameter</span>
<span class="sd">  """</span>
  <span class="c1"># Clear up gradients as Pytorch automatically accumulates gradients from</span>
  <span class="c1"># successive backward calls</span>
  <span class="n">zero_grad</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
  <span class="c1"># Compute gradients on given objective</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">par</span><span class="p">,</span> <span class="n">vel</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grad_vel</span><span class="p">):</span>
      <span class="c1">#################################################</span>
      <span class="c1">## TODO for students: update the value of the parameter ##</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement momentum update"</span><span class="p">)</span>
      <span class="c1">#################################################</span>
      <span class="c1"># Update 'velocity'</span>
      <span class="n">vel</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
      <span class="c1"># Update parameters</span>
      <span class="n">par</span><span class="o">.</span><span class="n">data</span> <span class="o">+=</span> <span class="o">...</span>


<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 4: Implement momentum'</span><span class="p">)</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model2</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> The model2 parameters before the update are: </span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">print_params</span><span class="p">(</span><span class="n">model2</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model2</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="n">initial_vel</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">randn_like</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model2</span><span class="o">.</span><span class="n">parameters</span><span class="p">()]</span>

<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># momentum_update(loss, list(model2.parameters()), grad_vel=initial_vel, lr=1e-1, beta=0.9)</span>
<span class="c1"># print('\n The model2 parameters after the update are: \n')</span>
<span class="c1"># print_params(model2)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.

 The model2 parameters before the update are: 

main.0.weight tensor([[-0.0264,  0.0010,  0.0173,  ...,  0.0297,  0.0278, -0.0221],
        [-0.0040, -0.0295, -0.0086,  ..., -0.0070,  0.0254, -0.0233],
        [ 0.0240, -0.0231,  0.0342,  ...,  0.0124,  0.0270, -0.0180],
        ...,
        [-0.0005,  0.0157,  0.0111,  ...,  0.0144, -0.0301, -0.0144],
        [ 0.0181,  0.0303,  0.0255,  ..., -0.0110, -0.0175,  0.0205],
        [ 0.0208, -0.0353, -0.0183,  ..., -0.0271,  0.0099,  0.0003]])
main.0.bias tensor([-0.0290, -0.0033,  0.0100, -0.0320,  0.0022,  0.0221,  0.0307,  0.0243,
         0.0159, -0.0064])
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_ba72f88a.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">The</span> <span class="n">model2</span> <span class="n">parameters</span> <span class="n">after</span> <span class="n">the</span> <span class="n">update</span> <span class="n">are</span><span class="p">:</span> 

<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">weight</span> <span class="n">tensor</span><span class="p">([[</span> <span class="mf">1.5898</span><span class="p">,</span>  <span class="mf">0.0116</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.0239</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0871</span><span class="p">,</span>  <span class="mf">0.4030</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9577</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.4653</span><span class="p">,</span>  <span class="mf">0.6022</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.7363</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.5485</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2747</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.6539</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.4117</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.1045</span><span class="p">,</span>  <span class="mf">0.6492</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0201</span><span class="p">,</span>  <span class="mf">0.6503</span><span class="p">,</span>  <span class="mf">0.1310</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.5098</span><span class="p">,</span>  <span class="mf">0.5075</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0718</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">1.1192</span><span class="p">,</span>  <span class="mf">0.2900</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9657</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.4405</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1174</span><span class="p">,</span>  <span class="mf">0.7542</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0792</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1857</span><span class="p">,</span>  <span class="mf">0.3537</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">1.0824</span><span class="p">,</span>  <span class="mf">1.0080</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.4254</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.3760</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.7491</span><span class="p">,</span>  <span class="mf">0.6025</span><span class="p">]])</span>
<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">bias</span> <span class="n">tensor</span><span class="p">([</span> <span class="mf">0.4147</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.0440</span><span class="p">,</span>  <span class="mf">0.8720</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.6201</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.9632</span><span class="p">,</span>  <span class="mf">0.9430</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5180</span><span class="p">,</span>  <span class="mf">1.3417</span><span class="p">,</span>
         <span class="mf">0.6574</span><span class="p">,</span>  <span class="mf">0.3677</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="interactive-demo-4-momentum-vs-gd">
<h2>Interactive Demo 4: Momentum vs. GD<a class="headerlink" href="#interactive-demo-4-momentum-vs-gd" title="Permalink to this headline">Â¶</a></h2>
<p>The plots below show the distance to the optimum for both variables across the two methods, as well as the parameter trajectory over the loss surface.</p>
<p>Run this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Run this cell to enable the widget!</span>
<span class="kn">from</span> <span class="nn">matplotlib.lines</span> <span class="kn">import</span> <span class="n">Line2D</span>

<span class="c1"># Find the optimum of this 2D problem using Newton's method</span>
<span class="k">def</span> <span class="nf">run_newton</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">init_list</span><span class="o">=</span><span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">200</span><span class="p">):</span>

  <span class="n">par_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">init_list</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">t_g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">par_tensor</span><span class="p">:</span> <span class="n">func</span><span class="p">(</span><span class="n">par_tensor</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">par_tensor</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_iter</span><span class="p">)):</span>
    <span class="n">eval_loss</span> <span class="o">=</span> <span class="n">t_g</span><span class="p">(</span><span class="n">par_tensor</span><span class="p">)</span>
    <span class="n">eval_grad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">eval_loss</span><span class="p">,</span> <span class="p">[</span><span class="n">par_tensor</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">eval_hess</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">t_g</span><span class="p">,</span> <span class="n">par_tensor</span><span class="p">)</span>
    <span class="c1"># Newton's update is:  - inverse(Hessian) x gradient</span>
    <span class="n">par_tensor</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">torch</span><span class="o">.</span><span class="n">inverse</span><span class="p">(</span><span class="n">eval_hess</span><span class="p">)</span> <span class="o">@</span> <span class="n">eval_grad</span>

  <span class="k">return</span> <span class="n">par_tensor</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>


<span class="n">set_seed</span><span class="p">(</span><span class="mi">2021</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>
<span class="c1"># Define 2d loss objectives and surface values</span>
<span class="n">g</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">:</span> <span class="n">loss_2d</span><span class="p">(</span><span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="p">),</span> <span class="n">u</span><span class="p">,</span> <span class="n">v</span><span class="p">)</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fromiter</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">U</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">V</span><span class="o">.</span><span class="n">ravel</span><span class="p">()),</span> <span class="n">U</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">V</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">best_u</span><span class="p">,</span> <span class="n">best_v</span>  <span class="o">=</span> <span class="n">run_newton</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">g</span><span class="p">)</span>

<span class="c1"># Initialization of the variables</span>
<span class="n">INITS</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">3.7</span><span class="p">]</span>

<span class="c1"># Used for plotting</span>
<span class="n">LABELS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'GD'</span><span class="p">,</span> <span class="s1">'Momentum'</span><span class="p">]</span>
<span class="n">COLORS</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'black'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">]</span>
<span class="n">LSTYLES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'-'</span><span class="p">,</span> <span class="s1">'--'</span><span class="p">]</span>


<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact_manual</span>
<span class="k">def</span> <span class="nf">momentum_experiment</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">300</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
                        <span class="n">lr</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatLogSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">1e-1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
                        <span class="n">beta</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">9e-1</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
                        <span class="p">):</span>

  <span class="c1"># Execute both optimizers</span>
  <span class="n">sgd_traj</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span><span class="n">INITS</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="n">g</span><span class="p">,</span> <span class="n">update_fn</span><span class="o">=</span><span class="n">gradient_update</span><span class="p">,</span>
                           <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">optim_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">})</span>
  <span class="n">mom_traj</span> <span class="o">=</span> <span class="n">run_optimizer</span><span class="p">(</span><span class="n">INITS</span><span class="p">,</span> <span class="n">eval_fn</span><span class="o">=</span><span class="n">g</span><span class="p">,</span> <span class="n">update_fn</span><span class="o">=</span><span class="n">momentum_update</span><span class="p">,</span>
                           <span class="n">max_steps</span><span class="o">=</span><span class="n">max_steps</span><span class="p">,</span> <span class="n">optim_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">'beta'</span><span class="p">:</span><span class="n">beta</span><span class="p">})</span>

  <span class="n">TRAJS</span> <span class="o">=</span> <span class="p">[</span><span class="n">sgd_traj</span><span class="p">,</span> <span class="n">mom_traj</span><span class="p">]</span>

  <span class="c1"># Plot distances</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">plot_param_distance</span><span class="p">(</span><span class="n">best_u</span><span class="p">,</span> <span class="n">best_v</span><span class="p">,</span> <span class="n">TRAJS</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span>
                      <span class="n">LSTYLES</span><span class="p">,</span> <span class="n">LABELS</span><span class="p">,</span> <span class="n">use_log</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">y_min_v</span><span class="o">=-</span><span class="mf">12.0</span><span class="p">,</span> <span class="n">y_max_v</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>

  <span class="c1"># # Plot trajectories</span>
  <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
  <span class="n">ax</span> <span class="o">=</span> <span class="n">plot_surface</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">fig</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">traj</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">TRAJS</span><span class="p">,</span> <span class="n">COLORS</span><span class="p">,</span> <span class="n">LABELS</span><span class="p">):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot3D</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter3D</span><span class="p">(</span><span class="o">*</span><span class="n">traj</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">'.-'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">c</span><span class="p">)</span>

  <span class="c1"># Plot optimum point</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">best_u</span><span class="p">,</span> <span class="n">best_v</span><span class="p">,</span> <span class="n">Z</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'*'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">80</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">'lime'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Opt.'</span><span class="p">);</span>
  <span class="n">lines</span> <span class="o">=</span> <span class="p">[</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                  <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span>
                  <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                  <span class="n">linestyle</span><span class="o">=</span><span class="s1">'--'</span><span class="p">)</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">COLORS</span><span class="p">]</span>
  <span class="n">lines</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Line2D</span><span class="p">([</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">'lime'</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">'*'</span><span class="p">))</span>
  <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">LABELS</span> <span class="o">+</span> <span class="p">[</span><span class="s1">'Optimum'</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">'right'</span><span class="p">,</span>
            <span class="n">bbox_to_anchor</span><span class="o">=</span><span class="p">(</span><span class="mf">.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.1</span><span class="p">),</span> <span class="n">ncol</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">LABELS</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "38365d55fe4b4de0a7966b179a12df8d"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "5732c66e76c1412b87386107e94d99be"}
</script></div>
</div>
</div>
<div class="section" id="think-4-momentum-and-oscillations">
<h2>Think! 4: Momentum and oscillations<a class="headerlink" href="#think-4-momentum-and-oscillations" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>Discuss how this specific example illustrates the issue of poor conditioning in optimization? How does momentum help resolve these difficulties?</p></li>
<li><p>Do you see oscillations for any of these methods? Why does this happen?</p></li>
<li><p>Finally, tune the learning rate and momentum parameters to achieve a loss below <span class="math notranslate nohighlight">\(10^{-6}\)</span> (for both dimensions) within 100 iterations.</p></li>
</ul>
<div class="section" id="id1">
<h3>Student Response<a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q2'</span> <span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>


<span class="n">button</span><span class="o">.</span><span class="n">on_click</span><span class="p">(</span><span class="n">on_button_clicked</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "64ea82c3e980469f815075615f8e001f"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "8f8780098fdc4abb845b27d35a1f40ed"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_5eaa9306.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-5-non-convexity">
<h1>Section 5: Non-convexity<a class="headerlink" href="#section-5-non-convexity" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~30 mins</em></p>
<p>The introduction of even just 1 hidden layer in the neural network transforms the previous convex optimization problem into a non-convex one. And with great non-convexity, comes great responsibilityâ€¦ (Sorry, we couldnâ€™t help it!)</p>
<p><strong>Note:</strong> From this section onwards we will be dealing with non-convex optimization problems for the remaining of the tutorial.</p>
<div class="section" id="video-5-overparametrization">
<h2>Video 5: Overparametrization<a class="headerlink" href="#video-5-overparametrization" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "95b18ce290194661b2d73b20245a5d2e"}
</script></div>
</div>
<p>Take a couple of minutes to play with a more complex 3D visualization of the loss landscape of a neural network on a non-convex problem. Visit https://losslandscape.com/explorer.</p>
<ol class="simple">
<li><p>Explore the features on the bottom left corner. You can see an explanation for each icon by clicking on the [i] button located on the top right corner.</p></li>
<li><p>Use the â€˜gradient descentâ€™ feature to perform a thought experiment:</p>
<ul class="simple">
<li><p>Choose an initialization</p></li>
<li><p>Choose the learning rate</p></li>
<li><p>Mentally formulate your hypothesis about what kind of trajectory you expect to observe</p></li>
</ul>
</li>
<li><p>Run the experiment and contrast your intuition with the observed behavior.</p></li>
<li><p>Repeat this experiment a handful of times for several initialization/learning rate configurations</p></li>
</ol>
</div>
<div class="section" id="interactive-demo-5-overparametrization-to-the-rescue">
<h2>Interactive Demo 5: Overparametrization to the rescue!<a class="headerlink" href="#interactive-demo-5-overparametrization-to-the-rescue" title="Permalink to this headline">Â¶</a></h2>
<p>As you may have seen, the non-convex nature of the surface can lead the optimization process to get stuck in undesirable local-optima. There is ample empirical evidence supporting the claim that â€˜overparameterizedâ€™ models are easier to train.</p>
<p>We will explore this assertion in the context of our MLP training. For this, we initialize a fixed model and construct several models by small random perturbations to the original initialized weights. Now, we train each of these perturbed models and see how the loss evolves. If we were in the convex setting, we should reach very similar objective values upon convergence since all these models were very close at the beginning of training, and in convex problems, every local optimum is also a global optimum.</p>
<p>Use the interactive plot below to visualize the loss progression for these perturbed models:</p>
<ol class="simple">
<li><p>Select different settings from the <code class="docutils literal notranslate"><span class="pre">hidden_dims</span></code> drop-down menu.</p></li>
<li><p>Explore the effect of the number of steps and learning rate.</p></li>
</ol>
<p>Execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact_manual</span>
<span class="k">def</span> <span class="nf">overparam</span><span class="p">(</span><span class="n">max_steps</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
              <span class="n">hidden_dims</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Dropdown</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s2">"10"</span><span class="p">,</span> <span class="s2">"20, 20"</span><span class="p">,</span> <span class="s2">"100, 100"</span><span class="p">],</span>
                                           <span class="n">value</span><span class="o">=</span><span class="s2">"10"</span><span class="p">),</span>
              <span class="n">lr</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatLogSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">5e-2</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
              <span class="n">num_inits</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">IntSlider</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>

    <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">subset_index</span><span class="p">,</span> <span class="p">:],</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">[</span><span class="n">subset_index</span><span class="p">]</span>

    <span class="n">hdims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">hidden_dims</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)]</span>
    <span class="n">base_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="n">hdims</span><span class="p">)</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_inits</span><span class="p">)):</span>
      <span class="n">model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
      <span class="n">random_update</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">noise_scale</span><span class="o">=</span><span class="mf">2e-1</span><span class="p">)</span>

      <span class="n">loss_hist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">max_steps</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
      <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">gradient_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">loss_hist</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">step</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

      <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_hist</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">loss_hist</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">num_params</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Number of paramaters in model:  '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_params</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "24a999f5704c4d2894a367b61161f7b7"}
</script></div>
</div>
<div class="section" id="think-5-1-width-and-depth-of-the-network">
<h3>Think! 5.1: Width and depth of the network<a class="headerlink" href="#think-5-1-width-and-depth-of-the-network" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>We see that as we increase the width/depth of the network, training becomes faster and more consistent across different initializations. What might be the reasons for this behavior?</p></li>
<li><p>What are some potential downsides of this approach to dealing with non-convexity?</p></li>
</ul>
<div class="section" id="id2">
<h4>Student Response<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h4>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q3'</span> <span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "af9b7cc487e1437c83b04b66db8df023"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f544708f12cf4d71ba903660bb3a9e64"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_d69ca8d7.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-6-full-gradients-are-expensive">
<h1>Section 6: Full gradients are expensive<a class="headerlink" href="#section-6-full-gradients-are-expensive" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~25 mins</em></p>
<p>So far we have used only a small (fixed) subset of 500 training examples to perform the updates on the model parameters in our quest to minimize the loss. But what if we decided to use the training set? Do our current approach scale to datasets with tens of thousands, or millions of datapoints?</p>
<p>In this section we explore an efficient alternative to avoid having to perform computations on all the training examples before performing a parameter update.</p>
<div class="section" id="video-6-mini-batches">
<h2>Video 6: Mini-batches<a class="headerlink" href="#video-6-mini-batches" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "bafc1c687d314d938483cd22c50fdc26"}
</script></div>
</div>
</div>
<div class="section" id="interactive-demo-6-1-cost-of-computation">
<h2>Interactive Demo 6.1: Cost of computation<a class="headerlink" href="#interactive-demo-6-1-cost-of-computation" title="Permalink to this headline">Â¶</a></h2>
<p>Evaluating a neural network is a relatively fast process. However, when repeated millions of times, the computational cost of performing forward and backward passes through the network starts to become significant.</p>
<p>In the visualization below, we show the time (averaged over 5 runs) of computing a forward and backward pass with a changing number of input examples. Choose from the different options in the drop-down box and note how the vertical scale changes depending on the size of the network.</p>
<p><strong>Remarks:</strong> Note that the computational cost of a forward pass shows a clear linear relationship with the number of input examples, and the cost of the corresponding backward pass exhibits a similar computational complexity.</p>
<p>Execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget!</span>

<span class="k">def</span> <span class="nf">measure_update_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">num_points</span><span class="p">):</span>
  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">[:</span><span class="n">num_points</span><span class="p">],</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span><span class="p">[:</span><span class="n">num_points</span><span class="p">]</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
  <span class="n">loss_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">gradient_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()),</span> <span class="n">lr</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">gradient_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">loss_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span> <span class="n">gradient_time</span> <span class="o">-</span> <span class="n">loss_time</span>


<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact</span>
<span class="k">def</span> <span class="nf">computation_time</span><span class="p">(</span><span class="n">hidden_dims</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Dropdown</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s2">"1"</span><span class="p">,</span> <span class="s2">"100"</span><span class="p">,</span> <span class="s2">"50, 50"</span><span class="p">],</span>
                                                  <span class="n">value</span><span class="o">=</span><span class="s2">"100"</span><span class="p">)):</span>

  <span class="n">hdims</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">hidden_dims</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)]</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="n">hdims</span><span class="p">)</span>

  <span class="n">NUM_POINTS</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">5000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">20000</span><span class="p">,</span> <span class="mi">30000</span><span class="p">,</span> <span class="mi">50000</span><span class="p">]</span>
  <span class="n">times_list</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">times_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">measure_update_time</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">NUM_POINTS</span><span class="p">]))</span>

  <span class="n">times</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">times_list</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">NUM_POINTS</span><span class="p">,</span> <span class="n">times</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Forward'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">NUM_POINTS</span><span class="p">,</span> <span class="n">times</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Backward'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Number of data points'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Seconds'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d6bbf9ed6c134d168d3e40fca475723e"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-6-implement-minibatch-sampling">
<h2>Coding Exercise 6: Implement minibatch sampling<a class="headerlink" href="#coding-exercise-6-implement-minibatch-sampling" title="Permalink to this headline">Â¶</a></h2>
<p>Complete the code in <code class="docutils literal notranslate"><span class="pre">sample_minibatch</span></code> so as to produce IID subsets of the training set of the desired size. (This is <em>not</em> a trick question.)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sample_minibatch</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">num_points</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
  <span class="sd">"""Sample a minibatch of size num_point from the provided input-target data</span>

<span class="sd">  Args:</span>
<span class="sd">    input_data (tensor): Multi-dimensional tensor containing the input data</span>
<span class="sd">    target_data (tensor): 1D tensor containing the class labels</span>
<span class="sd">    num_points (int): Number of elements to be included in minibatch</span>

<span class="sd">  Returns:</span>
<span class="sd">    batch_inputs (tensor): Minibatch inputs</span>
<span class="sd">    batch_targets (tensor): Minibatch targets</span>
<span class="sd">  """</span>
  <span class="c1">#################################################</span>
  <span class="c1">## TODO for students: sample minibatch of data ##</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement gradient update"</span><span class="p">)</span>
  <span class="c1">#################################################</span>
  <span class="c1"># Sample a collection of IID indices from the existing data</span>
  <span class="n">batch_indices</span> <span class="o">=</span> <span class="o">...</span>
  <span class="c1"># Use batch_indices to extract entries from the input and target data tensors</span>
  <span class="n">batch_inputs</span> <span class="o">=</span> <span class="n">input_data</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>
  <span class="n">batch_targets</span> <span class="o">=</span> <span class="n">target_data</span><span class="p">[</span><span class="o">...</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">batch_inputs</span><span class="p">,</span> <span class="n">batch_targets</span>

<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 6: Implement minibatch sampling'</span><span class="p">)</span>


<span class="c1">## Uncomment to test your function</span>
<span class="c1"># x_batch, y_batch = sample_minibatch(X, y, num_points=100)</span>
<span class="c1"># print(f"The input shape is {x_batch.shape} and the target shape is: {y_batch.shape}")</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_6bf245d5.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">The</span> <span class="nb">input</span> <span class="n">shape</span> <span class="ow">is</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">])</span> <span class="ow">and</span> <span class="n">the</span> <span class="n">target</span> <span class="n">shape</span> <span class="ow">is</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="interactive-demo-6-2-compare-different-minibatch-sizes">
<h2>Interactive Demo 6.2: <em>Compare</em> different minibatch sizes<a class="headerlink" href="#interactive-demo-6-2-compare-different-minibatch-sizes" title="Permalink to this headline">Â¶</a></h2>
<p>What are the trade-offs induced by the choice of minibatch size? The interactive plot below shows the training evolution of a 2-hidden layer MLP with 100 hidden units in each hidden layer. Different plots correspond to a different choice of minibatch size. We have a fixed time budget for all the cases, reflected in the horizontal axes of these plots.</p>
<p>Execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget!</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact_manual</span>
<span class="k">def</span> <span class="nf">minibatch_experiment</span><span class="p">(</span><span class="n">batch_sizes</span><span class="o">=</span><span class="s1">'20, 250, 1000'</span><span class="p">,</span>
                         <span class="n">lrs</span><span class="o">=</span><span class="s1">'5e-3, 5e-3, 5e-3'</span><span class="p">,</span>
                         <span class="n">time_budget</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Dropdown</span><span class="p">(</span><span class="n">options</span><span class="o">=</span><span class="p">[</span><span class="s2">"2.5"</span><span class="p">,</span> <span class="s2">"5"</span><span class="p">,</span> <span class="s2">"10"</span><span class="p">],</span>
                                                      <span class="n">value</span><span class="o">=</span><span class="s2">"2.5"</span><span class="p">)):</span>

  <span class="n">batch_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">batch_sizes</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)]</span>
  <span class="n">lrs</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">lrs</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">','</span><span class="p">)]</span>

  <span class="n">LOSS_HIST</span> <span class="o">=</span> <span class="p">{</span><span class="n">_</span><span class="p">:[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">batch_sizes</span><span class="p">}</span>

  <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span>
  <span class="n">base_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>

  <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tqdm</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">)):</span>
    <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="c1"># Create a new copy of the model for each batch size</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="n">lrs</span><span class="p">[</span><span class="nb">id</span><span class="p">]</span>
    <span class="c1"># Fixed budget per choice of batch size</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span> <span class="o">&lt;</span> <span class="nb">float</span><span class="p">(</span><span class="n">time_budget</span><span class="p">):</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sample_minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
      <span class="n">gradient_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
      <span class="n">LOSS_HIST</span><span class="p">[</span><span class="n">batch_size</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">,</span>
                                    <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch_sizes</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">batch_size</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">batch_sizes</span><span class="p">):</span>
    <span class="n">plot_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">LOSS_HIST</span><span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plot_data</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">plot_data</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'Batch size: '</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">batch_size</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Seconds'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "bba84d1df7a140e79a6007f59680b9af"}
</script></div>
</div>
<p><strong>Remarks:</strong> SGD works! We have an algorithm that can be applied (with the due precautions) to learn datasets of arbitrary size.</p>
<p>However, <strong>note the diference in the vertical scale</strong> across the plots above. When using a larger minibatch, we can perform fewer parameter updates as the forward and backward passes are more expensive.</p>
<p>This highlights the interplay between the minibatch size and the learning rate: when our minibatch is larger, we have a more confident estimator of the direction to move, and thus can afford a larger learning rate. On the other hand, extremely small minibatches are very fast computationally but are not representative of the data distribution and yield estimations of the gradient with high variance.</p>
<p>We encourage you to tune the value of the learning rate for each of the minibatch sizes in the previous demo, to achieve a training loss steadily below 0.5 within 5 seconds.</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-7-adaptive-methods">
<h1>Section 7: Adaptive methods<a class="headerlink" href="#section-7-adaptive-methods" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~25 mins</em></p>
<p>As of now, you should be aware that there are many knobs to turn when working on a machine learning problem. Some of these relate to the optimization algorithm, to the choice of model, or to the objective to minimize. Here are some prototypical examples:</p>
<ul class="simple">
<li><p>Problem: loss function, regularization coefficients (Day 5)</p></li>
<li><p>Model: architecture, activations function</p></li>
<li><p>Optimizer: learning rate, batch size, momentum coefficient</p></li>
</ul>
<p>We concentrate on the choices that are directly related with optimization. In particular, we will explore some <em>automatic</em> methods for setting the learning rate, in a way that fixes the poor-conditioning problem and is robust across different problems.</p>
<div class="section" id="video-7-adaptive-methods">
<h2>Video 7: Adaptive Methods<a class="headerlink" href="#video-7-adaptive-methods" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "bb99ab7159af404f96a549e8dcbbe030"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-7-implement-rmsprop">
<h2>Coding Exercise 7: Implement RMSprop<a class="headerlink" href="#coding-exercise-7-implement-rmsprop" title="Permalink to this headline">Â¶</a></h2>
<p>In this exercise you will implement the update of the RMSprop optimizer:</p>
<div class="amsmath math notranslate nohighlight" id="equation-31242483-fdde-4724-94db-3c9c57fb689e">
<span class="eqno">(47)<a class="headerlink" href="#equation-31242483-fdde-4724-94db-3c9c57fb689e" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
v_{t} &amp;= \alpha v_{t-1} + (1 - \alpha) \nabla J(w_t)^2 \\ \\
w_{t+1} &amp;= w_t - \eta \frac{\nabla J(w_t)}{\sqrt{v_t + \epsilon}}
\end{align}\]</div>
<p>where the non-standard operations (division of two vectors, squaring a vector, etc) are to be interpreted as element-wise operations, i.e., the operation is applied to each (pair of) entry[ies] of the vector(s) considered as real number(s).</p>
<p>Here, the <span class="math notranslate nohighlight">\(\epsilon\)</span> hyperparameter provides numerical estability to the algorithm, by preventing the learning rate to become too big when <span class="math notranslate nohighlight">\(v_t\)</span> is small. Typically, we set <span class="math notranslate nohighlight">\(\epsilon\)</span> to a default small value, like <span class="math notranslate nohighlight">\(10^{-8}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rmsprop_update</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">grad_sq</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
  <span class="sd">"""Perform an RMSprop update on a collection of parameters</span>

<span class="sd">  Args:</span>
<span class="sd">    loss (tensor): A scalar tensor containing the loss whose gradient will be computed</span>
<span class="sd">    params (iterable): Collection of parameters with respect to which we compute gradients</span>
<span class="sd">    grad_sq (iterable): Moving average of squared gradients</span>
<span class="sd">    lr (float): Scalar specifying the learning rate or step-size for the update</span>
<span class="sd">    alpha (float): Moving average parameter</span>
<span class="sd">    epsilon (float): for numerical estability</span>
<span class="sd">  """</span>
  <span class="c1"># Clear up gradients as Pytorch automatically accumulates gradients from</span>
  <span class="c1"># successive backward calls</span>
  <span class="n">zero_grad</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
  <span class="c1"># Compute gradients on given objective</span>
  <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="p">(</span><span class="n">par</span><span class="p">,</span> <span class="n">gsq</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">grad_sq</span><span class="p">):</span>
      <span class="c1">#################################################</span>
      <span class="c1">## TODO for students: update the value of the parameter ##</span>
      <span class="c1"># Use gsq.data and par.grad</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Student exercise: implement gradient update"</span><span class="p">)</span>
      <span class="c1">#################################################</span>
      <span class="c1"># Update estimate of gradient variance</span>
      <span class="n">gsq</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="o">...</span>
      <span class="c1"># Update parameters</span>
      <span class="n">par</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span>  <span class="o">...</span>


<span class="c1"># add event to airtable</span>
<span class="n">atform</span><span class="o">.</span><span class="n">add_event</span><span class="p">(</span><span class="s1">'Coding Exercise 7: Implement RMSprop'</span><span class="p">)</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">model3</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1"> The model3 parameters before the update are: </span><span class="se">\n</span><span class="s1">'</span><span class="p">)</span>
<span class="n">print_params</span><span class="p">(</span><span class="n">model3</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model3</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">y</span><span class="p">)</span>
<span class="c1"># Intialize the moving average of squared gradients</span>
<span class="n">grad_sq</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-6</span><span class="o">*</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">model3</span><span class="o">.</span><span class="n">parameters</span><span class="p">())]</span>



<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># rmsprop_update(loss, list(model3.parameters()), grad_sq=grad_sq, lr=1e-3)</span>
<span class="c1"># print('\n The model3 parameters after the update are: \n')</span>
<span class="c1"># print_params(model3)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.

 The model3 parameters before the update are: 

main.0.weight tensor([[-0.0264,  0.0010,  0.0173,  ...,  0.0297,  0.0278, -0.0221],
        [-0.0040, -0.0295, -0.0086,  ..., -0.0070,  0.0254, -0.0233],
        [ 0.0240, -0.0231,  0.0342,  ...,  0.0124,  0.0270, -0.0180],
        ...,
        [-0.0005,  0.0157,  0.0111,  ...,  0.0144, -0.0301, -0.0144],
        [ 0.0181,  0.0303,  0.0255,  ..., -0.0110, -0.0175,  0.0205],
        [ 0.0208, -0.0353, -0.0183,  ..., -0.0271,  0.0099,  0.0003]])
main.0.bias tensor([-0.0290, -0.0033,  0.0100, -0.0320,  0.0022,  0.0221,  0.0307,  0.0243,
         0.0159, -0.0064])
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_b4a7e579.py"><em>Click for solution</em></a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span> <span class="n">The</span> <span class="n">model3</span> <span class="n">parameters</span> <span class="n">after</span> <span class="n">the</span> <span class="n">update</span> <span class="n">are</span><span class="p">:</span> 

<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">weight</span> <span class="n">tensor</span><span class="p">([[</span><span class="o">-</span><span class="mf">0.0240</span><span class="p">,</span>  <span class="mf">0.0031</span><span class="p">,</span>  <span class="mf">0.0193</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0316</span><span class="p">,</span>  <span class="mf">0.0297</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0198</span><span class="p">],</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0063</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0318</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0109</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0093</span><span class="p">,</span>  <span class="mf">0.0232</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0255</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0218</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0253</span><span class="p">,</span>  <span class="mf">0.0320</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0102</span><span class="p">,</span>  <span class="mf">0.0248</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0203</span><span class="p">],</span>
        <span class="o">...</span><span class="p">,</span>
        <span class="p">[</span><span class="o">-</span><span class="mf">0.0027</span><span class="p">,</span>  <span class="mf">0.0136</span><span class="p">,</span>  <span class="mf">0.0089</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span>  <span class="mf">0.0123</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0324</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0166</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0159</span><span class="p">,</span>  <span class="mf">0.0281</span><span class="p">,</span>  <span class="mf">0.0233</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0133</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0197</span><span class="p">,</span>  <span class="mf">0.0182</span><span class="p">],</span>
        <span class="p">[</span> <span class="mf">0.0186</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0376</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0205</span><span class="p">,</span>  <span class="o">...</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0293</span><span class="p">,</span>  <span class="mf">0.0077</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0019</span><span class="p">]])</span>
<span class="n">main</span><span class="mf">.0</span><span class="o">.</span><span class="n">bias</span> <span class="n">tensor</span><span class="p">([</span><span class="o">-</span><span class="mf">0.0313</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0011</span><span class="p">,</span>  <span class="mf">0.0122</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0342</span><span class="p">,</span>  <span class="mf">0.0045</span><span class="p">,</span>  <span class="mf">0.0199</span><span class="p">,</span>  <span class="mf">0.0329</span><span class="p">,</span>  <span class="mf">0.0265</span><span class="p">,</span>
         <span class="mf">0.0182</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0041</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="section" id="interactive-demo-7-compare-optimizers">
<h2>Interactive Demo 7: Compare optimizers<a class="headerlink" href="#interactive-demo-7-compare-optimizers" title="Permalink to this headline">Â¶</a></h2>
<p>Below, we compare your implementations of SGD, momentum and RMSprop. If you have successfully coded all the exercises so far: congrats! You are now <em>in the know</em> of some of the most commonly used and powerful tools of optimization for deep learning.</p>
<p>Execute this cell to enable the widget!</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @markdown Execute this cell to enable the widget!</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_set</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">train_set</span><span class="o">.</span><span class="n">targets</span>

<span class="nd">@widgets</span><span class="o">.</span><span class="n">interact_manual</span>
<span class="k">def</span> <span class="nf">compare_optimizers</span><span class="p">(</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">250</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">lr</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatLogSlider</span><span class="p">(</span><span class="n">value</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">5</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span>
    <span class="n">max_steps</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">5</span><span class="p">)):</span>

  <span class="n">SGD_DICT</span> <span class="o">=</span> <span class="p">[</span><span class="n">gradient_update</span><span class="p">,</span> <span class="s1">'SGD'</span><span class="p">,</span> <span class="s1">'black'</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">}]</span>
  <span class="n">MOM_DICT</span> <span class="o">=</span> <span class="p">[</span><span class="n">momentum_update</span><span class="p">,</span> <span class="s1">'Momentum'</span><span class="p">,</span> <span class="s1">'red'</span><span class="p">,</span> <span class="s1">'--'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">'beta'</span><span class="p">:</span> <span class="mf">0.9</span><span class="p">}]</span>
  <span class="n">RMS_DICT</span> <span class="o">=</span> <span class="p">[</span><span class="n">rmsprop_update</span><span class="p">,</span> <span class="s1">'RMSprop'</span><span class="p">,</span> <span class="s1">'fuchsia'</span><span class="p">,</span> <span class="s1">'-'</span><span class="p">,</span> <span class="p">{</span><span class="s1">'lr'</span><span class="p">:</span> <span class="n">lr</span><span class="p">,</span> <span class="s1">'alpha'</span><span class="p">:</span> <span class="mf">0.8</span><span class="p">}]</span>

  <span class="n">ALL_DICTS</span> <span class="o">=</span> <span class="p">[</span><span class="n">SGD_DICT</span><span class="p">,</span> <span class="n">MOM_DICT</span><span class="p">,</span> <span class="n">RMS_DICT</span><span class="p">]</span>

  <span class="n">base_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>

  <span class="n">LOSS_HIST</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">for</span> <span class="n">opt_dict</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">ALL_DICTS</span><span class="p">):</span>
    <span class="n">update_fn</span><span class="p">,</span> <span class="n">opt_name</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">lstyle</span><span class="p">,</span> <span class="n">kwargs</span> <span class="o">=</span> <span class="n">opt_dict</span>
    <span class="n">LOSS_HIST</span><span class="p">[</span><span class="n">opt_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
    <span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">opt_name</span> <span class="o">!=</span> <span class="s1">'SGD'</span><span class="p">:</span>
      <span class="n">aux_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">_</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">params</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">):</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">sample_minibatch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
      <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">labels</span><span class="p">)</span>
      <span class="k">if</span> <span class="n">opt_name</span> <span class="o">==</span> <span class="s1">'SGD'</span><span class="p">:</span>
        <span class="n">update_fn</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
      <span class="k">else</span><span class="p">:</span>
        <span class="n">update_fn</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">aux_tensors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
      <span class="n">LOSS_HIST</span><span class="p">[</span><span class="n">opt_name</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

  <span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ALL_DICTS</span><span class="p">),</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">optim_dict</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axs</span><span class="p">,</span> <span class="n">ALL_DICTS</span><span class="p">):</span>
    <span class="n">opt_name</span> <span class="o">=</span> <span class="n">optim_dict</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">max_steps</span><span class="p">),</span> <span class="n">LOSS_HIST</span><span class="p">[</span><span class="n">opt_name</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">opt_name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0070a41cf4284e41b07b4f31f5758220"}
</script></div>
</div>
<div class="section" id="discussion">
<h3><strong>Discussion</strong><a class="headerlink" href="#discussion" title="Permalink to this headline">Â¶</a></h3>
<p>Tune the 3 methods above in order to make each individually excel and discuss your findings. How do the methods compare in terms of robustness to small changes of the hyperparameters? How easy was it to find a good hyperparameter configuration?</p>
<p><strong>Remarks:</strong> Note that RMSprop is allowing us to use a â€˜per-dimensionâ€™ learning rate <em>without having to tune one learning rate for each dimension <strong>ourselves</strong></em>. The method uses information collected about the variance of the gradients throughout training to <strong>adapt</strong> the step size for each of the parameters automatically. The savings in tuning efforts of RMSprop over SGD or â€˜plainâ€™ momentum are undisputed on this task.</p>
<p>Moreover, adaptive optimization methods are currently a highly active research domain, with many related algorithms like Adam, AMSgrad, Adagrad being used in practical application and theoretically investigated.</p>
</div>
<div class="section" id="locality-of-gradients">
<h3>Locality of Gradients<a class="headerlink" href="#locality-of-gradients" title="Permalink to this headline">Â¶</a></h3>
<p>As weâ€™ve seen throught this tutorial, poor conditioning can be a significant burden on convergence to an optimum while using gradient based optimization. Of the methods weâ€™ve seen to deal with this issue, notice how both momentum and adaptive learning rates incorperate past gradient values into their update schemes. Why do we use past values of our loss functionâ€™s gradient while updating our current MLP weights?</p>
<p>Recall from W1D2 that the gradient of a function, <span class="math notranslate nohighlight">\(\nabla f(w_t)\)</span>, is a <strong>local</strong> property and computes the direction of maximum change of <span class="math notranslate nohighlight">\(f(w_t)\)</span> at the point <span class="math notranslate nohighlight">\(w_t\)</span>. However, when we train our MLP model we are hoping to find the <strong>global</strong> optimum for our training loss. By incorperating past values of our functionâ€™s gradient into our optimization schemes, we use more information about the overall shape of our function than just a single gradient alone can provide.</p>
</div>
</div>
<div class="section" id="think-7-loss-function-and-optimization">
<h2>Think! 7: Loss function and optimization<a class="headerlink" href="#think-7-loss-function-and-optimization" title="Permalink to this headline">Â¶</a></h2>
<p>Can you think of other ways we can incorperate more information about our loss function into our optimization schemes?</p>
<div class="section" id="id3">
<h3>Student Response<a class="headerlink" href="#id3" title="Permalink to this headline">Â¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Student Response</span>
<span class="kn">from</span> <span class="nn">ipywidgets</span> <span class="kn">import</span> <span class="n">widgets</span>


<span class="n">text</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">Textarea</span><span class="p">(</span>
   <span class="n">value</span><span class="o">=</span><span class="s1">'Type your answer here and click on `Submit!`'</span><span class="p">,</span>
   <span class="n">placeholder</span><span class="o">=</span><span class="s1">'Type something'</span><span class="p">,</span>
   <span class="n">description</span><span class="o">=</span><span class="s1">''</span><span class="p">,</span>
   <span class="n">disabled</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">button</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Button</span><span class="p">(</span><span class="n">description</span><span class="o">=</span><span class="s2">"Submit!"</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">text</span><span class="p">,</span><span class="n">button</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_button_clicked</span><span class="p">(</span><span class="n">b</span><span class="p">):</span>
   <span class="n">atform</span><span class="o">.</span><span class="n">add_answer</span><span class="p">(</span><span class="s1">'q4'</span> <span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">value</span><span class="p">)</span>
   <span class="nb">print</span><span class="p">(</span><span class="s2">"Submission successful!"</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "63f3302bb46b4edd98d62ba9a169a939"}
</script><script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0130473646ea43648b6862fe678d4425"}
</script></div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_a3f4354b.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-8-ethical-concerns">
<h1>Section 8: Ethical concerns<a class="headerlink" href="#section-8-ethical-concerns" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~15mins</em></p>
<div class="section" id="video-8-ethical-concerns">
<h2>Video 8: Ethical concerns<a class="headerlink" href="#video-8-ethical-concerns" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "e2464164d4614fe49450f6d8536fa36d"}
</script></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">Â¶</a></h1>
<ul class="simple">
<li><p>Optimization is necessary to create Deep Learning models that are guaranteed to converge</p></li>
<li><p>Stochastic Gradient Descent and Momentum are two commonly used optimization techniques</p></li>
<li><p>RMSProp is a way of adaptive hyper parameter tuning which utilises a per-dimension learning rate</p></li>
<li><p>Poor choice of optimization objectives can lead to unforeseen, undesirable consequences</p></li>
</ul>
<p>If you have time left, you can read the Bonus material, were we put all together and we compare our model with a benchmark model.</p>
<div class="section" id="airtable-submission-link">
<h2>Airtable Submission Link<a class="headerlink" href="#airtable-submission-link" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Airtable Submission Link</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> <span class="k">as</span> <span class="n">IPydisplay</span>
<span class="n">IPydisplay</span><span class="o">.</span><span class="n">HTML</span><span class="p">(</span>
   <span class="sa">f</span><span class="s2">"""</span>
<span class="s2"> &lt;div&gt;</span>
<span class="s2">   &lt;a href= "</span><span class="si">{</span><span class="n">atform</span><span class="o">.</span><span class="n">url</span><span class="p">()</span><span class="si">}</span><span class="s2">" target="_blank"&gt;</span>
<span class="s2">   &lt;img src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1"</span>
<span class="s2"> alt="button link end of day Survey" style="width:410px"&gt;&lt;/a&gt;</span>
<span class="s2">   &lt;/div&gt;"""</span> <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
<div>
<a href="https://portal.neuromatchacademy.org/api/redirect/to/9548a279-c9f9-4586-b89c-f0ceceba5c14?data=eyJmb3JtX2lkIjogImFwcG43VmRQUnNlU29NWEVHIiwgInRhYmxlX25hbWUiOiAiVzFENF9UMSIsICJhbnN3ZXJzIjoge30sICJldmVudHMiOiBbeyJldmVudCI6ICJpbml0IiwgInRzIjogMTYyOTU2MzI3Mi40NzE1NDYyfSwgeyJldmVudCI6ICJWaWRlbyAxOiBJbnRyb2R1Y3Rpb24iLCAidHMiOiAxNjI5NTYzMjczLjMyMjY4MzZ9LCB7ImV2ZW50IjogIlZpZGVvIDI6IENhc2UgU3R1ZHkgLSBNTFAgQ2xhc3NpZmljYXRpb24iLCAidHMiOiAxNjI5NTYzMjczLjQwMTg2NDN9LCB7ImV2ZW50IjogIlZpZGVvIDM6IE9wdGltaXphdGlvbiBvZiBhbiBPYmplY3RpdmUgRnVuY3Rpb24iLCAidHMiOiAxNjI5NTYzMjg3LjczMjgzODZ9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSAzOiBJbXBsZW1lbnQgZ3JhZGllbnQgZGVzY2VudCIsICJ0cyI6IDE2Mjk1NjMyODcuNzU5NTc5NH0sIHsiZXZlbnQiOiAiVmlkZW8gNDogTW9tZW50dW0iLCAidHMiOiAxNjI5NTYzMjg4LjI5OTgxODh9LCB7ImV2ZW50IjogIkNvZGluZyBFeGVyY2lzZSA0OiBJbXBsZW1lbnQgbW9tZW50dW0iLCAidHMiOiAxNjI5NTYzMjg4LjM0MjU2NX0sIHsiZXZlbnQiOiAiVmlkZW8gNTogT3ZlcnBhcmFtZXRyaXphdGlvbiIsICJ0cyI6IDE2Mjk1NjMyOTAuMjg3MDI0NX0sIHsiZXZlbnQiOiAiVmlkZW8gNjogTWluaS1iYXRjaGVzIiwgInRzIjogMTYyOTU2MzI5MC40NjM2NTE0fSwgeyJldmVudCI6ICJDb2RpbmcgRXhlcmNpc2UgNjogSW1wbGVtZW50IG1pbmliYXRjaCBzYW1wbGluZyIsICJ0cyI6IDE2Mjk1NjMyOTAuNTMzMjc5Mn0sIHsiZXZlbnQiOiAiVmlkZW8gNzogQWRhcHRpdmUgTWV0aG9kcyIsICJ0cyI6IDE2Mjk1NjMyOTAuNjY0NTE0NX0sIHsiZXZlbnQiOiAiQ29kaW5nIEV4ZXJjaXNlIDc6IEltcGxlbWVudCBSTVNwcm9wIiwgInRzIjogMTYyOTU2MzI5MC42ODUxMjE4fSwgeyJldmVudCI6ICJWaWRlbyA4OiBFdGhpY2FsIGNvbmNlcm5zIiwgInRzIjogMTYyOTU2MzI5MC44NDQ0ODd9LCB7ImV2ZW50IjogInVybCBnZW5lcmF0ZWQiLCAidHMiOiAxNjI5NTYzMjkwLjg2MDQ0NH1dfQ%3D%3D" target="_blank">
<img alt="button link end of day Survey" src="https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1" style="width:410px"/></a>
</div></div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="bonus-putting-it-all-together">
<h1>Bonus: Putting it all together<a class="headerlink" href="#bonus-putting-it-all-together" title="Permalink to this headline">Â¶</a></h1>
<p><em>Time estimate: ~40 mins</em></p>
<p>We have progressively built a sophisticated optimization algorithm which is able to deal with a non-convex, poor-conditioned problem concerning tens of thousands of training examples. Now we present <em>you</em> with a small challenge: beat us! :P</p>
<p>Your mission is to train an MLP model that can compete with a benchmark model which we have pre-trained for you. In this section you will be able to use the full Pytorch power: loading the data, defining the model, sampling minibatches as well as Pytorchâ€™s <strong>optimizer implementations</strong>.</p>
<p>There is a big engineering component behind the design of optimizers and their implementation can sometimes become tricky. So unless you are directly doing research in optimization, itâ€™s recommended to use an implementation provided by a widely reviewed open-source library.</p>
<div class="section" id="video-9-putting-it-all-together">
<h2>Video 9: Putting it all together<a class="headerlink" href="#video-9-putting-it-all-together" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "6dc27c6cdd344015841676e53afe1fa9"}
</script></div>
</div>
</div>
<div class="section" id="download-parameters-of-the-benchmark-model">
<h2>Download parameters of the benchmark model<a class="headerlink" href="#download-parameters-of-the-benchmark-model" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Download parameters of the benchmark model</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s1">'benchmark_model.pt'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"https://osf.io/sj4e8/download"</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
  <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>

<span class="c1"># Load the benchmark model's parameters</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
<span class="k">if</span> <span class="n">DEVICE</span> <span class="o">==</span> <span class="s2">"cuda"</span><span class="p">:</span>
  <span class="n">benchmark_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
  <span class="n">benchmark_state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="n">map_location</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">'cpu'</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create MLP object and update weights with those of saved model</span>
<span class="n">benchmark_model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                      <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">benchmark_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">benchmark_state_dict</span><span class="p">)</span>


<span class="c1"># Define helper function to evaluate models</span>
<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data_loader</span><span class="p">,</span> <span class="n">num_batches</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">'cpu'</span><span class="p">):</span>

  <span class="n">loss_log</span><span class="p">,</span> <span class="n">acc_log</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

  <span class="c1"># We are just evaluating the model, no need to compute gradients</span>
  <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
      <span class="c1"># If we only evaluate a number of batches, stop after we reach that number</span>
      <span class="k">if</span> <span class="n">batch_id</span> <span class="o">&gt;</span> <span class="n">num_batches</span><span class="p">:</span>
        <span class="k">break</span>
      <span class="c1"># Extract minibatch data</span>
      <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="c1"># Evaluate model and loss on minibatch</span>
      <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
      <span class="n">loss_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
      <span class="n">acc_log</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mf">1.</span> <span class="o">*</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

  <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">loss_log</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">acc_log</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We define an optimizer in the following steps:</p>
<ol class="simple">
<li><p>Load  the corresponding class that implements the parameter updates and other internal management activities, including:</p>
<ul class="simple">
<li><p>create auxiliary variables,</p></li>
<li><p>update moving averages,</p></li>
<li><p>adjust learning rate.</p></li>
</ul>
</li>
<li><p>Pass the parameters of the Pytorch model that the optimizer has control over. Note that different parameter groups can potentially be controlled by different optimizers.</p></li>
<li><p>Specify hyperparameters, including learning rate, momentum, moving average factors, etc.</p></li>
</ol>
</div>
<div class="section" id="exercise-bonus-train-your-own-model">
<h2>Exercise Bonus: Train your own model<a class="headerlink" href="#exercise-bonus-train-your-own-model" title="Permalink to this headline">Â¶</a></h2>
<p>Now, train the model with your preferred optimizer and find a good combination of hyperparameter settings.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#################################################</span>
<span class="c1">## TODO for students: adjust training settings ##</span>

<span class="c1"># The three parameters below are in your full control</span>
<span class="n">MAX_EPOCHS</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># select number of epochs to train</span>
<span class="n">LR</span> <span class="o">=</span> <span class="mf">1e-5</span>  <span class="c1"># choose the step size</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">64</span>  <span class="c1"># number of examples per minibatch</span>

<span class="c1"># Define the model and associated optimizer -- you may change its architecture!</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">MLP</span><span class="p">(</span><span class="n">in_dim</span><span class="o">=</span><span class="mi">784</span><span class="p">,</span> <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">hidden_dims</span><span class="o">=</span><span class="p">[</span><span class="mi">200</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">50</span><span class="p">])</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># You can take your pick from many different optimizers</span>
<span class="c1"># Check the optimizer documentation and hyperparameter meaning before using!</span>
<span class="c1"># More details on Pytorch optimizers: https://pytorch.org/docs/stable/optim.html</span>
<span class="c1"># optimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)</span>
<span class="c1"># optimizer = torch.optim.RMSprop(model.parameters(), lr=LR, alpha=0.99)</span>
<span class="c1"># optimizer = torch.optim.Adagrad(model.parameters(), lr=LR)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">LR</span><span class="p">)</span>
<span class="c1">#################################################</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1"># Print trainig stats every LOG_FREQ minibatches</span>
<span class="n">LOG_FREQ</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># Frequency for evaluating the validation metrics</span>
<span class="n">VAL_FREQ</span> <span class="o">=</span> <span class="mi">200</span>
<span class="c1"># Load data using a Pytorch Dataset</span>
<span class="n">train_set_orig</span><span class="p">,</span> <span class="n">test_set_orig</span> <span class="o">=</span> <span class="n">load_mnist_data</span><span class="p">(</span><span class="n">change_tensors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># We separate 10,000 training samples to create a validation set</span>
<span class="n">train_set_orig</span><span class="p">,</span> <span class="n">val_set_orig</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">random_split</span><span class="p">(</span><span class="n">train_set_orig</span><span class="p">,</span> <span class="p">[</span><span class="mi">50000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">])</span>

<span class="c1"># Create the corresponding DataLoaders for training and test</span>
<span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">train_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">train_set_orig</span><span class="p">,</span>
                                           <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                           <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span>
                                           <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                           <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                           <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
<span class="n">val_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_set_orig</span><span class="p">,</span>
                                         <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                         <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                         <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                         <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                         <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">test_set_orig</span><span class="p">,</span>
                                          <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                                          <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                                          <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                          <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

<span class="c1"># Run training</span>
<span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'train_loss'</span><span class="p">:[],</span>
           <span class="s1">'train_acc'</span><span class="p">:[],</span>
           <span class="s1">'val_loss'</span><span class="p">:[],</span>
           <span class="s1">'val_acc'</span><span class="p">:[],</span>
           <span class="s1">'val_idx'</span><span class="p">:[]}</span>

<span class="n">step_idx</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">MAX_EPOCHS</span><span class="p">)):</span>

  <span class="n">running_loss</span><span class="p">,</span> <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>

  <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">):</span>
    <span class="n">step_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="c1"># Extract minibatch data and labels</span>
    <span class="n">data</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">),</span> <span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="c1"># Just like before, refresh gradient accumulators.</span>
    <span class="c1"># Note that this is now a method of the optimizer.</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
    <span class="c1"># Evaluate model and loss on minibatch</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">))</span>
    <span class="c1"># Compute gradients</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="c1"># Update parameters</span>
    <span class="c1"># Note how all the magic in the update of the parameters is encapsulated by</span>
    <span class="c1"># the optimizer class.</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1"># Log metrics for plotting</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">'train_loss'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
    <span class="n">metrics</span><span class="p">[</span><span class="s1">'train_acc'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="n">VAL_FREQ</span> <span class="o">==</span> <span class="p">(</span><span class="n">VAL_FREQ</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
      <span class="c1"># Get an estimate of the validation accuracy with 100 batches</span>
      <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span>
                                     <span class="n">num_batches</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                     <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">'val_idx'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">step_idx</span><span class="p">)</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)</span>
      <span class="n">metrics</span><span class="p">[</span><span class="s1">'val_acc'</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val_acc</span><span class="p">)</span>

      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[VALID] Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> - Batch </span><span class="si">{</span><span class="n">batch_id</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> - "</span>
            <span class="sa">f</span><span class="s2">"Loss: </span><span class="si">{</span><span class="n">val_loss</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> - Acc: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">val_acc</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>

    <span class="c1"># print statistics</span>
    <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">running_acc</span> <span class="o">+=</span> <span class="n">acc</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="c1"># Print every LOG_FREQ minibatches</span>
    <span class="k">if</span> <span class="n">batch_id</span> <span class="o">%</span> <span class="n">LOG_FREQ</span> <span class="o">==</span> <span class="p">(</span><span class="n">LOG_FREQ</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
      <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"[TRAIN] Epoch </span><span class="si">{</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> - Batch </span><span class="si">{</span><span class="n">batch_id</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2"> - "</span>
            <span class="sa">f</span><span class="s2">"Loss: </span><span class="si">{</span><span class="n">running_loss</span> <span class="o">/</span> <span class="n">LOG_FREQ</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> - "</span>
            <span class="sa">f</span><span class="s2">"Acc: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">running_acc</span> <span class="o">/</span> <span class="n">LOG_FREQ</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">%"</span><span class="p">)</span>

      <span class="n">running_loss</span><span class="p">,</span> <span class="n">running_acc</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "34e3cadd720c4523b05660b845f0aae4"}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 1 - Batch 200 - Loss: 2.235 - Acc: 38.174%
[TRAIN] Epoch 1 - Batch 200 - Loss: 2.274 - Acc: 30.945%
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 1 - Batch 400 - Loss: 2.067 - Acc: 52.773%
[TRAIN] Epoch 1 - Batch 400 - Loss: 2.166 - Acc: 44.289%
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 1 - Batch 600 - Loss: 1.789 - Acc: 56.836%
[TRAIN] Epoch 1 - Batch 600 - Loss: 1.935 - Acc: 55.367%
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 2 - Batch 200 - Loss: 1.265 - Acc: 69.531%
[TRAIN] Epoch 2 - Batch 200 - Loss: 1.373 - Acc: 66.094%
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 2 - Batch 400 - Loss: 1.072 - Acc: 77.617%
[TRAIN] Epoch 2 - Batch 400 - Loss: 1.168 - Acc: 74.133%
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[VALID] Epoch 2 - Batch 600 - Loss: 0.928 - Acc: 80.957%
[TRAIN] Epoch 2 - Batch 600 - Loss: 0.997 - Acc: 79.094%
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_2984</span><span class="o">/</span><span class="mf">729571843.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">56</span>     <span class="n">acc</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">*</span> <span class="p">(</span><span class="n">preds</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">))</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>     <span class="c1"># Compute gradients</span>
<span class="ne">---&gt; </span><span class="mi">58</span>     <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">59</span>     <span class="c1"># Update parameters</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span>     <span class="c1"># Note how all the magic in the update of the parameters is encapsulated by</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torch/_tensor.py</span> in <span class="ni">backward</span><span class="nt">(self, gradient, retain_graph, create_graph, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">253</span>                 <span class="n">create_graph</span><span class="o">=</span><span class="n">create_graph</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">254</span>                 <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">255</span>         <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradient</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">256</span> 
<span class="g g-Whitespace">    </span><span class="mi">257</span>     <span class="k">def</span> <span class="nf">register_hook</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hook</span><span class="p">):</span>

<span class="nn">/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torch/autograd/__init__.py</span> in <span class="ni">backward</span><span class="nt">(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)</span>
<span class="g g-Whitespace">    </span><span class="mi">147</span>     <span class="n">Variable</span><span class="o">.</span><span class="n">_execution_engine</span><span class="o">.</span><span class="n">run_backward</span><span class="p">(</span>
<span class="g g-Whitespace">    </span><span class="mi">148</span>         <span class="n">tensors</span><span class="p">,</span> <span class="n">grad_tensors_</span><span class="p">,</span> <span class="n">retain_graph</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span>
<span class="ne">--&gt; </span><span class="mi">149</span>         <span class="n">allow_unreachable</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">accumulate_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># allow_unreachable flag</span>
<span class="g g-Whitespace">    </span><span class="mi">150</span> 
<span class="g g-Whitespace">    </span><span class="mi">151</span> 

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'train_loss'</span><span class="p">])),</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">'train_loss'</span><span class="p">],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'val_idx'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">'val_loss'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Valid'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Loss'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'train_acc'</span><span class="p">])),</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">'train_acc'</span><span class="p">],</span>
           <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">metrics</span><span class="p">[</span><span class="s1">'val_idx'</span><span class="p">],</span> <span class="n">metrics</span><span class="p">[</span><span class="s1">'val_acc'</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Valid'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Iteration'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Accuracy'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="think-bonus-metrics">
<h2>Think! Bonus: Metrics<a class="headerlink" href="#think-bonus-metrics" title="Permalink to this headline">Â¶</a></h2>
<p>Which metric did you optimize when searching for the right configuration? The training set loss? Accuracy? Validation/test set metrics? Why? Discuss!</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D4_Optimization/solutions/W1D4_Tutorial1_Solution_093a66ad.py"><em>Click for solution</em></a></p>
<div class="section" id="evaluation">
<h3>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this headline">Â¶</a></h3>
<p>We <em>finally</em> can evaluate and compare the performance of the models on previously unseen examples.</p>
<p>Which model would you keep? (*drum roll*)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">'Your model...'</span><span class="p">)</span>
<span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">my_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">my_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Train Loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> / Test Loss </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Train Accuracy </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">% / Test Accuracy </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Benchmark model'</span><span class="p">)</span>
<span class="n">train_loss</span><span class="p">,</span> <span class="n">train_accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">benchmark_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">test_loss</span><span class="p">,</span> <span class="n">test_accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">benchmark_model</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Train Loss </span><span class="si">{</span><span class="n">train_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1"> / Test Loss </span><span class="si">{</span><span class="n">test_loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">'</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Train Accuracy </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">train_accuracy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">% / Test Accuracy </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">test_accuracy</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">%'</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D4_Optimization/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="../chapter_title.html" id="prev-link" title="previous page">Optimization</a>
<a class="right-next" href="../../W1D5_Regularization/chapter_title.html" id="next-link" title="next page">Regularization</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br/>
        
            Â© Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>