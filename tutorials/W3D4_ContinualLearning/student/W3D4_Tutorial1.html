
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 1: Introduction to Continual Learning — Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<link href="../../../_static/nma-dl-logo-square-4xp.jpeg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="W3D4_Tutorial2.html" rel="next" title="Tutorial 2: Out-of-distribution (OOD) Learning"/>
<link href="../chapter_title.html" rel="prev" title="Continual Learning"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-dl-logo-square-4xp.jpeg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial Neural Networks
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing more with fewer parameters
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Training loop of CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.html">
     Tutorial 3: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial2.html">
     Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_GenerativeModels/chapter_title.html">
   Generative Models (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Advanced topics
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Continual Learning (W3D4)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 1: Introduction to Continual Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionModelingProjectDL.html">
     Example Model Project: the Train Illusion
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/Example_Deep_Learning_Project.html">
     Example Deep Learning Project
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/docs/projects_overview.html">
   Project Templates
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/>
<label for="toctree-checkbox-19">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ComputerVision/README.html">
     Computer Vision
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-20" name="toctree-checkbox-20" type="checkbox"/>
<label for="toctree-checkbox-20">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/em_synapses.html">
       Knowledge Extraction from a Convolutional Neural Network
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/spectrogram_analysis.html">
       Music classification and generation with spectrograms
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/screws.html">
       Objective
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/image_alignment.html">
       Image Alignment
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/data_augmentation.html">
       Data Augmentation in image classification models
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ComputerVision/transfer_learning.html">
       Transfer Learning
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/ReinforcementLearning/README.html">
     Reinforcement Learning
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-21" name="toctree-checkbox-21" type="checkbox"/>
<label for="toctree-checkbox-21">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/robolympics.html">
       NMA Robolympics: Controlling robots using reinforcement learning
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/lunar_lander.html">
       Performance Analysis of DQN Algorithm on the Lunar Lander task
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/ReinforcementLearning/human_rl.html">
       Using RL to Model Cognitive Tasks
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/README.html">
     Natural Language Processing
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-22" name="toctree-checkbox-22" type="checkbox"/>
<label for="toctree-checkbox-22">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/sentiment_analysis.html">
       Twitter Sentiment Analysis
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/NaturalLanguageProcessing/machine_translation.html">
       Machine Translation
      </a>
</li>
</ul>
</li>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../../projects/Neuroscience/README.html">
     Neuroscience
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-23" name="toctree-checkbox-23" type="checkbox"/>
<label for="toctree-checkbox-23">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/slides.html">
       Slides
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/ideas_and_datasets.html">
       Ideas
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/pose_estimation.html">
       Animal Pose Estimation
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/cellular_segmentation.html">
       Segmentation and Denoising
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/algonauts_videos.html">
       Load algonauts videos
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/blurry_vision.html">
       Vision with Lost Glasses: Modelling how the brain deals with noisy input
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/finetuning_fmri.html">
       Moving beyond Labels: Finetuning CNNs on BOLD response
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../../projects/Neuroscience/neuro_seq_to_seq.html">
       Focus on what matters: inferring low-dimensional dynamics from neural recordings
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/datasets_and_models.html">
   Models and Data sets
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W3D4_ContinualLearning/student/W3D4_Tutorial1.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W3D4_ContinualLearning/student/W3D4_Tutorial1.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 1: Introduction to Continual Learning
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-0-overview-of-the-session-and-introduction-to-continual-learning">
     Video 0: Overview of the session and introduction to continual learning
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#install-dependencies">
     Install dependencies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#helper-functions">
     Helper functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#data-loader-mnist-dataset">
     Data-loader MNIST dataset
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-the-sequential-learning-problem-catastrophic-forgetting">
   Section 1: The sequential learning problem: catastrophic forgetting
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-introduction-to-catastrophic-forgetting">
     Video 1: Introduction to catastrophic forgetting
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-a-brief-example-of-catastrophic-forgetting">
     Section 1.1: A brief example of catastrophic forgetting
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#model-training-and-testing-functions-run-me">
       Model Training and Testing Functions [RUN ME!]
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-continual-learning-strategies">
   Section 2: Continual Learning strategies
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-cl-strategies">
     Video 2: CL strategies
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#split-mnist">
     Split MNIST
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#naive-strategy-fine-tuning">
     Naive strategy (“fine-tuning”)
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#elastic-weight-consolidation-ewc">
     Elastic Weight Consolidation (EWC)
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#plot-naive-vs-ewc-results">
       Plot Naive vs EWC results
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-continual-learning-benchmarks">
   Section 3: Continual learning benchmarks
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-benchmarks-and-different-types-of-continual-learning">
     Video 3: Benchmarks and different types of continual learning
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#task-incremental-split-mnist-versus-class-incremental-split-mnist">
     Task-incremental Split MNIST
     <em>
      versus
     </em>
     class-incremental Split MNIST
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#example-ewc-on-the-class-incremental-version-of-split-mnist">
     Example: EWC on the class-incremental version of Split MNIST
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#replay">
     Replay
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#example-test-replay-on-the-class-incremental-version-of-split-mnist">
     Example: Test replay on the class-incremental version of Split MNIST
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#plot-ewc-vs-replay">
       Plot EWC vs. Replay
      </a>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-3-identify-the-continual-learning-scenario-of-the-permuted-mnist-example-from-section-1">
     Exercise 3: Identify the continual learning scenario of the permuted MNIST example from Section 1
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-evaluation-of-continual-learning-algorithms">
   Section 4: Evaluation of continual learning algorithms
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-continual-learning-evaluation">
     Video 4: Continual Learning Evaluation
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-1-average-accuracy">
     Section 4.1: Average Accuracy
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-2-backward-transfer">
     Section 4.2: Backward Transfer
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-4-2-evaluate-your-cl-algorithm">
       Exercise 4.2: Evaluate your CL algorithm
      </a>
</li>
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-4-2-performance-metrics">
       Think! 4.2: Performance metrics
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-5-continual-learning-applications">
   Section 5: Continual Learning Applications
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-continual-learning-applications">
     Video 5: Continual Learning Applications
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#exercise-5-explore-the-challenging-core50-scenarios">
     Exercise 5: Explore the challenging CORe50 scenarios!
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W3D4_ContinualLearning/student/W3D4_Tutorial1.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-1-introduction-to-continual-learning">
<h1>Tutorial 1: Introduction to Continual Learning<a class="headerlink" href="#tutorial-1-introduction-to-continual-learning" title="Permalink to this headline">¶</a></h1>
<p><strong>Week 3, Day 4: Continual Learning</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Keiland Cooper, Diganta Misra, Gido van de Ven, Andrea Cossu, Vincenzo Lomonaco</p>
<p><strong>Content reviewers:</strong> Arush Tagade, Jeremy Forest, Siwei Bai</p>
<p><strong>Content editors:</strong> Anoop Kulkarni, Spiros Chavlis</p>
<p><strong>Production editors:</strong> Deepak Raya, Spiros Chavlis</p>
</div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial we’ll dive head-first into the exciting field of continual learning (CL). CL has gained increasing attention in recent years, and for good reason. CL is positioned as a problem across sub-disciplines, from academia to industry, and may promise to be a major pathway towards strong artificial intelligence (AI). As datasets get bigger and AI gets smarter, we’re expecting more and more cognitive capabilities from our machines.</p>
<p>We have a few specific objectives for this tutorial:</p>
<ul class="simple">
<li><p>Introduce major CL concepts</p></li>
<li><p>Introduce the most common strategies to aid CL</p></li>
<li><p>Utilize benchmarks and evaluation metrics</p></li>
<li><p>Explore present day applications of CL</p></li>
</ul>
<div class="section" id="video-0-overview-of-the-session-and-introduction-to-continual-learning">
<h2>Video 0: Overview of the session and introduction to continual learning<a class="headerlink" href="#video-0-overview-of-the-session-and-introduction-to-continual-learning" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "286f20c9824e43a1a4740f0fce053d84"}
</script></div>
</div>
</div>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">¶</a></h2>
<p>These are the slides for the videos in this tutorial</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/ejywm/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">¶</a></h1>
<p>First, let’s load in some useful packages and functions. We’ll primarily be using PyTorch as our neural network framework of choice. Be sure to run all the cells below so the code runs properly.</p>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Install dependencies</span>
<span class="o">!</span>pip install seaborn --quiet
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">datasets</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>

<span class="k">def</span> <span class="nf">plot_mnist</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">nPlots</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
  <span class="sd">""" Plot MNIST-like data """</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nPlots</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nPlots</span><span class="p">,</span> <span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">ii</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">multi_task_barplot</span><span class="p">(</span><span class="n">accs</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="sd">''' Plot n task accuracy</span>
<span class="sd">      used for S1 intro to CF code '''</span>
  <span class="n">nTasks</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nTasks</span><span class="p">),</span> <span class="n">accs</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'k'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Testing Accuracy (%)'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">nTasks</span><span class="p">),</span>
            <span class="p">[</span><span class="sa">f</span><span class="s2">"</span><span class="si">{</span><span class="n">TN</span><span class="si">}</span><span class="se">\n</span><span class="s2">Task </span><span class="si">{</span><span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">"</span> <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">TN</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="o">.</span><span class="n">keys</span><span class="p">())],</span>
            <span class="n">size</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">plot_task</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">samples_num</span><span class="p">):</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
  <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">samples_num</span><span class="p">):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">samples_num</span><span class="p">,</span> <span class="n">ii</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">ii</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">"gray"</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">'off'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="helper-functions">
<h2>Helper functions<a class="headerlink" href="#helper-functions" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Helper functions</span>

<span class="k">def</span> <span class="nf">load_mnist</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">asnumpy</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="sd">'''</span>
<span class="sd">  Helper function to maintain compatability with</span>
<span class="sd">  previous MNIST dataloaders in CLAI COLAB</span>

<span class="sd">  Much of this can likely now be fixed with the toTensor call on inport</span>
<span class="sd">  Or by using proper PyTorch functions... lol</span>

<span class="sd">  - KWC</span>
<span class="sd">  '''</span>

  <span class="n">x_traint</span><span class="p">,</span> <span class="n">t_traint</span> <span class="o">=</span> <span class="n">mnist_train</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mnist_train</span><span class="o">.</span><span class="n">targets</span>
  <span class="n">x_testt</span><span class="p">,</span> <span class="n">t_testt</span> <span class="o">=</span> <span class="n">mnist_test</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">mnist_test</span><span class="o">.</span><span class="n">targets</span>

  <span class="k">if</span> <span class="n">asnumpy</span><span class="p">:</span>
    <span class="c1"># Fix dimensions and convert back to np array for code compatability</span>
    <span class="c1"># We aren't using torch dataloaders for ease of use</span>
    <span class="n">x_traint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x_traint</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_testt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x_testt</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span> <span class="o">=</span> <span class="n">x_traint</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">x_testt</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">t_train</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">t_traint</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">t_testt</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span> <span class="o">=</span> <span class="n">x_traint</span><span class="p">,</span> <span class="n">t_traint</span>
    <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">x_testt</span><span class="p">,</span> <span class="n">t_testt</span>

  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"x_train dim: </span><span class="si">{</span><span class="n">x_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and type: </span><span class="si">{</span><span class="n">x_train</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"t_train dim: </span><span class="si">{</span><span class="n">t_train</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and type: </span><span class="si">{</span><span class="n">t_train</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"x_train dim: </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and type: </span><span class="si">{</span><span class="n">x_test</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"t_train dim: </span><span class="si">{</span><span class="n">t_test</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> and type: </span><span class="si">{</span><span class="n">t_test</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span>


<span class="k">def</span> <span class="nf">permute_mnist</span><span class="p">(</span><span class="n">mnist</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">""" Given the training set, permute pixels of each img the same way. """</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">"starting permutation..."</span><span class="p">)</span>
    <span class="n">h</span> <span class="o">=</span> <span class="n">w</span> <span class="o">=</span> <span class="mi">28</span>
    <span class="n">perm_inds</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">h</span><span class="o">*</span><span class="n">w</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">perm_inds</span><span class="p">)</span>
    <span class="c1"># print(perm_inds)</span>
    <span class="n">perm_mnist</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">set</span> <span class="ow">in</span> <span class="n">mnist</span><span class="p">:</span>
        <span class="n">num_img</span> <span class="o">=</span> <span class="nb">set</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">flat_set</span> <span class="o">=</span> <span class="nb">set</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_img</span><span class="p">,</span> <span class="n">w</span> <span class="o">*</span> <span class="n">h</span><span class="p">)</span>
        <span class="n">perm_mnist</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">flat_set</span><span class="p">[:,</span> <span class="n">perm_inds</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">num_img</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">h</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">print</span><span class="p">(</span><span class="s2">"done."</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">perm_mnist</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is not enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
          <span class="s2">"If you want to enable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
          <span class="s2">"`Hardware accelerator.` and select `GPU` from the dropdown menu"</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook. </span><span class="se">\n</span><span class="s2">"</span>
          <span class="s2">"If you want to disable it, in the menu under `Runtime` -&gt; </span><span class="se">\n</span><span class="s2">"</span>
          <span class="s2">"`Hardware accelerator.` and select `None` from the dropdown menu"</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
GPU is not enabled in this notebook. 
If you want to enable it, in the menu under `Runtime` -&gt; 
`Hardware accelerator.` and select `GPU` from the dropdown menu
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="data-loader-mnist-dataset">
<h2>Data-loader MNIST dataset<a class="headerlink" href="#data-loader-mnist-dataset" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Data-loader MNIST dataset</span>
<span class="kn">import</span> <span class="nn">tarfile</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">MNIST</span>

<span class="c1"># TODO:</span>
<span class="c1"># We need a more permenate solution for this...</span>
<span class="c1"># https://github.com/pytorch/vision/issues/1938</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading and unpacking MNIST data. Please wait a moment...'</span><span class="p">)</span>

<span class="c1"># The MNIST repo on LeCun's website nor AWS seem to be availible</span>
<span class="c1"># This is one popular private repo, but beware</span>
<span class="c1"># PyTorch is reported to be hosting one soon...</span>

<span class="n">fname</span> <span class="o">=</span> <span class="s1">'MNIST.tar.gz'</span>
<span class="n">url</span> <span class="o">=</span> <span class="s1">'https://www.di.ens.fr/~lelarge/MNIST.tar.gz'</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">allow_redirects</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">fname</span><span class="p">,</span> <span class="s1">'wb'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
  <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
<span class="k">with</span> <span class="n">tarfile</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span> <span class="k">as</span> <span class="n">tar</span><span class="p">:</span>
  <span class="n">tar</span><span class="o">.</span><span class="n">extractall</span><span class="p">(</span><span class="s1">'./'</span><span class="p">)</span>  <span class="c1"># specify which folder to extract to</span>

<span class="n">mnist_train</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s1">'./'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="p">]),</span>
                    <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">mnist_test</span> <span class="o">=</span> <span class="n">MNIST</span><span class="p">(</span><span class="s1">'./'</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                    <span class="n">transform</span><span class="o">=</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="p">]),</span>
                   <span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Downloading MNIST completed.'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading and unpacking MNIST data. Please wait a moment...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading MNIST completed.
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-the-sequential-learning-problem-catastrophic-forgetting">
<h1>Section 1: The sequential learning problem: catastrophic forgetting<a class="headerlink" href="#section-1-the-sequential-learning-problem-catastrophic-forgetting" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-1-introduction-to-catastrophic-forgetting">
<h2>Video 1: Introduction to catastrophic forgetting<a class="headerlink" href="#video-1-introduction-to-catastrophic-forgetting" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "c182bf99233f43e1b6bda97c2b3f5576"}
</script></div>
</div>
<p>Here we’ll explore catastrophic forgetting first hand, a key barrier preventing continual learning in neural networks. To do so, we’ll build a simple network model and try our best to teach it the trusty MNIST dataset</p>
</div>
<div class="section" id="section-1-1-a-brief-example-of-catastrophic-forgetting">
<h2>Section 1.1: A brief example of catastrophic forgetting<a class="headerlink" href="#section-1-1-a-brief-example-of-catastrophic-forgetting" title="Permalink to this headline">¶</a></h2>
<p>Let’s define a simple CNN that can perform fairly well on MNIST. We’ll also load in some training and testing functions we wrote to load the data into the model and train / test it. We don’t need to get into the details how they work for now (pretty standard) but feel free to double click the cell if you’re curious!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Here we define a simple multilayer CNN. Nothing too fancy</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="sd">""" run the network forward</span>
<span class="sd">    (uses the functional library (F) imported from pytorch)"""</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2_drop</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-training-and-testing-functions-run-me">
<h3>Model Training and Testing Functions [RUN ME!]<a class="headerlink" href="#model-training-and-testing-functions-run-me" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Model Training and Testing Functions [RUN ME!]</span>

<span class="c1"># @markdown `train(model, x_train, t_train, optimizer, epoch, device)`</span>
<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Train fnction</span>
<span class="sd">  """</span>
  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

  <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_train</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">):</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">256</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">t_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
  <span class="nb">print</span><span class="p">(</span><span class="s1">'Train Epoch: </span><span class="si">{}</span><span class="s1"> </span><span class="se">\t</span><span class="s1">Loss: </span><span class="si">{:.6f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span>


<span class="c1"># @markdown `test(model, x_test, t_test, device)`</span>
<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="sd">"""</span>
<span class="sd">    Test function.</span>
<span class="sd">    """</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">correct</span><span class="p">,</span> <span class="n">test_loss</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_test</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">):</span>
      <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">256</span>
      <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_test</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
          <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
          <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">t_test</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">test_loss</span> <span class="o">+=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>  <span class="c1"># sum up batch loss</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># get the index of the max logit</span>
        <span class="n">correct</span> <span class="o">+=</span> <span class="n">pred</span><span class="o">.</span><span class="n">eq</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">view_as</span><span class="p">(</span><span class="n">pred</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">test_loss</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Test set: Average loss: </span><span class="si">{:.4f}</span><span class="s1">, Accuracy: </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> (</span><span class="si">{:.0f}</span><span class="s1">%)</span><span class="se">\n</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">correct</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_test</span><span class="p">),</span>
        <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_test</span><span class="p">)))</span>
    <span class="k">return</span> <span class="mf">100.</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">simpNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">simpNet</span><span class="p">,</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">,</span> <span class="mi">320</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">out</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">320</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s load in our dataset, MNIST. We’ll also run a function we defined in the helper function cell above that permutes (scrambles) the images. This allows us to create additional datasets with similar statistics to MNIST on the fly. We’ll call the normal MNIST Task 1, and the permuted MNIST Task 2. We’ll see why in a second!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load in MNIST and create an additional permuted dataset</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">,</span>
                                              <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">x_train2</span><span class="p">,</span> <span class="n">x_test2</span> <span class="o">=</span> <span class="n">permute_mnist</span><span class="p">([</span><span class="n">x_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">],</span> <span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Plot the data to see what we're working with</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Task 1: MNIST Training data:'</span><span class="p">)</span>
<span class="n">plot_mnist</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">nPlots</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Task 2: Permuted MNIST data:'</span><span class="p">)</span>
<span class="n">plot_mnist</span><span class="p">(</span><span class="n">x_train2</span><span class="p">,</span> <span class="n">nPlots</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x_train dim: (60000, 1, 28, 28) and type: uint8
t_train dim: (60000,) and type: int64
x_train dim: (10000, 1, 28, 28) and type: uint8
t_train dim: (10000,) and type: int64
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task 1: MNIST Training data:
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_37_2.png" src="../../../_images/W3D4_Tutorial1_37_2.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task 2: Permuted MNIST data:
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_37_4.png" src="../../../_images/W3D4_Tutorial1_37_4.png"/>
</div>
</div>
<p>Great! We have our data. This commonly  used task is typically called the “permuted MNIST <a class="reference external" href="https://arxiv.org/pdf/1312.6211.pdf">task</a>”, given the shuffling of the data. The permutations are the same across all images in the same task (all the permuted image in that task follow are permuted in the same way). This is useful as it allows you to create almost as many tasks as you would like out of the same dataset. While it may <a class="reference external" href="https://arxiv.org/pdf/1805.09733.pdf">not be the best benchmark for CL</a>, it is commonly used, and will serve our purposes well enough for illustration.</p>
<p>Now, let’s initialize and train our model on the standard MNIST dataset (Task 1) and make sure everything is working properly.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define a new model and set params</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Train the model on MNIST</span>
<span class="n">nEpochs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training model on </span><span class="si">{</span><span class="n">nEpochs</span><span class="si">}</span><span class="s2"> epochs..."</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">nEpochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
  <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training model on 3 epochs...
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/opt/hostedtoolcache/Python/3.7.11/x64/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.877743
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0003, Accuracy: 8384/10000 (84%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.763951
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0002, Accuracy: 9267/10000 (93%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 3 	Loss: 0.960827
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0001, Accuracy: 9402/10000 (94%)
</pre></div>
</div>
</div>
</div>
<p>Okay great! It seems we get decent accuracy on standard MNIST which means the model is learning our dataset. Now, a reasonable assumption is that, like humans, once the network learns something, it can aggregate its knowledge and learn something else.</p>
<p>First, let’s get a baseline for how the model performs on the dataset it was just trained on (Task 1) as well as to see how well it performs on a new dataset (Task 2).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># test the model's accuracy on both the regular and permuted dataset</span>

<span class="c1"># Let's define a dictionary that holds each of the task</span>
<span class="c1"># datasets and labels</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'MNIST'</span><span class="p">:(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">),</span>
         <span class="s1">'Perm MNIST'</span><span class="p">:(</span><span class="n">x_test2</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)}</span>
<span class="n">t1_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ti</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing on task </span><span class="si">{</span><span class="n">ti</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">t1_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tasks</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">tasks</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">))</span>

<span class="c1"># And then let's plot the testing accuracy on both datasets</span>
<span class="n">multi_task_barplot</span><span class="p">(</span><span class="n">t1_accs</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="s1">'Accuracy after training on Task 1 </span><span class="se">\n</span><span class="s1">but before Training on Task 2'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task 1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0001, Accuracy: 9402/10000 (94%)

Testing on task 2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0020, Accuracy: 894/10000 (9%)
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_41_3.png" src="../../../_images/W3D4_Tutorial1_41_3.png"/>
</div>
</div>
<p>As we saw before, the model does great on the Task 1 dataset it was trained on, but not so well on the new one. No worries! We haven’t taught it the permuted MNIST dataset yet! So let’s train the <em>same</em> task 1-trained-model on the new data, and see if we can get comparable performance between the two types of MNIST</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train the previously trained model on Task 2, the permuted MNIST dataset</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
  <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train2</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test2</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

<span class="c1"># Same data as before, stored in a dict</span>
<span class="n">tasks</span> <span class="o">=</span> <span class="p">{</span><span class="s1">'MNIST'</span><span class="p">:(</span><span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">),</span>
         <span class="s1">'Perm MNIST'</span><span class="p">:(</span><span class="n">x_test2</span><span class="p">,</span> <span class="n">t_test</span><span class="p">)}</span>
<span class="c1"># Test the model on both datasets, same as before</span>
<span class="n">t12_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">ti</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">tasks</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing on task </span><span class="si">{</span><span class="n">ti</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">t12_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">tasks</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">tasks</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">))</span>

<span class="c1"># And then let's plot each of the testing accuracies after the new training</span>
<span class="n">multi_task_barplot</span><span class="p">(</span><span class="n">t12_accs</span><span class="p">,</span> <span class="n">tasks</span><span class="p">,</span> <span class="n">t</span><span class="o">=</span><span class="s1">'Accuracy after training on Task 1 and then Training on Task 2'</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 1.818300
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0008, Accuracy: 5744/10000 (57%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 1.703263
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0006, Accuracy: 6988/10000 (70%)

Testing on task 1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0019, Accuracy: 804/10000 (8%)

Testing on task 2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0006, Accuracy: 6988/10000 (70%)
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_43_6.png" src="../../../_images/W3D4_Tutorial1_43_6.png"/>
</div>
</div>
<p>Hey! Training did the trick, task 2 (permuted MNIST) has great accuracy now that we trained the model on it. But something is wrong. We just saw that Task 1 (standard MNIST) had high accuracy before we trained on the new task. What gives? Try to incorporate what you learned in the lecture to help explain the problem we’re seeing. You might also take a few seconds and think of what possible soultions you might like to try. In the next section, we’ll look into exactly that!</p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-continual-learning-strategies">
<h1>Section 2: Continual Learning strategies<a class="headerlink" href="#section-2-continual-learning-strategies" title="Permalink to this headline">¶</a></h1>
<div class="section" id="video-2-cl-strategies">
<h2>Video 2: CL strategies<a class="headerlink" href="#video-2-cl-strategies" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "f554ed146bf947c2b47ccc36e1c3b7a5"}
</script></div>
</div>
</div>
<div class="section" id="split-mnist">
<h2>Split MNIST<a class="headerlink" href="#split-mnist" title="Permalink to this headline">¶</a></h2>
<p>For this section we will again use the MNIST dataset, but we will now create 5 tasks by splitting the dataset up in such a way that each task contains 2 classes. This problem is called Split MNIST, and it is popular toy problem in the continual learning literature</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1"># Specify which classes should be part of which task</span>
<span class="n">task_classes_arr</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">)]</span>
<span class="n">tasks_num</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_classes_arr</span><span class="p">)</span>

<span class="c1"># Divide the data over the different tasks</span>
<span class="n">task_data_with_overlap</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">task_classes</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_classes_arr</span><span class="p">):</span>
  <span class="n">train_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">t_train</span><span class="p">,</span> <span class="n">task_classes</span><span class="p">)</span>
  <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">t_test</span><span class="p">,</span> <span class="n">task_classes</span><span class="p">)</span>
  <span class="n">x_train_task</span><span class="p">,</span> <span class="n">t_train_task</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">t_train</span><span class="p">[</span><span class="n">train_mask</span><span class="p">]</span>
  <span class="n">x_test_task</span><span class="p">,</span> <span class="n">t_test_task</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">test_mask</span><span class="p">],</span> <span class="n">t_test</span><span class="p">[</span><span class="n">test_mask</span><span class="p">]</span>
  <span class="c1"># Convert the original class labels (i.e., the digits 0 to 9) to</span>
  <span class="c1"># "within-task labels" so that within each task one of the digits is labelled</span>
  <span class="c1"># as '0' and the other as '1'.</span>
  <span class="n">task_data_with_overlap</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x_train_task</span><span class="p">,</span> <span class="n">t_train_task</span> <span class="o">-</span> <span class="p">(</span><span class="n">task_id</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
                                 <span class="n">x_test_task</span><span class="p">,</span> <span class="n">t_test_task</span> <span class="o">-</span> <span class="p">(</span><span class="n">task_id</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)))</span>

<span class="c1"># Display tasks</span>
<span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">task_classes_arr</span><span class="p">)):</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Task: </span><span class="si">{</span><span class="n">sample</span> <span class="o">+</span> <span class="mi">1</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">plot_task</span><span class="p">(</span><span class="n">task_data_with_overlap</span><span class="p">[</span><span class="n">sample</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_classes_arr</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
Task: 1
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_50_1.png" src="../../../_images/W3D4_Tutorial1_50_1.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task: 2
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_50_3.png" src="../../../_images/W3D4_Tutorial1_50_3.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task: 3
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_50_5.png" src="../../../_images/W3D4_Tutorial1_50_5.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task: 4
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_50_7.png" src="../../../_images/W3D4_Tutorial1_50_7.png"/>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Task: 5
</pre></div>
</div>
<img alt="../../../_images/W3D4_Tutorial1_50_9.png" src="../../../_images/W3D4_Tutorial1_50_9.png"/>
</div>
</div>
</div>
<div class="section" id="naive-strategy-fine-tuning">
<h2>Naive strategy (“fine-tuning”)<a class="headerlink" href="#naive-strategy-fine-tuning" title="Permalink to this headline">¶</a></h2>
<p>First, let’s see what happens if we simply sequentially train a deep neural network on these tasks in the standard way.</p>
<p>Let’s start by defining our network. As is common in the continual learning literature, we will use a “multi-headed layout”. This means that we have a separate output layer for each task to be learned, but the hidden layers of the network are shared between all tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">## Base network that is shared between all tasks</span>
<span class="k">class</span> <span class="nc">FBaseNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hsize</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FBaseNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">784</span><span class="p">,</span> <span class="n">hsize</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="c1">## Output layer, which will be separate for each task</span>
<span class="k">class</span> <span class="nc">FHeadNet</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">base_net</span><span class="p">,</span> <span class="n">input_size</span><span class="o">=</span><span class="mi">512</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">FHeadNet</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">base_net</span> <span class="o">=</span> <span class="n">base_net</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">base_net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_layer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the base network (a new head is defined when we encounter a new task)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">FBaseNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">heads</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Define a list to store test accuracies for each task</span>
<span class="n">accs_naive</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Set the number of epochs to train each task for</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Loop through all tasks</span>
<span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tasks_num</span><span class="p">):</span>
  <span class="c1"># Collect the training data for the new task</span>
  <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">task_data_with_overlap</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>

  <span class="c1"># Define a new head for this task</span>
  <span class="n">model</span> <span class="o">=</span> <span class="n">FHeadNet</span><span class="p">(</span><span class="n">base</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">heads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

  <span class="c1"># Set the optimizer</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

  <span class="c1"># Train the model (with the new head) on the current task</span>
  <span class="n">train</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">],</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="c1"># Test the model on all tasks seen so far</span>
  <span class="n">accs_subset</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">task_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">task_data_with_overlap</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">accs_subset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
  <span class="c1"># For unseen tasks, we don't test</span>
  <span class="k">if</span> <span class="n">task_id</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">tasks_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
    <span class="n">accs_subset</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">4</span> <span class="o">-</span> <span class="n">task_id</span><span class="p">))</span>
  <span class="c1"># Collect all test accuracies</span>
  <span class="n">accs_naive</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accs_subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 3 	Loss: 0.000000
Test set: Average loss: 0.0000, Accuracy: 2113/2115 (100%)

Train Epoch: 3 	Loss: 0.443125
Test set: Average loss: 0.0031, Accuracy: 1930/2115 (91%)

Test set: Average loss: 0.0002, Accuracy: 1861/2042 (91%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 3 	Loss: 0.097207
Test set: Average loss: 0.0096, Accuracy: 1239/2115 (59%)

Test set: Average loss: 0.0011, Accuracy: 1498/2042 (73%)

Test set: Average loss: 0.0000, Accuracy: 1864/1874 (99%)

Train Epoch: 3 	Loss: 0.000244
Test set: Average loss: 0.0070, Accuracy: 893/2115 (42%)

Test set: Average loss: 0.0007, Accuracy: 1497/2042 (73%)

Test set: Average loss: 0.0004, Accuracy: 1152/1874 (61%)

Test set: Average loss: 0.0000, Accuracy: 1974/1986 (99%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 3 	Loss: 0.695176
Test set: Average loss: 0.0034, Accuracy: 1807/2115 (85%)

Test set: Average loss: 0.0004, Accuracy: 1042/2042 (51%)

Test set: Average loss: 0.0004, Accuracy: 1051/1874 (56%)

Test set: Average loss: 0.0004, Accuracy: 1091/1986 (55%)

Test set: Average loss: 0.0005, Accuracy: 1046/1983 (53%)
</pre></div>
</div>
</div>
</div>
<p>As you can see, whenever this network is trained on a new task, its performance on previously learned tasks drops substantially.</p>
<p>Now, let’s see whether we can use a continual learning strategy to prevent such forgetting.</p>
</div>
<div class="section" id="elastic-weight-consolidation-ewc">
<h2>Elastic Weight Consolidation (EWC)<a class="headerlink" href="#elastic-weight-consolidation-ewc" title="Permalink to this headline">¶</a></h2>
<p>EWC is a popular CL strategy which involves computing the importance of weights of the network relative to the task using the Fisher score and then penalizing the network for changes to the most important weights of the previous task.</p>
<p>It was introduced in the paper “<a class="reference external" href="https://arxiv.org/abs/1612.00796">Overcoming catastrophic forgetting in neural networks
</a>“.</p>
<p>For EWC, we need to define a new function to compute the fisher information matrix for each weight at the end of every task:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">on_task_update</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">shared_model</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span>
                   <span class="n">optpar_dict</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>

  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

  <span class="c1"># accumulating gradients</span>
  <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_train</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">):</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">256</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">t_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

  <span class="n">fisher_dict</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">optpar_dict</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="c1"># gradients accumulated can be used to calculate fisher</span>
  <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">shared_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
    <span class="n">optpar_dict</span><span class="p">[</span><span class="n">task_id</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
    <span class="n">fisher_dict</span><span class="p">[</span><span class="n">task_id</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">param</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We also need to modify our train function to add the new regularization loss:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train_ewc</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">shared_model</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
              <span class="n">epoch</span><span class="p">,</span> <span class="n">ewc_lambda</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span> <span class="n">optpar_dict</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>

  <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="k">for</span> <span class="n">start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t_train</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">256</span><span class="p">):</span>
    <span class="n">end</span> <span class="o">=</span> <span class="n">start</span> <span class="o">+</span> <span class="mi">256</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">x_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">t_train</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

    <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

    <span class="c1">### magic here! :-)</span>
    <span class="k">for</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">task_id</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">shared_model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
        <span class="n">fisher</span> <span class="o">=</span> <span class="n">fisher_dict</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>
        <span class="n">optpar</span> <span class="o">=</span> <span class="n">optpar_dict</span><span class="p">[</span><span class="n">task</span><span class="p">][</span><span class="n">name</span><span class="p">]</span>
        <span class="n">loss</span> <span class="o">+=</span> <span class="p">(</span><span class="n">fisher</span> <span class="o">*</span> <span class="p">(</span><span class="n">optpar</span> <span class="o">-</span> <span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="n">ewc_lambda</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Train Epoch: </span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2">Loss: </span><span class="si">{</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now let’s train with EWC:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the base network (a new head is defined when we encounter a new task)</span>
<span class="n">base</span> <span class="o">=</span> <span class="n">FBaseNet</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">heads</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Define a list to store test accuracies for each task</span>
<span class="n">accs_ewc</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Set number of epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">2</span>

<span class="c1"># Set EWC hyperparameter</span>
<span class="n">ewc_lambda</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="c1"># Define dictionaries to store values needed by EWC</span>
<span class="n">fisher_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">optpar_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Loop through all tasks</span>
<span class="k">for</span> <span class="n">task_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">tasks_num</span><span class="p">):</span>
    <span class="c1"># Collect the training data for the new task</span>
    <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">task_data_with_overlap</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span>

    <span class="c1"># Define a new head for this task</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">FHeadNet</span><span class="p">(</span><span class="n">base</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">heads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="c1"># Set the optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="c1"># Train the model (with the new head) on the current task</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">train_ewc</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">],</span> <span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span><span class="o">.</span><span class="n">base_net</span><span class="p">,</span> <span class="n">task_id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span>
                  <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">ewc_lambda</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span>
                  <span class="n">optpar_dict</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">on_task_update</span><span class="p">(</span><span class="n">task_id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">],</span>
                   <span class="n">heads</span><span class="p">[</span><span class="n">task_id</span><span class="p">]</span><span class="o">.</span><span class="n">base_net</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span> <span class="n">optpar_dict</span><span class="p">,</span>
                   <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

    <span class="c1"># Test the model on all tasks seen so far</span>
    <span class="n">accs_subset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">task_id</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">task_data_with_overlap</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">heads</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
        <span class="n">accs_subset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_acc</span><span class="p">)</span>
    <span class="c1"># For unseen tasks, we don't test</span>
    <span class="k">if</span> <span class="n">task_id</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">tasks_num</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">accs_subset</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">4</span> <span class="o">-</span> <span class="n">task_id</span><span class="p">))</span>
    <span class="c1"># Collect all test accuracies</span>
    <span class="n">accs_ewc</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accs_subset</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.005017
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.001975
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0004, Accuracy: 2108/2115 (100%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.451759
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.164818
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0017, Accuracy: 1364/2115 (64%)

Test set: Average loss: 0.0002, Accuracy: 1816/2042 (89%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: nan
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: nan
Test set: Average loss: nan, Accuracy: 980/2115 (46%)

Test set: Average loss: nan, Accuracy: 1032/2042 (51%)

Test set: Average loss: nan, Accuracy: 982/1874 (52%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: nan
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: nan
Test set: Average loss: nan, Accuracy: 980/2115 (46%)

Test set: Average loss: nan, Accuracy: 1032/2042 (51%)

Test set: Average loss: nan, Accuracy: 982/1874 (52%)

Test set: Average loss: nan, Accuracy: 958/1986 (48%)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: nan
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: nan
Test set: Average loss: nan, Accuracy: 980/2115 (46%)

Test set: Average loss: nan, Accuracy: 1032/2042 (51%)

Test set: Average loss: nan, Accuracy: 982/1874 (52%)

Test set: Average loss: nan, Accuracy: 958/1986 (48%)

Test set: Average loss: nan, Accuracy: 974/1983 (49%)
</pre></div>
</div>
</div>
</div>
<div class="section" id="plot-naive-vs-ewc-results">
<h3>Plot Naive vs EWC results<a class="headerlink" href="#plot-naive-vs-ewc-results" title="Permalink to this headline">¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">seaborn</span></code> library should be installed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plot Naive vs EWC results</span>

<span class="c1"># @markdown `seaborn` library should be installed</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">accs_fine_grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">accs_naive</span><span class="p">)</span>
<span class="n">nan_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">accs_naive</span><span class="p">)</span>

<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">accs_naive</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">nan_mask</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">'.0f'</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">xticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">accs_ewc</span><span class="p">,</span> <span class="n">vmin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">vmax</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">mask</span><span class="o">=</span><span class="n">nan_mask</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">fmt</span><span class="o">=</span><span class="s1">'.0f'</span><span class="p">,</span>
            <span class="n">yticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">xticklabels</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">cbar</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Tested on Task'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Naive'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'EWC'</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">accs_naive</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">nanmean</span><span class="p">(</span><span class="n">accs_ewc</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">linewidth</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">'Naive'</span><span class="p">,</span> <span class="s1">'EWC'</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">'Accumulated Accuracy for Seen Tasks'</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">'Task Number'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial1_65_0.png" src="../../../_images/W3D4_Tutorial1_65_0.png"/>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-continual-learning-benchmarks">
<h1>Section 3: Continual learning benchmarks<a class="headerlink" href="#section-3-continual-learning-benchmarks" title="Permalink to this headline">¶</a></h1>
<p>In this section, we will introduce different ways in which a continual learning problem could be set up.</p>
<div class="section" id="video-3-benchmarks-and-different-types-of-continual-learning">
<h2>Video 3: Benchmarks and different types of continual learning<a class="headerlink" href="#video-3-benchmarks-and-different-types-of-continual-learning" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "696b41973d5c4f9eb26f7dace5d1a00b"}
</script></div>
</div>
<p>As introduced in the above video, continual learning research certainly does not only use the MNIST dataset.
But not to make things more complicated than necessary (and to make sure the examples run in an acceptable amount of time), we continue with the Split MNIST example for now.
At the end of this notebook we will take a sneak peak at the CORe50 dataset.</p>
<p>Another point made in the video is that continual learning is not a unitary problem, but that there are different types (or ‘scenarios’) of continual learning:</p>
<ul class="simple">
<li><p><strong>Task-incremental learning</strong>: an algorithm must incrementally learn a set of clearly distinct tasks (the tasks are clearly distinct because the algorithm is always told which task it must perform)</p></li>
<li><p><strong>Domain-incremental learning</strong>: an algorithm must learn the same kind of task but in different contexts or domains</p></li>
<li><p><strong>Class-incremental learning</strong>: an algorithm must incrementally learn to distinguish between an increasing number of classes.</p></li>
</ul>
<p>![table.png](data:image/png;base64,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)</p>
<p>These continual learning scenarios can be distinguished from each other based on whether task identity information (or the task label) is provided to the algorithm, and – if it is not – whether task identity must be inferred (see schematic in the lecture slides).</p>
<p>In <a class="reference external" href="https://arxiv.org/abs/1904.07734">this paper</a> you can find more details about these different types of continual learning.</p>
</div>
<div class="section" id="task-incremental-split-mnist-versus-class-incremental-split-mnist">
<h2>Task-incremental Split MNIST <em>versus</em> class-incremental Split MNIST<a class="headerlink" href="#task-incremental-split-mnist-versus-class-incremental-split-mnist" title="Permalink to this headline">¶</a></h2>
<p>Now, let’s get back to our Split MNIST example. To start with, let’s identify according to which scenario Split MNIST was performed in the previous section.</p>
<p>Recall that the Split MNIST problem consists of five tasks, whereby each task contains two digits. In the previous section, the model was set-up in such a way that it had a separate output layer for each of these tasks (this is typically called a ‘<em>multi-headed output layer</em>’). At test time, the model then used the output layer of the task to which the example to be classified belonged. This means that it was assumed that the model always knows which task it must perform, so this was an example of <strong>task-incremental learning</strong>.</p>
<p>In the continual learning literature. this variant of Split MNIST is also referred to as <em><strong>multi-headed Split MNIST</strong></em>.
However, although a multi-headed output layer is probably the most common way to use task identity information, it is not the only way (for example, see <a class="reference external" href="https://doi.org/10.1073/pnas.1803839115">this paper</a>).</p>
<p>Now, let’s reorganize the Split MNIST problem to set it up as a <strong>class-incremental learning</strong> problem. That is, task information is no longer provided to the model; and the model must be able to decide itself to which task a test sample belongs.
This means that, after all tasks have been learned, the model must now choose between all ten digits.
This variant of Split MNIST is also referred to as <em><strong>single-headed Split MNIST</strong></em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load the MNIST dataset</span>
<span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">load_mnist</span><span class="p">(</span><span class="n">mnist_train</span><span class="p">,</span> <span class="n">mnist_test</span><span class="p">,</span>
                                              <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Define which classes are part of each task</span>
<span class="n">classes_per_task</span> <span class="o">=</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">),</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">)]</span>

<span class="c1"># Divde the MNIST dataset in tasks</span>
<span class="n">task_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">classes_in_this_task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">classes_per_task</span><span class="p">):</span>

  <span class="c1"># Which data-points belong to the classes in the current task?</span>
  <span class="n">train_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">t_train</span><span class="p">,</span> <span class="n">classes_in_this_task</span><span class="p">)</span>
  <span class="n">test_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">isin</span><span class="p">(</span><span class="n">t_test</span><span class="p">,</span> <span class="n">classes_in_this_task</span><span class="p">)</span>
  <span class="n">x_train_task</span><span class="p">,</span> <span class="n">t_train_task</span> <span class="o">=</span> <span class="n">x_train</span><span class="p">[</span><span class="n">train_mask</span><span class="p">],</span> <span class="n">t_train</span><span class="p">[</span><span class="n">train_mask</span><span class="p">]</span>
  <span class="n">x_test_task</span><span class="p">,</span> <span class="n">t_test_task</span> <span class="o">=</span> <span class="n">x_test</span><span class="p">[</span><span class="n">test_mask</span><span class="p">],</span> <span class="n">t_test</span><span class="p">[</span><span class="n">test_mask</span><span class="p">]</span>

  <span class="c1"># Add the data for the current task</span>
  <span class="n">task_data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x_train_task</span><span class="p">,</span> <span class="n">t_train_task</span><span class="p">,</span> <span class="n">x_test_task</span><span class="p">,</span> <span class="n">t_test_task</span><span class="p">))</span>

<span class="c1"># In contrast to the task-incremental version of Split MNIST explored in the</span>
<span class="c1"># last section, now task identity information will not be provided to the model</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x_train dim: (60000, 1, 28, 28) and type: uint8
t_train dim: (60000,) and type: int64
x_train dim: (10000, 1, 28, 28) and type: uint8
t_train dim: (10000,) and type: int64
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="example-ewc-on-the-class-incremental-version-of-split-mnist">
<h2>Example: EWC on the class-incremental version of Split MNIST<a class="headerlink" href="#example-ewc-on-the-class-incremental-version-of-split-mnist" title="Permalink to this headline">¶</a></h2>
<p>Let’s now try the EWC method on this class-incremental version of Split MNIST.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the model and the optimzer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>

<span class="c1"># Set 'lambda', the hyperparameter of EWC</span>
<span class="n">ewc_lambda</span> <span class="o">=</span> <span class="mf">0.4</span>

<span class="c1"># Define dictionaries to store values needed by EWC</span>
<span class="n">fisher_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">optpar_dict</span> <span class="o">=</span> <span class="p">{}</span>

<span class="c1"># Prepare list to store average accuracies after each task</span>
<span class="n">ewc_accs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through all tasks</span>
<span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_data</span><span class="p">):</span>

  <span class="c1"># Collect training data</span>
  <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">task</span>

  <span class="c1"># Training with EWC</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">"Training on task: "</span><span class="p">,</span> <span class="nb">id</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">):</span>
    <span class="n">train_ewc</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="nb">id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span>
              <span class="n">ewc_lambda</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span> <span class="n">optpar_dict</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="n">on_task_update</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">fisher_dict</span><span class="p">,</span>
                 <span class="n">optpar_dict</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="c1"># Evaluate performance after training on this task</span>
  <span class="n">avg_acc</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">id_test</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_data</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing on task: </span><span class="si">{</span><span class="n">id_test</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">task</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">avg_acc</span> <span class="o">=</span> <span class="n">avg_acc</span> <span class="o">+</span> <span class="n">acc</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Avg acc: </span><span class="si">{</span><span class="n">avg_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_data</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">ewc_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_data</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training on task:  0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.226513
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2109/2115 (100%)

Testing on task: 1
Test set: Average loss: 0.0064, Accuracy: 0/2042 (0%)

Testing on task: 2
Test set: Average loss: 0.0072, Accuracy: 0/1874 (0%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0083, Accuracy: 0/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0083, Accuracy: 0/1983 (0%)

Avg acc: 19.94326241134752
Training on task:  1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 1.479263
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task: 0
Test set: Average loss: 0.0014, Accuracy: 251/2115 (12%)

Testing on task: 1
Test set: Average loss: 0.0004, Accuracy: 1764/2042 (86%)

Testing on task: 2
Test set: Average loss: 0.0023, Accuracy: 0/1874 (0%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0030, Accuracy: 1/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0039, Accuracy: 0/1983 (0%)

Avg acc: 19.660772188126113
Training on task:  2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 1.621918
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task: 0
Test set: Average loss: 0.0018, Accuracy: 131/2115 (6%)

Testing on task: 1
Test set: Average loss: 0.0015, Accuracy: 201/2042 (10%)

Testing on task: 2
Test set: Average loss: 0.0005, Accuracy: 1682/1874 (90%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0031, Accuracy: 0/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0040, Accuracy: 0/1983 (0%)

Avg acc: 21.158336014316063
Training on task:  3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 2.478762
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task: 0
Test set: Average loss: 0.0015, Accuracy: 401/2115 (19%)

Testing on task: 1
Test set: Average loss: 0.0013, Accuracy: 568/2042 (28%)

Testing on task: 2
Test set: Average loss: 0.0014, Accuracy: 353/1874 (19%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0013, Accuracy: 900/1986 (45%)

Testing on task: 4
Test set: Average loss: 0.0018, Accuracy: 6/1983 (0%)

Avg acc: 22.246436598027916
Training on task:  4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 70596837987991433510912.000000
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing on task: 0
Test set: Average loss: 0.0022, Accuracy: 3/2115 (0%)

Testing on task: 1
Test set: Average loss: 0.0017, Accuracy: 4/2042 (0%)

Testing on task: 2
Test set: Average loss: 0.0016, Accuracy: 13/1874 (1%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0018, Accuracy: 12/1986 (1%)

Testing on task: 4
Test set: Average loss: 0.0016, Accuracy: 1012/1983 (51%)

Avg acc: 10.533890092866773
</pre></div>
</div>
</div>
</div>
<p>That didn’t work well…</p>
<p>The model only correctly predicts the classes from the last task it has seen, all earlier seen classes seem to be forgotten.</p>
<p>You might wonder whether the reason that EWC performed so badly in the above example is because we chose an unsuitable value for the hyperparameter lambda.
Although we don’t have time to demonstrate this, there are no values of lambda that would lead to good performance.</p>
<p>In general, parameter regularization based methods, such as EWC, have been found not to work well on class-incremental learning problems.</p>
</div>
<div class="section" id="replay">
<h2>Replay<a class="headerlink" href="#replay" title="Permalink to this headline">¶</a></h2>
<p>As discussed in the lecture of the previous section, another popular continual learning strategy is replay. Let’s see whether replay works better on the class-incremental learning version of Split MNIST than EWC did.</p>
<p>One implementation of replay is to simply store all data from previously seen tasks, and to then, whenever a new task must be learned, mix in that stored data with the training data of the new task.</p>
<p>To achieve this form of replay, let’s define the following function for shuffling multiple datasets (e.g., the data from previous tasks with the data from the current task) together:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">shuffle_datasets</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">seed</span><span class="p">,</span> <span class="n">in_place</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="sd">""" Shuffle a list of two (or more) datasets. """</span>

  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">rng_state</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">get_state</span><span class="p">()</span>
  <span class="n">new_dataset</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">in_place</span><span class="p">:</span>
      <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">new_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">rng_state</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="n">in_place</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">new_dataset</span>
</pre></div>
</div>
</div>
</div>
<p>Note that this form of replay is somewhat extreme, as it stores all the training data from previous tasks. In practice, replay is often implemented in ways that store less data, for example either by using relatively small memory buffers (see <a class="reference external" href="https://arxiv.org/abs/1902.10486">this paper</a>) or by learning a generative model to then generate the data to be replayed (see <a class="reference external" href="https://arxiv.org/abs/1705.08690">this paper</a> or <a class="reference external" href="https://www.nature.com/articles/s41467-020-17866-2">this paper</a>).</p>
</div>
<div class="section" id="example-test-replay-on-the-class-incremental-version-of-split-mnist">
<h2>Example: Test replay on the class-incremental version of Split MNIST<a class="headerlink" href="#example-test-replay-on-the-class-incremental-version-of-split-mnist" title="Permalink to this headline">¶</a></h2>
<p>Let’s try whether this replay strategy works better than EWC.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define the model and the optimizer</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="c1"># Prepare list to store average accuracies after each task</span>
<span class="n">rehe_accs</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Loop through all tasks</span>
<span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_data</span><span class="p">):</span>

  <span class="c1"># Collect training data</span>
  <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">task</span>

  <span class="c1"># Add replay</span>
  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">id</span><span class="p">):</span>
    <span class="n">past_x_train</span><span class="p">,</span> <span class="n">past_t_train</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">task_data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    <span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">x_train</span><span class="p">,</span> <span class="n">past_x_train</span><span class="p">))</span>
    <span class="n">t_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">t_train</span><span class="p">,</span> <span class="n">past_t_train</span><span class="p">))</span>

  <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span> <span class="o">=</span> <span class="n">shuffle_datasets</span><span class="p">([</span><span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

  <span class="c1"># Training</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Training on task: </span><span class="si">{</span><span class="nb">id</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">):</span>
    <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_train</span><span class="p">,</span> <span class="n">t_train</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>

  <span class="c1"># Evaluate performance after training on this task</span>
  <span class="n">avg_acc</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">for</span> <span class="n">id_test</span><span class="p">,</span> <span class="n">task</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">task_data</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Testing on task: </span><span class="si">{</span><span class="n">id_test</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span> <span class="o">=</span> <span class="n">task</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x_test</span><span class="p">,</span> <span class="n">t_test</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">avg_acc</span> <span class="o">=</span> <span class="n">avg_acc</span> <span class="o">+</span> <span class="n">acc</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Avg acc: </span><span class="si">{</span><span class="n">avg_acc</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">task_data</span><span class="p">)</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
  <span class="n">rehe_accs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_acc</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">task_data</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training on task: 0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.180061
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.012716
Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2114/2115 (100%)

Testing on task: 1
Test set: Average loss: 0.0119, Accuracy: 0/2042 (0%)

Testing on task: 2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0132, Accuracy: 0/1874 (0%)

Testing on task: 3
Test set: Average loss: 0.0141, Accuracy: 0/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0110, Accuracy: 0/1983 (0%)

Avg acc: 19.990543735224584
Training on task: 1
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.402671
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.205235
Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2102/2115 (99%)

Testing on task: 1
Test set: Average loss: 0.0000, Accuracy: 1992/2042 (98%)

Testing on task: 2
Test set: Average loss: 0.0040, Accuracy: 0/1874 (0%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0048, Accuracy: 0/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0039, Accuracy: 0/1983 (0%)

Avg acc: 39.38735259317917
Training on task: 2
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.532893
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.392877
Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2084/2115 (99%)

Testing on task: 1
Test set: Average loss: 0.0000, Accuracy: 1988/2042 (97%)

Testing on task: 2
Test set: Average loss: 0.0000, Accuracy: 1817/1874 (97%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0026, Accuracy: 0/1986 (0%)

Testing on task: 4
Test set: Average loss: 0.0024, Accuracy: 0/1983 (0%)

Avg acc: 58.569638110341316
Training on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.637280
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.496460
Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2068/2115 (98%)

Testing on task: 1
Test set: Average loss: 0.0000, Accuracy: 1977/2042 (97%)

Testing on task: 2
Test set: Average loss: 0.0000, Accuracy: 1793/1874 (96%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0000, Accuracy: 1887/1986 (95%)

Testing on task: 4
Test set: Average loss: 0.0018, Accuracy: 0/1983 (0%)

Avg acc: 77.05748490353808
Training on task: 4
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 1 	Loss: 0.605949
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Train Epoch: 2 	Loss: 0.674918
Testing on task: 0
Test set: Average loss: 0.0000, Accuracy: 2064/2115 (98%)

Testing on task: 1
Test set: Average loss: 0.0000, Accuracy: 1966/2042 (96%)

Testing on task: 2
Test set: Average loss: 0.0000, Accuracy: 1821/1874 (97%)

Testing on task: 3
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: Average loss: 0.0000, Accuracy: 1873/1986 (94%)

Testing on task: 4
Test set: Average loss: 0.0001, Accuracy: 1793/1983 (90%)

Avg acc: 95.15347301254934
</pre></div>
</div>
</div>
</div>
<p>And finally, let’s compare the performance of EWC and Replay on the class-incremental version of Split MNIST in a plot:</p>
<div class="section" id="plot-ewc-vs-replay">
<h3>Plot EWC vs. Replay<a class="headerlink" href="#plot-ewc-vs-replay" title="Permalink to this headline">¶</a></h3>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plot EWC vs. Replay</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">rehe_accs</span><span class="p">,</span> <span class="s1">'-o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"Replay"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="n">ewc_accs</span><span class="p">,</span> <span class="s1">'-o'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">"EWC"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Tasks Encountered'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Average Accuracy'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'CL Strategies on Class-incremental version of Split MNIST'</span><span class="p">,</span>
          <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">prop</span><span class="o">=</span><span class="p">{</span><span class="s1">'size'</span><span class="p">:</span> <span class="mi">16</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../../_images/W3D4_Tutorial1_89_0.png" src="../../../_images/W3D4_Tutorial1_89_0.png"/>
</div>
</div>
</div>
</div>
<div class="section" id="exercise-3-identify-the-continual-learning-scenario-of-the-permuted-mnist-example-from-section-1">
<h2>Exercise 3: Identify the continual learning scenario of the permuted MNIST example from Section 1<a class="headerlink" href="#exercise-3-identify-the-continual-learning-scenario-of-the-permuted-mnist-example-from-section-1" title="Permalink to this headline">¶</a></h2>
<p>What type of ‘scenario’ was the permuted MNIST problem that was introduced in Section 1? Was it task-incremental, domain-incremental or class-incremental? Try to motivate your answer.</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D4_ContinualLearning/solutions/W3D4_Tutorial1_Solution_ba508d9e.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-evaluation-of-continual-learning-algorithms">
<h1>Section 4: Evaluation of continual learning algorithms<a class="headerlink" href="#section-4-evaluation-of-continual-learning-algorithms" title="Permalink to this headline">¶</a></h1>
<p>Understanding how your CL algorithm is performing is key to gain insights on its behavior and to decide how to improve it.</p>
<p>Here, we will focus on how to build some of the most important CL metrics!</p>
<div class="section" id="video-4-continual-learning-evaluation">
<h2>Video 4: Continual Learning Evaluation<a class="headerlink" href="#video-4-continual-learning-evaluation" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "d42965d41018467691b8d30b7434512a"}
</script></div>
</div>
<p>We have already trained the model on T tasks and recorded all the accuracy values in a single TxT matrix.</p>
</div>
<div class="section" id="section-4-1-average-accuracy">
<h2>Section 4.1: Average Accuracy<a class="headerlink" href="#section-4-1-average-accuracy" title="Permalink to this headline">¶</a></h2>
<p>The Average Accuracy (ACC) metric computes the average accuracy over all tasks after training on all tasks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">ACC</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Average Accuracy metric</span>

<span class="sd">  :param result_matrix: TxT matrix containing accuracy values in each (i, j) entry.</span>
<span class="sd">    (i, j) -&gt; test accuracy on task j after training on task i</span>
<span class="sd">  """</span>

  <span class="n">final_accs</span> <span class="o">=</span> <span class="n">result_matrix</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># take accuracies after final training</span>
  <span class="n">acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">final_accs</span><span class="p">)</span>  <span class="c1"># compute average</span>

  <span class="k">return</span> <span class="n">acc</span><span class="p">,</span> <span class="n">final_accs</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="section-4-2-backward-transfer">
<h2>Section 4.2: Backward Transfer<a class="headerlink" href="#section-4-2-backward-transfer" title="Permalink to this headline">¶</a></h2>
<p>The Backward Transfer (BWT) metric of task i computes the accuracy on task i after training on last task <strong>minus</strong> the accuracy on task i after training on task i.</p>
<p>To get the average BWT you have to average across all tasks.</p>
<p><strong>Negative BWT expresses the amount of forgetting suffered by the algorithm.</strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">BWT</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">):</span>
  <span class="sd">"""</span>
<span class="sd">  Backward Transfer metric</span>

<span class="sd">  :param result_matrix: TxT matrix containing accuracy values in each (i, j) entry.</span>
<span class="sd">    (i, j) -&gt; test accuracy on task j after training on task i</span>
<span class="sd">  """</span>

  <span class="n">final_accs</span> <span class="o">=</span> <span class="n">result_matrix</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># take accuracies after final training</span>
  <span class="c1"># accuracies on task i right after training on task i, for all i</span>
  <span class="n">training_accs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">)</span>
  <span class="n">task_bwt</span> <span class="o">=</span> <span class="n">final_accs</span> <span class="o">-</span> <span class="n">training_accs</span>  <span class="c1"># BWT for each task</span>
  <span class="n">average_bwt</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">task_bwt</span><span class="p">)</span>  <span class="c1"># compute average</span>

  <span class="k">return</span> <span class="n">average_bwt</span><span class="p">,</span> <span class="n">task_bwt</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="exercise-4-2-evaluate-your-cl-algorithm">
<h3>Exercise 4.2: Evaluate your CL algorithm<a class="headerlink" href="#exercise-4-2-evaluate-your-cl-algorithm" title="Permalink to this headline">¶</a></h3>
<p>You should replace the ellipses, i.e., <code class="docutils literal notranslate"><span class="pre">...</span></code>, with your code. This is the only cell you have to modify :)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">"""</span>
<span class="sd">Create a TxT matrix with values between 0 and 1 to</span>
<span class="sd">be used to compute the metrics.</span>
<span class="sd">"""</span>
<span class="n">T</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># number of tasks</span>
<span class="n">result_matrix</span> <span class="o">=</span> <span class="o">...</span>  <span class="c1"># here put a TxT matrix with values in [0, 1]</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D4_ContinualLearning/solutions/W3D4_Tutorial1_Solution_77a92249.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="think-4-2-performance-metrics">
<h3>Think! 4.2: Performance metrics<a class="headerlink" href="#think-4-2-performance-metrics" title="Permalink to this headline">¶</a></h3>
<p>Why we choose a specific number of performance metrics even if we have access to numerous metrics? Why the result matrix has <code class="docutils literal notranslate"><span class="pre">nan</span></code> values?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W3D4_ContinualLearning/solutions/W3D4_Tutorial1_Solution_b5bea723.py"><em>Click for solution</em></a></p>
<p>You <strong>don’t</strong> need to modify the next cell, just execute it to see metrics in action!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">result_matrix</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">T</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
  <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"You should fill the values of `result_matrix`, and `T` first."</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Result matrix shape: </span><span class="si">{</span><span class="n">result_matrix</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Result matrix values:</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">result_matrix</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># print Average Accuracy metric</span>
<span class="n">acc</span><span class="p">,</span> <span class="n">final_accs</span> <span class="o">=</span> <span class="n">ACC</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">ACC: </span><span class="si">{</span><span class="n">acc</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Accuracies for each task: </span><span class="si">{</span><span class="n">final_accs</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>

<span class="c1"># print Backward Transfer metric</span>
<span class="n">bwt</span><span class="p">,</span> <span class="n">bwt_task</span> <span class="o">=</span> <span class="n">BWT</span><span class="p">(</span><span class="n">result_matrix</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">BWT: </span><span class="si">{</span><span class="n">bwt</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"BWT for each task: </span><span class="si">{</span><span class="n">bwt_task</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">AttributeError</span><span class="g g-Whitespace">                            </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_14980</span><span class="o">/</span><span class="mf">675530718.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span>   <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">"You should fill the values of `result_matrix`, and `T` first."</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">3</span> 
<span class="ne">----&gt; </span><span class="mi">4</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Result matrix shape: </span><span class="si">{</span><span class="n">result_matrix</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Result matrix values:</span><span class="se">\n</span><span class="s2"> </span><span class="si">{</span><span class="n">result_matrix</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> 

<span class="ne">AttributeError</span>: 'ellipsis' object has no attribute 'shape'
</pre></div>
</div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-5-continual-learning-applications">
<h1>Section 5: Continual Learning Applications<a class="headerlink" href="#section-5-continual-learning-applications" title="Permalink to this headline">¶</a></h1>
<p>Continual Learning with deep architectures may help us develop sustainable AI systems that can efficiently improve their skills and knowledge over time, adapting to ever-changing environments and learning objectives. In this section we will discuss about intriguing real-world applications that would highly benefit from recent advances in Continual Learning.</p>
<div class="section" id="video-5-continual-learning-applications">
<h2>Video 5: Continual Learning Applications<a class="headerlink" href="#video-5-continual-learning-applications" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "0b538e5938ee4f5ab07cb6ad4c03033e"}
</script></div>
</div>
<p><strong>CORe50</strong> is an interesting real-world video dataset composed of 50 domestic objects belonging to 10 different categories and specifically designed for Continual Learning. You can find more information about the dataset and benchmark in its <a class="reference external" href="https://vlomonaco.github.io/core50">official website</a>.</p>
<p>Here we will use the <a class="reference external" href="https://avalanche.continualai.org">Avalanche library</a> to automatically download and use this dataset. Avalanche allows you to explore more challenging datasets and tasks to bring your continual learning algorithms into the real-world!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install git+https://github.com/ContinualAI/avalanche.git --quiet
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>^C
<span class="-Color -Color-Red">ERROR: Operation cancelled by user</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">avalanche.benchmarks.classic</span> <span class="kn">import</span> <span class="n">CORe50</span>
<span class="c1"># the scenario "New Instances" (NI) corresponds to the previously introduced</span>
<span class="c1"># Domain-Incremental setting and it’s based on the idea of encountering images</span>
<span class="c1"># of the same classes for every incremental batch of data (or experience if you</span>
<span class="c1"># will). The "mini" option downloads data 32x32 instead of the original 128x128.</span>
<span class="n">benchmark</span> <span class="o">=</span> <span class="n">CORe50</span><span class="p">(</span><span class="n">dataset_root</span><span class="o">=</span><span class="s2">"/content/core50/"</span><span class="p">,</span> <span class="n">scenario</span><span class="o">=</span><span class="s2">"ni"</span><span class="p">,</span> <span class="n">mini</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">benchmark</span><span class="o">.</span><span class="n">train_stream</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">classes_in_this_experience</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercise-5-explore-the-challenging-core50-scenarios">
<h2>Exercise 5: Explore the challenging CORe50 scenarios!<a class="headerlink" href="#exercise-5-explore-the-challenging-core50-scenarios" title="Permalink to this headline">¶</a></h2>
<p>CORe50 offers a number of interesting preset scenarios already implemented and available to you through Avalanche.</p>
<p>In this exercise try to explore the different scenarios offered (like the challenging NICv2-391) and possibly even apply what you’ve previously learned (like a replay approach) to get the best accuracy you can!</p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h1>
<p>Well, you did it! Congratulations on making it through your (first?) Continual Learning codebase. As mentioned, this is only the tip of the iceberg, and there’s a lot more you can dig into if you want to explore.</p>
<p>If you do want to explore, one of the best places to learn more is <a class="reference external" href="https://www.continualai.org/about_us/">ContinualAI.org</a>. There, you can interact with a large portion of the continual learning community, and find resources such as a <a class="reference external" href="https://www.continualai.org/papers/">database</a> of relevant papers, <a class="reference external" href="https://www.youtube.com/c/continualai">lectures</a> from researchers discussing their papers, <a class="reference external" href="https://github.com/ContinualAI/colab">additional tutorials</a>, and much <a class="reference external" href="https://www.continualai.org/lab/">more</a>. You might also be interested in <a class="reference external" href="https://avalanche.continualai.org/">Avalanche</a>, the largest  library for continual learning.</p>
<p>MILA also has a wonderful <a class="reference external" href="https://sites.google.com/view/ift6760-b2021">website</a> with open Continual Learning course materials, by Dr. Irina Rish.</p>
<p>Further questions? Feel free to reach out to <a class="reference external" href="https://www.kwcooper.xyz/contact">Keiland</a></p>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W3D4_ContinualLearning/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="../chapter_title.html" id="prev-link" title="previous page">Continual Learning</a>
<a class="right-next" href="W3D4_Tutorial2.html" id="next-link" title="next page">Tutorial 2: Out-of-distribution (OOD) Learning</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br/>
        
            © Copyright 2021.<br/>
</p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>